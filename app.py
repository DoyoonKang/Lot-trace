import altair as alt
import streamlit as st
import pandas as pd
import datetime as dt
import re
from pathlib import Path
from openpyxl import load_workbook
import requests
from io import StringIO
from typing import List, Dict, Optional


# =========================
# Page Config (ë”± 1ë²ˆë§Œ!)
# =========================
st.set_page_config(
    page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬",
    page_icon="ğŸ§ª",
    layout="wide",
)


# =========================
# Google Sheets (Public) Reader
# =========================
@st.cache_data(ttl=60, show_spinner=False)
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))


# =========================
# Config
# =========================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BINDER_VISC = "Binder_Visc"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"

COLOR_CODE = {
    "Black": "B",
    "White": "W",
    "Blue": "U",
    "Green": "G",
    "Yellow": "Y",
    "Red": "R",
    "Pink": "P",
}

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"


# =========================
# Helpers
# =========================
def _read_excel_from_path(xlsx_path: str) -> Dict[str, pd.DataFrame]:
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)

    return {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "binder_visc": read(SHEET_BINDER_VISC),
        "base_lab": read(SHEET_BASE_LAB),
    }


@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> Dict[str, pd.DataFrame]:
    return _read_excel_from_path(xlsx_path)


def normalize_date(x):
    if pd.isna(x):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        return pd.to_datetime(x).date()
    except Exception:
        return None


def coerce_date_series(s: pd.Series) -> pd.Series:
    """
    ë‚ ì§œ íŒŒì‹±ì„ ìµœëŒ€í•œ ê°•í•˜ê²Œ:
    - ì¼ë°˜ ë¬¸ìì—´/ë‚ ì§œê°ì²´ -> pd.to_datetime
    - ì—‘ì…€ ë‚ ì§œ ìˆ«ì(ì˜ˆ: 45234) -> origin=1899-12-30 ë¡œ ë³€í™˜
    """
    if s is None:
        return pd.Series([pd.NaT] * 0)

    x = s.copy()

    # 1) ì¼ë°˜ íŒŒì‹±
    dt1 = pd.to_datetime(x, errors="coerce")

    # 2) ì—‘ì…€ ìˆ«ì ë‚ ì§œ ë³´ì •(ì¼ë¶€ë§Œ NaTì¸ ê²½ìš°ë„ ë³´ì™„)
    num = pd.to_numeric(x, errors="coerce")
    dt2 = pd.to_datetime(num, unit="D", origin="1899-12-30", errors="coerce")

    return dt1.fillna(dt2)


def coerce_float_series(s: pd.Series) -> pd.Series:
    """
    '45,000' ê°™ì´ ì‰¼í‘œ í¬í•¨/ë¬¸ì í¬í•¨ ìˆ«ìë„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
    """
    if s is None:
        return pd.Series([pd.NA] * 0)
    x = s.copy()
    x = x.astype(str).str.replace(",", "", regex=False).str.strip()
    x = x.replace({"": pd.NA, "nan": pd.NA, "None": pd.NA, "NaN": pd.NA})
    return pd.to_numeric(x, errors="coerce")


def safe_minmax_dates(values, fallback_days: int = 90):
    s = pd.to_datetime(values, errors="coerce").dropna()
    today = dt.date.today()
    if len(s) == 0:
        return today - dt.timedelta(days=fallback_days), today
    return s.min().date(), s.max().date()


def delta_e76(lab1, lab2):
    return float(((lab1[0] - lab2[0]) ** 2 + (lab1[1] - lab2[1]) ** 2 + (lab1[2] - lab2[2]) ** 2) ** 0.5)


def extract_delta_e_from_note(note: str) -> Optional[float]:
    if note is None or pd.isna(note):
        return None
    s = str(note)
    m = re.search(r"\[Î”E76=([0-9]+(?:\.[0-9]+)?)\]", s)
    if m:
        try:
            return float(m.group(1))
        except Exception:
            return None
    return None


def get_binder_limits(spec_binder: pd.DataFrame, binder_name: str):
    df = spec_binder[spec_binder["ë°”ì¸ë”ëª…"] == binder_name].copy()
    visc = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("ì ë„", na=False)]
    uv = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("UV", na=False)]

    visc_lo = float(visc["í•˜í•œ"].dropna().iloc[0]) if len(visc["í•˜í•œ"].dropna()) else None
    visc_hi = float(visc["ìƒí•œ"].dropna().iloc[0]) if len(visc["ìƒí•œ"].dropna()) else None
    uv_hi = float(uv["ìƒí•œ"].dropna().iloc[0]) if len(uv["ìƒí•œ"].dropna()) else None
    rule = df["Lotë¶€ì—¬ê·œì¹™"].dropna().iloc[0] if "Lotë¶€ì—¬ê·œì¹™" in df.columns and len(df["Lotë¶€ì—¬ê·œì¹™"].dropna()) else None
    return visc_lo, visc_hi, uv_hi, rule


def parse_binder_rule(rule: Optional[str]):
    if not rule:
        return None, False
    m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip())
    if not m:
        return None, False
    return m.group(1), bool(m.group(2))


def infer_binder_type_from_lot(spec_binder: pd.DataFrame, binder_lot: str):
    if not binder_lot:
        return None
    rules = (
        spec_binder[["ë°”ì¸ë”ëª…", "Lotë¶€ì—¬ê·œì¹™"]]
        .dropna()
        .drop_duplicates()
        .to_dict("records")
    )
    for r in rules:
        rule = str(r["Lotë¶€ì—¬ê·œì¹™"])
        m = re.match(r"^([A-Za-z0-9]+)\+", rule)
        if m:
            prefix = m.group(1)
            if str(binder_lot).startswith(prefix):
                return r["ë°”ì¸ë”ëª…"]
    return None


def next_seq_for_pattern(existing_lots: pd.Series, prefix: str, date_str: str, sep: str = "-"):
    lots = existing_lots.dropna().astype(str).tolist()
    seqs = []
    for lot in lots:
        if not lot.startswith(prefix + date_str):
            continue
        rest = lot[len(prefix + date_str):]
        if sep and rest.startswith(sep):
            rest = rest[len(sep):]
        m = re.match(r"^(\d+)", rest)
        if m:
            try:
                seqs.append(int(m.group(1)))
            except Exception:
                pass
    return (max(seqs) + 1) if seqs else 1


def generate_single_lot(single_df: pd.DataFrame, product_code: str, color_group: str, in_date: dt.date):
    code = (product_code or "").strip()
    color_code = COLOR_CODE.get(color_group)
    if not color_code:
        return None

    if code.startswith("NPL"):
        prefix = "NPL"
    elif code.startswith("PL"):
        prefix = "PL"
    elif code.startswith("SL") or code.startswith("NSL"):
        prefix = "SL"
    else:
        prefix = "PL"

    date_str = in_date.strftime("%y%m%d")
    patt_prefix = f"{prefix}{color_code}{date_str}"
    lots = single_df.get("ë‹¨ì¼ìƒ‰ì‰í¬ Lot", pd.Series(dtype=str)).dropna().astype(str).tolist()

    seqs = []
    for lot in lots:
        if lot.startswith(patt_prefix):
            rest = lot[len(patt_prefix):]
            m = re.match(r"^(\d{2,})", rest)
            if m:
                seqs.append(int(m.group(1)))
    seq = (max(seqs) + 1) if seqs else 1
    return f"{patt_prefix}{seq:02d}"


def judge_range(value, lo, hi):
    if value is None or pd.isna(value):
        return None
    try:
        v = float(value)
    except Exception:
        return None
    if lo is not None and v < float(lo):
        return "ë¶€ì í•©"
    if hi is not None and v > float(hi):
        return "ë¶€ì í•©"
    return "ì í•©"


def ensure_sheet_with_headers(xlsx_path: str, sheet_name: str, headers: List[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        wb.save(xlsx_path)


def append_row_to_sheet(xlsx_path: str, sheet_name: str, row: dict):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    values = [row.get(h, None) for h in headers]
    ws.append(values)
    wb.save(xlsx_path)


def append_rows_to_sheet(xlsx_path: str, sheet_name: str, rows: List[dict]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]

    for row in rows:
        values = [row.get(h, None) for h in headers]
        ws.append(values)

    wb.save(xlsx_path)


def df_quick_filter(df: pd.DataFrame, text: str, cols: List[str]):
    if not text:
        return df
    t = str(text).strip()
    if not t:
        return df
    mask = False
    for c in cols:
        if c not in df.columns:
            continue
        mask = mask | df[c].astype(str).str.contains(t, case=False, na=False)
    return df[mask]


def sort_df_by_any_date_col(df: pd.DataFrame):
    if df is None or len(df) == 0:
        return df
    candidates = ["ì¼ì", "ë‚ ì§œ", "ì…ì¶œê³ ì¼", "ì…ê³ ì¼", "ì¶œê³ ì¼", "Date", "date"]
    hit = None
    for c in candidates:
        if c in df.columns:
            hit = c
            break
    if hit is None:
        return df
    tmp = df.copy()
    tmp["_sort_date"] = pd.to_datetime(tmp[hit], errors="coerce")
    tmp = tmp.sort_values("_sort_date", ascending=False).drop(columns=["_sort_date"])
    return tmp


# =========================
# UI Header
# =========================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("âœ… ëŒ€ì‹œë³´ë“œ(ë‹¨ì¼ìƒ‰ ìš”ì•½/ì¶”ì´)  |  âœ… ì‰í¬ ì…ê³  ì…ë ¥(ì—‘ì…€ ëˆ„ì )  |  âœ… ë°”ì¸ë” ì…ì¶œê³ /ì—…ì²´ë°˜í™˜  |  âœ… ë¹ ë¥¸ê²€ìƒ‰")


# =========================
# Data file selection (Excel)
# =========================
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼")
    xlsx_path = st.text_input(
        "ì—‘ì…€ íŒŒì¼ ê²½ë¡œ",
        value=DEFAULT_XLSX,
        help="ë¡œì»¬ ì‹¤í–‰ ì‹œ, app.pyì™€ ê°™ì€ í´ë”ì— ì—‘ì…€ì„ ë‘ë©´ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(ì½ê¸° ì „ìš© ê¶Œì¥)", type=["xlsx"])

if uploaded is not None:
    tmp_bytes = uploaded.read()
    tmp_path = Path(st.session_state.get("_tmp_xlsx_path", ".streamlit_tmp.xlsx"))
    tmp_path.write_bytes(tmp_bytes)
    xlsx_path = str(tmp_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì´ ëª¨ë“œì—ì„œëŠ” ì €ì¥í•´ë„ ì„œë²„ì— ì˜êµ¬ ëˆ„ì ì´ ë³´ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)")

if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.stop()

# ì—…ì²´ë°˜í™˜ ì‹œíŠ¸ ì—†ìœ¼ë©´ ìë™ ìƒì„±
ensure_sheet_with_headers(
    xlsx_path,
    SHEET_BINDER_RETURN,
    headers=["ë°˜í™˜ì¼ì", "ë°”ì¸ë”ëª…", "ê´€ë ¨ Lot(ì„ íƒ)", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "]
)

# ë°ì´í„° ë¡œë“œ
data = load_data(xlsx_path)
binder_df = data["binder"].copy()
single_df = data["single"].copy()
spec_binder = data["spec_binder"].copy()
spec_single = data["spec_single"].copy()
base_lab = data["base_lab"].copy()

# normalize (ìˆìœ¼ë©´)
if "ì œì¡°/ì…ê³ ì¼" in binder_df.columns:
    binder_df["ì œì¡°/ì…ê³ ì¼"] = binder_df["ì œì¡°/ì…ê³ ì¼"].apply(normalize_date)
if "ì…ê³ ì¼" in single_df.columns:
    single_df["ì…ê³ ì¼"] = single_df["ì…ê³ ì¼"].apply(normalize_date)

# ì—…ì²´ë°˜í™˜ ë¡œë“œ
try:
    binder_return_df = pd.read_excel(xlsx_path, sheet_name=SHEET_BINDER_RETURN).copy()
    if "ë°˜í™˜ì¼ì" in binder_return_df.columns:
        binder_return_df["ë°˜í™˜ì¼ì"] = binder_return_df["ë°˜í™˜ì¼ì"].apply(normalize_date)
except Exception:
    binder_return_df = pd.DataFrame(columns=["ë°˜í™˜ì¼ì", "ë°”ì¸ë”ëª…", "ê´€ë ¨ Lot(ì„ íƒ)", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "])


# =========================
# Tabs
# =========================
tab_dash, tab_ink_in, tab_binder, tab_search = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ§¾ ì‰í¬ ì…ê³ ", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰"]
)


# =========================
# Dashboard (ê·¸ë˜í”„ëŠ” ì´ íƒ­ì—ë§Œ)
# =========================
with tab_dash:
    b_total = len(binder_df)
    s_total = len(single_df)
    b_ng = int((binder_df.get("íŒì •", pd.Series(dtype=str)) == "ë¶€ì í•©").sum()) if "íŒì •" in binder_df.columns else 0
    s_ng = int((single_df.get("ì ë„íŒì •", pd.Series(dtype=str)) == "ë¶€ì í•©").sum()) if "ì ë„íŒì •" in single_df.columns else 0

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ë°”ì¸ë” ê¸°ë¡", f"{b_total:,}")
    c2.metric("ë°”ì¸ë” ë¶€ì í•©", f"{b_ng:,}")
    c3.metric("ë‹¨ì¼ìƒ‰ ê¸°ë¡", f"{s_total:,}")
    c4.metric("ë‹¨ì¼ìƒ‰(ì ë„) ë¶€ì í•©", f"{s_ng:,}")

    st.divider()

    # -------------------------
    # 1) ë‹¨ì¼ìƒ‰ ë°ì´í„° í‘œ
    # -------------------------
    st.subheader("1) ë‹¨ì¼ìƒ‰ ë°ì´í„° ëª©ë¡ (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë°”ì¸ë”/ì ë„/ìƒ‰ì°¨)")
    st.caption("ë³´ê³ ìš©ìœ¼ë¡œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì •ë¦¬í•´ í•œ ë²ˆì— ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.")

    s = single_df.copy()

    if "ë¹„ê³ " in s.columns:
        s["ìƒ‰ì°¨ê°’(Î”E76)"] = s["ë¹„ê³ "].apply(extract_delta_e_from_note)
    else:
        s["ìƒ‰ì°¨ê°’(Î”E76)"] = None

    # ë‚ ì§œ/ì ë„ ê°•ì œ ë³€í™˜(í‘œì—ì„œë„ ì¼ê´€ë˜ê²Œ)
    if "ì…ê³ ì¼" in s.columns:
        s["_in_dt"] = coerce_date_series(s["ì…ê³ ì¼"])
    else:
        s["_in_dt"] = pd.NaT

    if "ì ë„ì¸¡ì •ê°’(cP)" in s.columns:
        s["_visc"] = coerce_float_series(s["ì ë„ì¸¡ì •ê°’(cP)"])
    else:
        s["_visc"] = pd.NA

    f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.6, 2.0])
    with f1:
        dmin, dmax = safe_minmax_dates(s["_in_dt"], fallback_days=90)
        start = st.date_input("ì‹œì‘ì¼", value=dmin, key="dash_list_start")
    with f2:
        end = st.date_input("ì¢…ë£Œì¼", value=dmax, key="dash_list_end")
    with f3:
        cg = st.multiselect("ìƒ‰ìƒêµ°", sorted(s["ìƒ‰ìƒêµ°"].dropna().unique().tolist()), key="dash_list_cg") if "ìƒ‰ìƒêµ°" in s.columns else []
    with f4:
        pc = st.multiselect("ì œí’ˆì½”ë“œ", sorted(s["ì œí’ˆì½”ë“œ"].dropna().unique().tolist()), key="dash_list_pc") if "ì œí’ˆì½”ë“œ" in s.columns else []

    if start > end:
        start, end = end, start

    s_view = s.copy()
    s_view = s_view.dropna(subset=["_in_dt"])
    s_view = s_view[(s_view["_in_dt"].dt.date >= start) & (s_view["_in_dt"].dt.date <= end)]

    if cg and "ìƒ‰ìƒêµ°" in s_view.columns:
        s_view = s_view[s_view["ìƒ‰ìƒêµ°"].isin(cg)]
    if pc and "ì œí’ˆì½”ë“œ" in s_view.columns:
        s_view = s_view[s_view["ì œí’ˆì½”ë“œ"].isin(pc)]

    show_cols = []
    s_view["ì œì¡°ì¼ì"] = s_view["_in_dt"].dt.date
    show_cols.append("ì œì¡°ì¼ì")
    if "ìƒ‰ìƒêµ°" in s_view.columns:
        show_cols.append("ìƒ‰ìƒêµ°")
    if "ì œí’ˆì½”ë“œ" in s_view.columns:
        show_cols.append("ì œí’ˆì½”ë“œ")
    if "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in s_view.columns:
        s_view["ì‚¬ìš©ëœë°”ì¸ë”"] = s_view["ì‚¬ìš©ëœ ë°”ì¸ë” Lot"].astype(str)
        show_cols.append("ì‚¬ìš©ëœë°”ì¸ë”")
    if "ì ë„ì¸¡ì •ê°’(cP)" in s_view.columns:
        s_view["ì ë„(cP)"] = s_view["_visc"]
        show_cols.append("ì ë„(cP)")
    show_cols.append("ìƒ‰ì°¨ê°’(Î”E76)")

    if len(s_view) == 0:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì¼ìƒ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(
            s_view.sort_values("_in_dt", ascending=False)[show_cols],
            use_container_width=True,
            hide_index=True,
        )

    st.divider()

    # -------------------------
    # 1-2) ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì  + ë¼ë²¨)
    # -------------------------
    st.subheader("ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„")
    st.caption("ê° ìƒ‰ìƒêµ°ì˜ í‰ê·  ì ë„ë¥¼ ì ìœ¼ë¡œ í‘œì‹œí•˜ê³  ì˜†ì— ê°’ì„ í‘œê¸°í•©ë‹ˆë‹¤.")

    if "ìƒ‰ìƒêµ°" in single_df.columns and "ì ë„ì¸¡ì •ê°’(cP)" in single_df.columns:
        tmp = single_df.copy()
        tmp["_visc"] = coerce_float_series(tmp["ì ë„ì¸¡ì •ê°’(cP)"])
        avg_df = (
            tmp.dropna(subset=["ìƒ‰ìƒêµ°", "_visc"])
            .groupby("ìƒ‰ìƒêµ°", as_index=False)["_visc"]
            .mean()
            .rename(columns={"_visc": "í‰ê· ì ë„(cP)"})
        )
        if len(avg_df) == 0:
            st.info("í‰ê· ì„ ê³„ì‚°í•  ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì ë„ê°’ í˜•ì‹/ì‰¼í‘œ/ê³µë°± í™•ì¸)")
        else:
            avg_df["ë¼ë²¨"] = avg_df["í‰ê· ì ë„(cP)"].round(1).astype(str)

            base = alt.Chart(avg_df).encode(
                x=alt.X("ìƒ‰ìƒêµ°:N", sort=sorted(avg_df["ìƒ‰ìƒêµ°"].tolist()), title="ìƒ‰ìƒêµ°"),
                y=alt.Y("í‰ê· ì ë„(cP):Q", title="í‰ê·  ì ë„(cP)"),
                tooltip=["ìƒ‰ìƒêµ°:N", "í‰ê· ì ë„(cP):Q"],
            )
            points = base.mark_point(size=180)
            labels = base.mark_text(dx=8, dy=-8, align="left").encode(text="ë¼ë²¨:N")
            st.altair_chart((points + labels).interactive(), use_container_width=True)
    else:
        st.info("ë‹¨ì¼ìƒ‰ ë°ì´í„°ì— 'ìƒ‰ìƒêµ°' ë˜ëŠ” 'ì ë„ì¸¡ì •ê°’(cP)' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # -------------------------
    # 2) ë‹¨ì¼ìƒ‰ ì ë„ ë³€í™” ì¶”ì´ (Lotë³„)
    # -------------------------
    st.subheader("2) ë‹¨ì¼ìƒ‰ ì ë„ ë³€í™” ì¶”ì´ (Lotë³„)")
    st.caption("ì„ íƒí•œ Lotë³„ë¡œ ì…ê³ ì¼ ê¸°ì¤€ ì ë„ ë³€í™”ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. (ì  í¬ê¸°/ë¼ë²¨ ê°•í™”)")

    need_cols = ["ì…ê³ ì¼", "ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ì ë„ì¸¡ì •ê°’(cP)"]
    miss = [c for c in need_cols if c not in single_df.columns]
    if miss:
        st.warning(f"ë‹¨ì¼ìƒ‰ ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {miss}")
    else:
        df = single_df.copy()
        df["_in_dt"] = coerce_date_series(df["ì…ê³ ì¼"])
        df["_visc"] = coerce_float_series(df["ì ë„ì¸¡ì •ê°’(cP)"])

        # Lot ì •ë¦¬(ë¹ˆë¬¸ì/None ì œê±°)
        df["_lot"] = df["ë‹¨ì¼ìƒ‰ì‰í¬ Lot"].astype(str).str.strip()
        df.loc[df["_lot"].isin(["", "nan", "None", "NaN"]), "_lot"] = pd.NA

        total_n = len(df)
        valid_date_n = int(df["_in_dt"].notna().sum())
        valid_visc_n = int(df["_visc"].notna().sum())
        valid_lot_n = int(df["_lot"].notna().sum())

        df = df.dropna(subset=["_in_dt", "_visc", "_lot"]).copy()
        df = df.sort_values("_in_dt")

        if len(df) == 0:
            st.info("ì…ê³ ì¼/ì ë„ ê°’ì´ ë¹„ì–´ìˆì–´ ì¶”ì´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with st.expander("ğŸ” ë°ì´í„° ì§„ë‹¨(ì™œ ê·¸ë˜í”„ê°€ ì•ˆ ëœ¨ëŠ”ì§€ í™•ì¸)", expanded=True):
                st.write(f"- ì „ì²´ í–‰ ìˆ˜: {total_n}")
                st.write(f"- ë‚ ì§œ íŒŒì‹± ì„±ê³µ: {valid_date_n}")
                st.write(f"- ì ë„ ìˆ«ì ë³€í™˜ ì„±ê³µ: {valid_visc_n}")
                st.write(f"- Lot ê°’ ì¡´ì¬: {valid_lot_n}")
                st.write("ì•„ë˜ëŠ” ì›ë³¸ ì¼ë¶€(ìƒìœ„ 20ê±´)ì™€ íŒŒì‹± ê²°ê³¼ì…ë‹ˆë‹¤.")
                diag = single_df[need_cols].copy().head(20)
                diag["_parsed_date"] = coerce_date_series(diag["ì…ê³ ì¼"])
                diag["_parsed_visc"] = coerce_float_series(diag["ì ë„ì¸¡ì •ê°’(cP)"])
                st.dataframe(diag, use_container_width=True)
        else:
            f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.6, 2.0])
            with f1:
                dmin, dmax = safe_minmax_dates(df["_in_dt"], fallback_days=90)
                start = st.date_input("ì‹œì‘ì¼(ì¶”ì´)", value=dmin, key="trend_start")
            with f2:
                end = st.date_input("ì¢…ë£Œì¼(ì¶”ì´)", value=dmax, key="trend_end")
            with f3:
                cg = st.multiselect("ìƒ‰ìƒêµ°(ì¶”ì´)", sorted(df["ìƒ‰ìƒêµ°"].dropna().unique().tolist()), key="trend_cg") if "ìƒ‰ìƒêµ°" in df.columns else []
            with f4:
                pc = st.multiselect("ì œí’ˆì½”ë“œ(ì¶”ì´)", sorted(df["ì œí’ˆì½”ë“œ"].dropna().unique().tolist()), key="trend_pc") if "ì œí’ˆì½”ë“œ" in df.columns else []

            if start > end:
                start, end = end, start

            df = df[(df["_in_dt"].dt.date >= start) & (df["_in_dt"].dt.date <= end)]
            if cg and "ìƒ‰ìƒêµ°" in df.columns:
                df = df[df["ìƒ‰ìƒêµ°"].isin(cg)]
            if pc and "ì œí’ˆì½”ë“œ" in df.columns:
                df = df[df["ì œí’ˆì½”ë“œ"].isin(pc)]

            lot_list = sorted(df["_lot"].astype(str).unique().tolist())
            default_pick = lot_list[-5:] if len(lot_list) > 5 else lot_list
            pick = st.multiselect("í‘œì‹œí•  ë‹¨ì¼ìƒ‰ Lot(ë³µìˆ˜ ì„ íƒ)", lot_list, default=default_pick, key="trend_lots")

            if pick:
                df = df[df["_lot"].astype(str).isin(pick)]

            if len(df) == 0:
                st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                df = df.sort_values("_in_dt")
                df["ë¼ë²¨"] = df["_visc"].round(1).astype(str)

                tooltip_cols = ["_in_dt:T", "_lot:N", "_visc:Q"]
                if "ì œí’ˆì½”ë“œ" in df.columns:
                    tooltip_cols.insert(2, "ì œí’ˆì½”ë“œ:N")
                if "ìƒ‰ìƒêµ°" in df.columns:
                    tooltip_cols.insert(3, "ìƒ‰ìƒêµ°:N")
                if "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in df.columns:
                    tooltip_cols.append("ì‚¬ìš©ëœ ë°”ì¸ë” Lot:N")

                base = alt.Chart(df).encode(
                    x=alt.X("_in_dt:T", sort="ascending", title="ì…ê³ ì¼"),
                    y=alt.Y("_visc:Q", title="ì ë„(cP)"),
                    color=alt.Color("_lot:N", title="Lot"),
                    tooltip=tooltip_cols,
                )

                line = base.mark_line()
                points = base.mark_point(size=260)  # ì  ë” í¬ê²Œ
                labels = base.mark_text(dx=10, dy=-12, align="left").encode(text="ë¼ë²¨:N")

                st.altair_chart((line + points + labels).interactive(), use_container_width=True)


# =========================
# ì‰í¬ ì…ê³  (ë‹¨ì¼ìƒ‰ ì…ë ¥ë§Œ)
# =========================
with tab_ink_in:
    st.subheader("ë‹¨ì¼ìƒ‰ ì‰í¬ ì…ê³  ì…ë ¥")
    st.caption("ì´ íƒ­ì€ **ì—‘ì…€ íŒŒì¼ì— í–‰ì„ ì¶”ê°€(Append)** í•˜ì—¬ ë°ì´í„°ê°€ ëˆ„ì ë©ë‹ˆë‹¤.")

    ink_types = ["HEMA", "Silicone"]
    color_groups = sorted(spec_single["ìƒ‰ìƒêµ°"].dropna().unique().tolist())
    product_codes = sorted(spec_single["ì œí’ˆì½”ë“œ"].dropna().unique().tolist())

    binder_lots = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    binder_lots = sorted(set(binder_lots), reverse=True)

    with st.form("single_form", clear_on_submit=True):
        col1, col2, col3, col4 = st.columns([1.2, 1.3, 1.5, 2.0])
        with col1:
            in_date = st.date_input("ì…ê³ ì¼", value=dt.date.today(), key="single_in_date")
            ink_type = st.selectbox("ì‰í¬íƒ€ì…", ink_types)
            color_group = st.selectbox("ìƒ‰ìƒêµ°", color_groups)
        with col2:
            product_code = st.selectbox("ì œí’ˆì½”ë“œ", product_codes)
            binder_lot = st.selectbox("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", binder_lots)
        with col3:
            visc_meas = st.number_input("ì ë„ì¸¡ì •ê°’(cP)", min_value=0.0, step=1.0, format="%.1f")
            supplier = st.selectbox("ë°”ì¸ë”ì œì¡°ì²˜", ["ë‚´ë¶€", "ì™¸ì£¼"], index=0)
        with col4:
            st.caption("ì„ íƒ: ì°©ìƒ‰ë ¥(L*a*b*) ì…ë ¥ ì‹œ, ê¸°ì¤€LABì´ ìˆìœ¼ë©´ Î”E(76)ì„ ìë™ ê³„ì‚°í•´ ë¹„ê³ ì— ê¸°ë¡í•©ë‹ˆë‹¤.")
            L = st.number_input("ì°©ìƒ‰ë ¥_L*", value=0.0, step=0.1, format="%.2f")
            a = st.number_input("ì°©ìƒ‰ë ¥_a*", value=0.0, step=0.1, format="%.2f")
            b = st.number_input("ì°©ìƒ‰ë ¥_b*", value=0.0, step=0.1, format="%.2f")
            lab_enabled = st.checkbox("L*a*b* ì…ë ¥í•¨", value=False)

        note = st.text_input("ë¹„ê³ ", value="", key="single_note")
        submit_s = st.form_submit_button("ì €ì¥(ë‹¨ì¼ìƒ‰)")

    if submit_s:
        binder_type = infer_binder_type_from_lot(spec_binder, binder_lot)

        spec_hit = spec_single[
            (spec_single["ìƒ‰ìƒêµ°"] == color_group) &
            (spec_single["ì œí’ˆì½”ë“œ"] == product_code)
        ].copy()

        if binder_type and "BinderType" in spec_hit.columns:
            spec_hit = spec_hit[spec_hit["BinderType"] == binder_type]

        if len(spec_hit) == 0:
            lo, hi = None, None
            visc_judge = None
            st.warning("ì ë„ ê¸°ì¤€ì„ Spec_Single_H&Sì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë°”ì¸ë”íƒ€ì… ì¡°í•© í™•ì¸)")
        else:
            lo = float(spec_hit["í•˜í•œ"].iloc[0])
            hi = float(spec_hit["ìƒí•œ"].iloc[0])
            visc_judge = judge_range(visc_meas, lo, hi)

        new_lot = generate_single_lot(single_df, product_code, color_group, in_date)
        if new_lot is None:
            st.error("ë‹¨ì¼ìƒ‰ Lot ìë™ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ° ë§¤í•‘ í™•ì¸ í•„ìš”)")
        else:
            note2 = note
            if lab_enabled:
                base_hit = base_lab[base_lab.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=str)) == product_code]
                if len(base_hit) == 1:
                    base = (
                        float(base_hit.iloc[0]["ê¸°ì¤€_L*"]),
                        float(base_hit.iloc[0]["ê¸°ì¤€_a*"]),
                        float(base_hit.iloc[0]["ê¸°ì¤€_b*"])
                    )
                    de = delta_e76((L, a, b), base)
                    note2 = (note2 + " " if note2 else "") + f"[Î”E76={de:.2f}]"
                else:
                    note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"

            row = {
                "ì…ê³ ì¼": in_date,
                "ì‰í¬íƒ€ì…\n(HEMA/Silicone)": ink_type,
                "ìƒ‰ìƒêµ°": color_group,
                "ì œí’ˆì½”ë“œ": product_code,
                "ë‹¨ì¼ìƒ‰ì‰í¬ Lot": new_lot,
                "ì‚¬ìš©ëœ ë°”ì¸ë” Lot": binder_lot,
                "ë°”ì¸ë”ì œì¡°ì²˜\n(ë‚´ë¶€/ì™¸ì£¼)": supplier,
                "BinderType(ìë™)": binder_type,
                "ì ë„ì¸¡ì •ê°’(cP)": float(visc_meas),
                "ì ë„í•˜í•œ": lo,
                "ì ë„ìƒí•œ": hi,
                "ì ë„íŒì •": visc_judge,
                "ì°©ìƒ‰ë ¥_L*": float(L) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_a*": float(a) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_b*": float(b) if lab_enabled else None,
                "ë¹„ê³ ": note2,
            }

            try:
                append_row_to_sheet(xlsx_path, SHEET_SINGLE, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë‹¨ì¼ìƒ‰ Lot = {new_lot} / ì ë„íŒì • = {visc_judge}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")


# =========================
# ë°”ì¸ë” ì…ì¶œê³  + ì—…ì²´ë°˜í™˜ + (êµ¬ê¸€ì‹œíŠ¸ ë³´ê¸°)
# =========================
with tab_binder:
    st.subheader("ë°”ì¸ë” ì…ì¶œê³  / ì—…ì²´ ë°˜í™˜")
    st.caption("ë°”ì¸ë” í’ˆì§ˆ ë°ì´í„°(ì œì¡°/ì…ê³ )ì™€ ì—…ì²´ ë°˜í™˜(kg)ì„ ì´ íƒ­ì—ì„œ í•¨ê»˜ ê´€ë¦¬í•©ë‹ˆë‹¤.")

    binder_names = sorted(spec_binder["ë°”ì¸ë”ëª…"].dropna().unique().tolist())
    binder_lots_all = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    binder_lots_all = sorted(set(binder_lots_all), reverse=True)

    # (0) ì—…ì²´ ë°˜í™˜ ì…ë ¥ (ìµœìƒë‹¨)
    st.markdown("### 0) ë°”ì¸ë” ì—…ì²´ ë°˜í™˜ ì…ë ¥ (kg ë‹¨ìœ„)")
    with st.form("binder_return_form", clear_on_submit=True):
        c1, c2, c3, c4 = st.columns([1.2, 1.6, 1.6, 2.6])
        with c1:
            r_date = st.date_input("ë°˜í™˜ì¼ì", value=dt.date.today(), key="ret_date")
        with c2:
            r_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="ret_name")
        with c3:
            r_lot = st.selectbox("ê´€ë ¨ Lot(ì„ íƒ)", ["(ì„ íƒì•ˆí•¨)"] + binder_lots_all, key="ret_lot")
        with c4:
            r_kg = st.number_input("ë°˜í™˜ëŸ‰(kg)", min_value=0.0, step=0.1, format="%.1f", key="ret_kg")

        r_note = st.text_input("ë¹„ê³ (ì„ íƒ)", value="", key="ret_note")
        ret_submit = st.form_submit_button("ì €ì¥(ì—…ì²´ë°˜í™˜)", type="primary")

    if ret_submit:
        if r_kg <= 0:
            st.warning("ë°˜í™˜ëŸ‰(kg)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        else:
            row = {
                "ë°˜í™˜ì¼ì": r_date,
                "ë°”ì¸ë”ëª…": r_name,
                "ê´€ë ¨ Lot(ì„ íƒ)": "" if r_lot == "(ì„ íƒì•ˆí•¨)" else r_lot,
                "ë°˜í™˜ëŸ‰(kg)": float(r_kg),
                "ë¹„ê³ ": r_note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER_RETURN, row)
                st.success("ì—…ì²´ ë°˜í™˜ ì…ë ¥ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    with st.expander("ì—…ì²´ ë°˜í™˜ ë‚´ì—­ ë³´ê¸°", expanded=True):
        if len(binder_return_df):
            tmp = binder_return_df.copy()
            tmp["_d"] = pd.to_datetime(tmp.get("ë°˜í™˜ì¼ì"), errors="coerce")
            tmp = tmp.sort_values("_d", ascending=False).drop(columns=["_d"])
            st.dataframe(tmp, use_container_width=True, hide_index=True)
        else:
            st.info("ì—…ì²´ ë°˜í™˜ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # (2) Google Sheets ë³´ê¸°
    st.markdown("### 1) ë°”ì¸ë” ì…ì¶œê³  (Google Sheets ìë™ ë°˜ì˜)")
    st.caption("êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´, ì´ í™”ë©´ì€ ìƒˆë¡œê³ ì¹¨ ì‹œ ìë™ìœ¼ë¡œ ìµœì‹  ê°’ì´ ë°˜ì˜ë©ë‹ˆë‹¤. (ìºì‹œ 60ì´ˆ)")

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
        df_hema = sort_df_by_any_date_col(df_hema)
        df_sil = sort_df_by_any_date_col(df_sil)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ëª» ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.exception(e)
        st.stop()

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### HEMA (ìµœì‹ ìˆœ)")
        st.dataframe(df_hema, use_container_width=True, hide_index=True)
    with c2:
        st.markdown("#### Silicon (ìµœì‹ ìˆœ)")
        st.dataframe(df_sil, use_container_width=True, hide_index=True)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key="binder_refresh"):
        st.cache_data.clear()
        st.rerun()


# =========================
# Search
# =========================
with tab_search:
    c1, c2, c3 = st.columns([2, 2, 3])
    with c1:
        mode = st.selectbox("ê²€ìƒ‰ ì¢…ë¥˜", ["ë°”ì¸ë” Lot", "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°", "ê¸°ê°„(ì…ê³ ì¼)"])
    with c2:
        q = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: PCB20250112-01 / PLB25041501 / PL-835-1 ...")
    with c3:
        st.write("")
        st.caption("ğŸ’¡ ë°”ì¸ë” Lotë¡œ ê²€ìƒ‰í•˜ë©´: ë°”ì¸ë” ì •ë³´ + í•´ë‹¹ ë°”ì¸ë”ë¥¼ ì‚¬ìš©í•œ ë‹¨ì¼ìƒ‰ ì‰í¬ ëª©ë¡ì„ ê°™ì´ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    if mode == "ê¸°ê°„(ì…ê³ ì¼)":
        d1, d2 = st.columns(2)
        with d1:
            start = st.date_input("ì‹œì‘ì¼", value=dt.date.today() - dt.timedelta(days=30), key="search_start")
        with d2:
            end = st.date_input("ì¢…ë£Œì¼", value=dt.date.today(), key="search_end")
        df = single_df.copy()
        if "ì…ê³ ì¼" in df.columns:
            df["_in_dt"] = coerce_date_series(df["ì…ê³ ì¼"])
            df = df.dropna(subset=["_in_dt"])
            df = df[df["_in_dt"].dt.date.between(start, end)]
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        st.dataframe(df.sort_values("_in_dt", ascending=False) if "_in_dt" in df.columns else df, use_container_width=True)

    elif mode == "ë°”ì¸ë” Lot":
        b = binder_df.copy()
        b_hit = df_quick_filter(b, q, ["Lot(ìë™)", "ë°”ì¸ë”ëª…", "ë¹„ê³ "])
        st.subheader("ë°”ì¸ë”_ì œì¡°_ì…ê³ ")
        if "ì œì¡°/ì…ê³ ì¼" in b_hit.columns:
            st.dataframe(b_hit.sort_values(by="ì œì¡°/ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(b_hit, use_container_width=True)

        if q and "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in single_df.columns:
            s_hit = single_df[single_df["ì‚¬ìš©ëœ ë°”ì¸ë” Lot"].astype(str).str.contains(str(q).strip(), case=False, na=False)]
            st.subheader("ì—°ê²°ëœ ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ (ì‚¬ìš©ëœ ë°”ì¸ë” Lot)")
            if "ì…ê³ ì¼" in s_hit.columns:
                st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
            else:
                st.dataframe(s_hit, use_container_width=True)

    elif mode == "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ìƒ‰ìƒêµ°", "ë¹„ê³ "])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)

    elif mode == "ì œí’ˆì½”ë“œ":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ì œí’ˆì½”ë“œ"])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)

    elif mode == "ìƒ‰ìƒêµ°":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ìƒ‰ìƒêµ°"])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)
