import altair as alt
import streamlit as st
import pandas as pd
import datetime as dt
import re
from pathlib import Path
from openpyxl import load_workbook
import requests
from io import StringIO

# =========================
# Page Config (ë”± 1ë²ˆë§Œ)
# =========================
st.set_page_config(
    page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬",
    page_icon="ğŸ§ª",
    layout="wide",
)

# =========================
# Google Sheets (Public) Reader
# =========================
@st.cache_data(ttl=60, show_spinner=False)
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))

# =========================
# Config
# =========================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"

# ìƒˆë¡œ ì¶”ê°€(ì—†ìœ¼ë©´ ìë™ ìƒì„±)
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"  # kg ë‹¨ìœ„ ë°˜í™˜ ê¸°ë¡

COLOR_CODE = {
    "Black": "B",
    "White": "W",
    "Blue": "U",
    "Green": "G",
    "Yellow": "Y",
    "Red": "R",
    "Pink": "P",
}

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"

# =========================
# Helpers
# =========================
def norm_key(x) -> str:
    if x is None:
        return ""
    s = str(x)
    s = s.replace("\n", " ").replace("\r", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def safe_to_float(x):
    if x is None:
        return None
    if isinstance(x, float) and pd.isna(x):
        return None
    if isinstance(x, str):
        if x.strip() == "":
            return None
        x = x.replace(",", "")
    try:
        return float(x)
    except Exception:
        return None

def normalize_date(x):
    if x is None:
        return None
    if isinstance(x, float) and pd.isna(x):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        return pd.to_datetime(x, errors="coerce").date()
    except Exception:
        return None

def safe_date_bounds(s: pd.Series):
    s2 = pd.to_datetime(s, errors="coerce").dropna()
    if len(s2) == 0:
        today = dt.date.today()
        return today, today
    return s2.min().date(), s2.max().date()

def delta_e76(lab1, lab2):
    return float(((lab1[0]-lab2[0])**2 + (lab1[1]-lab2[1])**2 + (lab1[2]-lab2[2])**2) ** 0.5)

def judge_range(value, lo, hi):
    v = safe_to_float(value)
    if v is None:
        return None
    if lo is not None and v < float(lo):
        return "ë¶€ì í•©"
    if hi is not None and v > float(hi):
        return "ë¶€ì í•©"
    return "ì í•©"

def ensure_sheet_exists(xlsx_path: str, sheet_name: str, headers: list[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        try:
            wb.calculation.calcMode = "auto"
            wb.calculation.fullCalcOnLoad = True
        except Exception:
            pass
        wb.save(xlsx_path)

def _read_excel_from_path(xlsx_path: str) -> dict[str, pd.DataFrame]:
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)
    return {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "base_lab": read(SHEET_BASE_LAB),
    }

@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> dict[str, pd.DataFrame]:
    return _read_excel_from_path(xlsx_path)

def set_excel_recalc_on_open(wb):
    # openpyxlë¡œ ì €ì¥í•˜ë©´ ìˆ˜ì‹ ìºì‹œê°’ì´ ë‚ ì•„ê°€ Streamlit(pandas)ì´ Noneìœ¼ë¡œ ì½ëŠ” ê²½ìš°ê°€ ë§ì•„ì„œ,
    # Excelì—ì„œ íŒŒì¼ ì—´ ë•Œ ìë™ ì¬ê³„ì‚°ë˜ë„ë¡ ì„¤ì •
    try:
        wb.calculation.calcMode = "auto"
        wb.calculation.fullCalcOnLoad = True
    except Exception:
        pass

def append_row_to_sheet(xlsx_path: str, sheet_name: str, row_by_normkey: dict):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]

    values = []
    for h in headers:
        nk = norm_key(h)
        values.append(row_by_normkey.get(nk, None))
    ws.append(values)

    set_excel_recalc_on_open(wb)
    wb.save(xlsx_path)

def append_rows_to_sheet(xlsx_path: str, sheet_name: str, rows_by_normkey: list[dict]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    norm_headers = [norm_key(h) for h in headers]

    for row in rows_by_normkey:
        ws.append([row.get(nh, None) for nh in norm_headers])

    set_excel_recalc_on_open(wb)
    wb.save(xlsx_path)

def detect_date_col(df: pd.DataFrame):
    # êµ¬ê¸€ì‹œíŠ¸ ì»¬ëŸ¼ëª… ë‹¤ì–‘ì„± ëŒ€ì‘
    for c in df.columns:
        ck = norm_key(c)
        if any(k in ck for k in ["ì¼ì", "ë‚ ì§œ", "date", "ì…ê³ ì¼", "ì¶œê³ ì¼"]):
            return c
    return None

# ===== Spec Helpers =====
def get_binder_limits(spec_binder: pd.DataFrame, binder_name: str):
    df = spec_binder[spec_binder["ë°”ì¸ë”ëª…"] == binder_name].copy()
    visc = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("ì ë„", na=False)]
    uv = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("UV", na=False)]

    visc_lo = safe_to_float(visc["í•˜í•œ"].dropna().iloc[0]) if len(visc["í•˜í•œ"].dropna()) else None
    visc_hi = safe_to_float(visc["ìƒí•œ"].dropna().iloc[0]) if len(visc["ìƒí•œ"].dropna()) else None
    uv_hi = safe_to_float(uv["ìƒí•œ"].dropna().iloc[0]) if len(uv["ìƒí•œ"].dropna()) else None
    rule = df["Lotë¶€ì—¬ê·œì¹™"].dropna().iloc[0] if "Lotë¶€ì—¬ê·œì¹™" in df.columns and len(df["Lotë¶€ì—¬ê·œì¹™"].dropna()) else None
    return visc_lo, visc_hi, uv_hi, rule

def infer_binder_type_from_lot(spec_binder: pd.DataFrame, binder_lot: str):
    # "Lotë¶€ì—¬ê·œì¹™"ì˜ prefixë¡œ ë°”ì¸ë”ëª…(BinderType)ì„ ì—­ì¶”ë¡ 
    if not binder_lot or (isinstance(binder_lot, float) and pd.isna(binder_lot)):
        return None
    binder_lot = str(binder_lot).strip()
    rules = (
        spec_binder[["ë°”ì¸ë”ëª…", "Lotë¶€ì—¬ê·œì¹™"]]
        .dropna()
        .drop_duplicates()
        .to_dict("records")
    )
    for r in rules:
        rule = str(r["Lotë¶€ì—¬ê·œì¹™"]).strip()
        m = re.match(r"^([A-Za-z0-9]+)\+", rule)
        if m:
            prefix = m.group(1)
            if binder_lot.startswith(prefix):
                return r["ë°”ì¸ë”ëª…"]
    return None

def next_seq_for_pattern(existing_lots: list[str], prefix: str, date_str: str, sep: str = "-"):
    seqs = []
    for lot in existing_lots:
        lot = str(lot).strip()
        if not lot.startswith(prefix + date_str):
            continue
        rest = lot[len(prefix + date_str):]
        if sep and rest.startswith(sep):
            rest = rest[len(sep):]
        m = re.match(r"^(\d+)", rest)
        if m:
            try:
                seqs.append(int(m.group(1)))
            except Exception:
                pass
    return (max(seqs) + 1) if seqs else 1

def generate_binder_lot(spec_binder: pd.DataFrame, binder_name: str, mfg_date: dt.date, existing_binder_lots: list[str]):
    _, _, _, rule = get_binder_limits(spec_binder, binder_name)
    if not rule:
        code = re.sub(r"\W+", "", binder_name)[:6].upper()
        return f"{code}{mfg_date.strftime('%Y%m%d')}-01"

    m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip())
    if not m:
        code = re.sub(r"\W+", "", binder_name)[:6].upper()
        return f"{code}{mfg_date.strftime('%Y%m%d')}-01"

    prefix = m.group(1)
    has_seq = bool(m.group(2))
    date_str = mfg_date.strftime("%Y%m%d")
    if has_seq:
        seq = next_seq_for_pattern(existing_binder_lots, prefix, date_str, sep="-")
        return f"{prefix}{date_str}-{seq:02d}"
    return f"{prefix}{date_str}"

def lot_prefix_from_single(product_code: str, color_group: str, in_date: dt.date):
    pc = (product_code or "").strip()
    cc = COLOR_CODE.get(color_group)
    if not cc or not in_date:
        return None
    if pc.startswith("NPL"):
        prefix = "NPL"
    elif pc.startswith("PL"):
        prefix = "PL"
    elif pc.startswith("SL") or pc.startswith("NSL"):
        prefix = "SL"
    else:
        prefix = "PL"
    date_str = in_date.strftime("%y%m%d")
    return f"{prefix}{cc}{date_str}"

def fill_missing_single_lots(df_single: pd.DataFrame) -> pd.Series:
    """
    ë‹¨ì¼ìƒ‰ì‰í¬ Lotì´ ìˆ˜ì‹/ìºì‹œ ë¬¸ì œë¡œ Noneìœ¼ë¡œ ì½íˆëŠ” ê²½ìš°,
    ì•±ì—ì„œ ë‹¤ì‹œ lotì„ ë³µì›(ì¶”ì´ ê·¸ë˜í”„/ê²€ìƒ‰ ì •ìƒí™”)
    """
    s = df_single.copy()
    # í•„ìš”í•œ ì»¬ëŸ¼
    if not all(c in s.columns for c in ["ì…ê³ ì¼", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°", "ë‹¨ì¼ìƒ‰ì‰í¬ Lot"]):
        return s.get("ë‹¨ì¼ìƒ‰ì‰í¬ Lot", pd.Series([None]*len(s), index=s.index))

    s["_in_date"] = pd.to_datetime(s["ì…ê³ ì¼"], errors="coerce").dt.date
    s["_lot_raw"] = s["ë‹¨ì¼ìƒ‰ì‰í¬ Lot"].astype(str)
    s["_lot_raw"] = s["_lot_raw"].replace(["nan", "None", "NaT"], "").str.strip()

    # ê¸°ì¡´ lotì—ì„œ prefixë³„ max seq ì¶”ì¶œ
    max_seq = {}
    patt = re.compile(r"^(NPL|PL|SL)([BWUGYRP])(\d{6})(\d{2,})$")
    for lot in s["_lot_raw"]:
        if not lot:
            continue
        m = patt.match(lot)
        if not m:
            continue
        pfx = f"{m.group(1)}{m.group(2)}{m.group(3)}"
        seq = int(m.group(4))
        max_seq[pfx] = max(max_seq.get(pfx, 0), seq)

    # ê²°ì¸¡ lot ì±„ìš°ê¸°(ë‚ ì§œâ†’ì›ë³¸ìˆœ)
    out = s["_lot_raw"].copy()
    for idx, row in s.sort_values(by=["_in_date"]).iterrows():
        if out.loc[idx]:
            continue
        in_date = row["_in_date"]
        pfx = lot_prefix_from_single(str(row.get("ì œí’ˆì½”ë“œ", "")).strip(), str(row.get("ìƒ‰ìƒêµ°", "")).strip(), in_date)
        if not pfx:
            continue
        next_seq = max_seq.get(pfx, 0) + 1
        max_seq[pfx] = next_seq
        out.loc[idx] = f"{pfx}{next_seq:02d}"
    return out

def compute_single_derived(df_single: pd.DataFrame, spec_binder: pd.DataFrame, spec_single: pd.DataFrame, base_lab: pd.DataFrame) -> pd.DataFrame:
    """
    Streamlitì—ì„œ Noneìœ¼ë¡œ ì½íˆëŠ”(=ì—‘ì…€ ìˆ˜ì‹ ìºì‹œ ë¬¸ì œ) ì»¬ëŸ¼ë“¤ì„ ì•±ì—ì„œ ì•ˆì „í•˜ê²Œ ì¬ê³„ì‚°:
    - BinderType(ìë™)
    - ì ë„í•˜í•œ/ì ë„ìƒí•œ/ì ë„íŒì •
    - ë‹¨ì¼ìƒ‰ì‰í¬ Lot (ì—†ìœ¼ë©´ ë³µì›)
    - Î”E76(ê°€ëŠ¥í•˜ë©´)
    """
    s = df_single.copy()

    # ë‚ ì§œ/ì ë„ íŒŒì‹±
    if "ì…ê³ ì¼" in s.columns:
        s["_ì…ê³ ì¼_dt"] = pd.to_datetime(s["ì…ê³ ì¼"], errors="coerce")
    else:
        s["_ì…ê³ ì¼_dt"] = pd.NaT

    if "ì ë„ì¸¡ì •ê°’(cP)" in s.columns:
        s["_ì ë„"] = pd.to_numeric(s["ì ë„ì¸¡ì •ê°’(cP)"].astype(str).str.replace(",", "", regex=False), errors="coerce")
    else:
        s["_ì ë„"] = pd.NA

    # Lot ë³µì›(ì—†ìœ¼ë©´)
    if "ë‹¨ì¼ìƒ‰ì‰í¬ Lot" in s.columns:
        fixed_lot = fill_missing_single_lots(s)
        s["_Lot_fix"] = fixed_lot
    else:
        s["_Lot_fix"] = ""

    # BinderType(ìë™) ë³´ì •
    if "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in s.columns:
        s["_BinderLot"] = s["ì‚¬ìš©ëœ ë°”ì¸ë” Lot"].astype(str).replace(["nan", "None"], "").str.strip()
    else:
        s["_BinderLot"] = ""

    def _infer_bt(x):
        bt = infer_binder_type_from_lot(spec_binder, x)
        return bt

    s["_BinderType_fix"] = s.get("BinderType(ìë™)", pd.Series([None]*len(s), index=s.index))
    # ê°’ì´ None/NaNì¸ ê³³ë§Œ ì±„ìš°ê¸°
    mask_bt = s["_BinderType_fix"].isna() | (s["_BinderType_fix"].astype(str).str.strip().isin(["", "None", "nan"]))
    s.loc[mask_bt, "_BinderType_fix"] = s.loc[mask_bt, "_BinderLot"].apply(_infer_bt)

    # ì ë„ ê¸°ì¤€(í•˜í•œ/ìƒí•œ/íŒì •) ë³´ì •
    # spec_single: ìƒ‰ìƒêµ°, ì œí’ˆì½”ë“œ, í•˜í•œ, ìƒí•œ, BinderType
    for c in ["ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ"]:
        if c in s.columns:
            s[c] = s[c].astype(str).str.strip()

    spec_single2 = spec_single.copy()
    for c in ["ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ", "BinderType"]:
        if c in spec_single2.columns:
            spec_single2[c] = spec_single2[c].astype(str).str.strip()

    def _lookup_limits(row):
        cg = row.get("ìƒ‰ìƒêµ°", "")
        pc = row.get("ì œí’ˆì½”ë“œ", "")
        bt = row.get("_BinderType_fix", None)
        if not cg or not pc:
            return None, None
        hit = spec_single2[(spec_single2["ìƒ‰ìƒêµ°"] == cg) & (spec_single2["ì œí’ˆì½”ë“œ"] == pc)].copy()
        if bt and "BinderType" in hit.columns and len(hit["BinderType"].dropna()):
            hit2 = hit[hit["BinderType"] == str(bt).strip()]
            if len(hit2) > 0:
                hit = hit2
        if len(hit) == 0:
            return None, None
        lo = safe_to_float(hit.iloc[0].get("í•˜í•œ", None))
        hi = safe_to_float(hit.iloc[0].get("ìƒí•œ", None))
        return lo, hi

    s["_ì ë„í•˜í•œ_fix"] = s.get("ì ë„í•˜í•œ", pd.Series([None]*len(s), index=s.index))
    s["_ì ë„ìƒí•œ_fix"] = s.get("ì ë„ìƒí•œ", pd.Series([None]*len(s), index=s.index))
    s["_ì ë„íŒì •_fix"] = s.get("ì ë„íŒì •", pd.Series([None]*len(s), index=s.index))

    for idx, row in s.iterrows():
        # í•˜í•œ/ìƒí•œ/íŒì •ì´ ì´ë¯¸ ìˆ«ì/ê°’ìœ¼ë¡œ ìˆìœ¼ë©´ ì¡´ì¤‘
        lo0 = safe_to_float(row.get("_ì ë„í•˜í•œ_fix", None))
        hi0 = safe_to_float(row.get("_ì ë„ìƒí•œ_fix", None))
        judge0 = str(row.get("_ì ë„íŒì •_fix", "")).strip()
        need = (lo0 is None and hi0 is None) or (judge0 in ["", "None", "nan"])
        if not need:
            continue

        lo, hi = _lookup_limits(row)
        if lo0 is None:
            s.at[idx, "_ì ë„í•˜í•œ_fix"] = lo
        if hi0 is None:
            s.at[idx, "_ì ë„ìƒí•œ_fix"] = hi

        visc = row.get("_ì ë„", None)
        s.at[idx, "_ì ë„íŒì •_fix"] = judge_range(visc, lo, hi)

    # Î”E76(ê°€ëŠ¥í•˜ë©´)
    s["_Î”E76_fix"] = None
    if "ì œí’ˆì½”ë“œ" in base_lab.columns:
        base2 = base_lab.copy()
        base2["ì œí’ˆì½”ë“œ"] = base2["ì œí’ˆì½”ë“œ"].astype(str).str.strip()
        base_map = {}
        if all(c in base2.columns for c in ["ê¸°ì¤€_L*", "ê¸°ì¤€_a*", "ê¸°ì¤€_b*"]):
            for _, r in base2.iterrows():
                pc = str(r.get("ì œí’ˆì½”ë“œ", "")).strip()
                if not pc:
                    continue
                base_map[pc] = (safe_to_float(r.get("ê¸°ì¤€_L*", None)),
                                safe_to_float(r.get("ê¸°ì¤€_a*", None)),
                                safe_to_float(r.get("ê¸°ì¤€_b*", None)))

        if all(c in s.columns for c in ["ì°©ìƒ‰ë ¥_L*", "ì°©ìƒ‰ë ¥_a*", "ì°©ìƒ‰ë ¥_b*"]):
            for idx, row in s.iterrows():
                pc = str(row.get("ì œí’ˆì½”ë“œ", "")).strip()
                if pc not in base_map:
                    continue
                ref = base_map[pc]
                if None in ref:
                    continue
                L = safe_to_float(row.get("ì°©ìƒ‰ë ¥_L*", None))
                a = safe_to_float(row.get("ì°©ìƒ‰ë ¥_a*", None))
                b = safe_to_float(row.get("ì°©ìƒ‰ë ¥_b*", None))
                if None in (L, a, b):
                    continue
                s.at[idx, "_Î”E76_fix"] = delta_e76((L, a, b), ref)

    return s

# =========================
# UI Header
# =========================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("âœ… ë¹ ë¥¸ ê²€ìƒ‰  |  âœ… ì‰í¬ ì…ê³ (ì—‘ì…€ ëˆ„ì )  |  âœ… ëŒ€ì‹œë³´ë“œ(ëª©ë¡/í‰ê· /ì¶”ì´)  |  âœ… ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸ ìë™ ë°˜ì˜)")

# =========================
# Data file selection (Excel)
# =========================
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼")
    xlsx_path = st.text_input(
        "ì—‘ì…€ íŒŒì¼ ê²½ë¡œ",
        value=DEFAULT_XLSX,
        help="ë¡œì»¬ ì‹¤í–‰ ì‹œ, app.pyì™€ ê°™ì€ í´ë”ì— ì—‘ì…€ì„ ë‘ë©´ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(ì—…ë¡œë“œ ëª¨ë“œ: ì„œë²„ ì €ì¥ ë³´ì¥ X)", type=["xlsx"])

# âœ… ì—…ë¡œë“œ íŒŒì¼ì€ 'ì²˜ìŒ 1íšŒë§Œ' tmpë¡œ ë³µì‚¬ (ì €ì¥í•œ ë‚´ìš©ì´ rerun ë•Œ ë®ì–´ì¨ì§€ëŠ” ë¬¸ì œ ë°©ì§€)
if uploaded is not None:
    upload_sig = f"{uploaded.name}:{uploaded.size}"
    if st.session_state.get("_uploaded_sig") != upload_sig:
        tmp_path = Path(".streamlit_tmp.xlsx")
        tmp_path.write_bytes(uploaded.getvalue())
        st.session_state["_uploaded_sig"] = upload_sig
        st.session_state["_tmp_xlsx_path"] = str(tmp_path)
    xlsx_path = st.session_state.get("_tmp_xlsx_path", xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì´ ëª¨ë“œì—ì„œëŠ” ì„œë²„ ì¬ì‹œì‘ ì‹œ ëˆ„ì  ë³´ì¥ì´ ì–´ë µìŠµë‹ˆë‹¤.)")

if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.stop()

# ì—…ì²´ë°˜í™˜ ì‹œíŠ¸ ì—†ìœ¼ë©´ ìƒì„±
ensure_sheet_exists(
    xlsx_path,
    SHEET_BINDER_RETURN,
    headers=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "]
)

# íŒŒì¼ ì‹œê·¸ë‹ˆì²˜(ìœ„ì ¯ key ì¶©ëŒ ë°©ì§€)
file_sig = f"{Path(xlsx_path).name}:{Path(xlsx_path).stat().st_mtime_ns}"

# Load
raw = load_data(xlsx_path)
binder_df = raw["binder"].copy()
single_df_raw = raw["single"].copy()
spec_binder = raw["spec_binder"].copy()
spec_single = raw["spec_single"].copy()
base_lab = raw["base_lab"].copy()

# ë‹¨ì¼ìƒ‰ íŒŒìƒ/ë³´ì •(ì¤‘ìš”!)
single_df = compute_single_derived(single_df_raw, spec_binder, spec_single, base_lab)

# =========================
# Tabs
# =========================
tab_dash, tab_ink_in, tab_binder, tab_search = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "âœï¸ ì‰í¬ ì…ê³ ", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰"]
)

# =========================
# Dashboard (ê·¸ë˜í”„/í‘œëŠ” ì—¬ê¸°ë§Œ)
# =========================
with tab_dash:
    # KPI(ê°„ë‹¨)
    b_total = len(binder_df)
    s_total = len(single_df)
    b_ng = int((binder_df.get("íŒì •", pd.Series(dtype=str)) == "ë¶€ì í•©").sum()) if "íŒì •" in binder_df.columns else 0
    s_ng = int((single_df.get("_ì ë„íŒì •_fix", pd.Series(dtype=str)) == "ë¶€ì í•©").sum())

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ë°”ì¸ë” ê¸°ë¡", f"{b_total:,}")
    c2.metric("ë°”ì¸ë” ë¶€ì í•©", f"{b_ng:,}")
    c3.metric("ë‹¨ì¼ìƒ‰ ê¸°ë¡", f"{s_total:,}")
    c4.metric("ë‹¨ì¼ìƒ‰(ì ë„) ë¶€ì í•©", f"{s_ng:,}")

    st.divider()

    # ---- 1) ëª©ë¡(ì—‘ì…€í˜•)
    st.subheader("1) ë‹¨ì¼ìƒ‰ ë°ì´í„° ëª©ë¡ (ì—‘ì…€í˜• ë³´ê¸°)")
    need_cols = ["_ì…ê³ ì¼_dt", "ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ", "ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "_ì ë„"]
    miss = [c for c in need_cols if c not in single_df.columns]
    if miss:
        st.warning(f"ë‹¨ì¼ìƒ‰ ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {miss}")
    else:
        dmin, dmax = safe_date_bounds(single_df["_ì…ê³ ì¼_dt"])
        f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.6, 2.0])
        with f1:
            start = st.date_input("ì‹œì‘ì¼(ëª©ë¡)", value=max(dmin, dmax - dt.timedelta(days=90)), key=f"list_start_{file_sig}")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼(ëª©ë¡)", value=dmax, key=f"list_end_{file_sig}")
        with f3:
            cg_opts = sorted([x for x in single_df["ìƒ‰ìƒêµ°"].dropna().unique().tolist()])
            cg = st.multiselect("ìƒ‰ìƒêµ°(ëª©ë¡)", cg_opts, key=f"list_cg_{file_sig}")
        with f4:
            pc_opts = sorted([x for x in single_df["ì œí’ˆì½”ë“œ"].dropna().unique().tolist()])
            pc = st.multiselect("ì œí’ˆì½”ë“œ(ëª©ë¡)", pc_opts, key=f"list_pc_{file_sig}")

        if start > end:
            start, end = end, start

        df_list = single_df.copy()
        df_list = df_list[(df_list["_ì…ê³ ì¼_dt"].dt.date >= start) & (df_list["_ì…ê³ ì¼_dt"].dt.date <= end)]
        if cg:
            df_list = df_list[df_list["ìƒ‰ìƒêµ°"].isin(cg)]
        if pc:
            df_list = df_list[df_list["ì œí’ˆì½”ë“œ"].isin(pc)]

        view = pd.DataFrame({
            "ì œì¡°ì¼ì": df_list["_ì…ê³ ì¼_dt"].dt.date,
            "ìƒ‰ìƒêµ°": df_list["ìƒ‰ìƒêµ°"],
            "ì œí’ˆì½”ë“œ": df_list["ì œí’ˆì½”ë“œ"],
            "ì‚¬ìš©ëœë°”ì¸ë”": df_list.get("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", ""),
            "BinderType": df_list["_BinderType_fix"],
            "ë‹¨ì¼ìƒ‰Lot": df_list["_Lot_fix"],
            "ì ë„(cP)": df_list["_ì ë„"],
            "ì ë„íŒì •": df_list["_ì ë„íŒì •_fix"],
            "ìƒ‰ì°¨(Î”E76)": df_list["_Î”E76_fix"],
        }).sort_values(by="ì œì¡°ì¼ì", ascending=False)

        st.dataframe(view, use_container_width=True, height=340)

        st.divider()

        # ---- 1-1) í‰ê·  ì ë„(ì  + ê°’)
        st.subheader("1-1) ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì  + ê°’ í‘œì‹œ)")
        mean_df = (
            view.dropna(subset=["ìƒ‰ìƒêµ°", "ì ë„(cP)"])
            .groupby("ìƒ‰ìƒêµ°", as_index=False)["ì ë„(cP)"]
            .mean()
            .rename(columns={"ì ë„(cP)": "í‰ê· ì ë„(cP)"})
        )
        if len(mean_df) == 0:
            st.info("í‘œì‹œí•  í‰ê·  ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            mean_df["í‘œì‹œ"] = mean_df["í‰ê· ì ë„(cP)"].round(0).astype("Int64").astype(str)

            base = alt.Chart(mean_df).encode(
                x=alt.X("ìƒ‰ìƒêµ°:N", sort=sorted(mean_df["ìƒ‰ìƒêµ°"].unique().tolist()), title="ìƒ‰ìƒêµ°"),
                y=alt.Y("í‰ê· ì ë„(cP):Q", title="í‰ê·  ì ë„(cP)"),
                tooltip=["ìƒ‰ìƒêµ°:N", "í‰ê· ì ë„(cP):Q"],
            )
            points = base.mark_circle(size=260)
            labels = base.mark_text(dx=12, dy=-10).encode(text="í‘œì‹œ:N")
            st.altair_chart((points + labels).interactive(), use_container_width=True)

    st.divider()

    # ---- 2) ì¶”ì´ ê·¸ë˜í”„(Lotë³„)
    st.subheader("2) ë‹¨ì¼ìƒ‰ ì ë„ ë³€í™” ì¶”ì´ (Lotë³„)")
    st.caption("Lot ê°’ì´ ì—‘ì…€ ìˆ˜ì‹/ìºì‹œ ë¬¸ì œë¡œ Noneìœ¼ë¡œ ì½í˜€ë„, ì•±ì´ ìë™ ë³µì›í•´ì„œ ê·¸ë˜í”„ê°€ ì •ìƒ í‘œì‹œë©ë‹ˆë‹¤.")

    df_tr = single_df.copy()
    df_tr = df_tr.dropna(subset=["_ì…ê³ ì¼_dt", "_ì ë„"])
    df_tr["Lot"] = df_tr["_Lot_fix"].astype(str).replace(["nan", "None"], "").str.strip()
    df_tr = df_tr[df_tr["Lot"] != ""]

    if len(df_tr) == 0:
        st.info("ì…ê³ ì¼/ì ë„/Lot ê°’ì´ ë¹„ì–´ìˆì–´ ì¶”ì´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        dmin, dmax = safe_date_bounds(df_tr["_ì…ê³ ì¼_dt"])
        f1, f2, f3, f4, f5 = st.columns([1.2, 1.2, 1.6, 2.0, 1.0])
        with f1:
            start = st.date_input("ì‹œì‘ì¼(ì¶”ì´)", value=max(dmin, dmax - dt.timedelta(days=90)), key=f"trend_start_{file_sig}")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼(ì¶”ì´)", value=dmax, key=f"trend_end_{file_sig}")
        with f3:
            cg_opts = sorted([x for x in df_tr.get("ìƒ‰ìƒêµ°", pd.Series(dtype=object)).dropna().unique().tolist()]) if "ìƒ‰ìƒêµ°" in df_tr.columns else []
            cg = st.multiselect("ìƒ‰ìƒêµ°(ì¶”ì´)", cg_opts, key=f"trend_cg_{file_sig}")
        with f4:
            pc_opts = sorted([x for x in df_tr.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=object)).dropna().unique().tolist()]) if "ì œí’ˆì½”ë“œ" in df_tr.columns else []
            pc = st.multiselect("ì œí’ˆì½”ë“œ(ì¶”ì´)", pc_opts, key=f"trend_pc_{file_sig}")
        with f5:
            show_labels = st.checkbox("ë¼ë²¨ í‘œì‹œ", value=True, key=f"trend_labels_{file_sig}")

        if start > end:
            start, end = end, start

        df_tr = df_tr[(df_tr["_ì…ê³ ì¼_dt"].dt.date >= start) & (df_tr["_ì…ê³ ì¼_dt"].dt.date <= end)]
        if cg and "ìƒ‰ìƒêµ°" in df_tr.columns:
            df_tr = df_tr[df_tr["ìƒ‰ìƒêµ°"].isin(cg)]
        if pc and "ì œí’ˆì½”ë“œ" in df_tr.columns:
            df_tr = df_tr[df_tr["ì œí’ˆì½”ë“œ"].isin(pc)]

        lot_list = sorted(df_tr["Lot"].dropna().unique().tolist())
        default_pick = lot_list[-5:] if len(lot_list) > 5 else lot_list
        pick = st.multiselect("í‘œì‹œí•  ë‹¨ì¼ìƒ‰ Lot(ë³µìˆ˜ ì„ íƒ)", lot_list, default=default_pick, key=f"trend_lots_{file_sig}")
        if pick:
            df_tr = df_tr[df_tr["Lot"].isin(pick)]

        if len(df_tr) == 0:
            st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„/ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë¡œíŠ¸ í•„í„° í™•ì¸)")
        else:
            df_tr = df_tr.sort_values("_ì…ê³ ì¼_dt")
            df_tr["ì ë„í‘œì‹œ"] = df_tr["_ì ë„"].round(0).astype("Int64").astype(str)

            tooltip_cols = ["_ì…ê³ ì¼_dt:T", "Lot:N", "_ì ë„:Q"]
            if "ì œí’ˆì½”ë“œ" in df_tr.columns:
                tooltip_cols.insert(2, "ì œí’ˆì½”ë“œ:N")
            if "ìƒ‰ìƒêµ°" in df_tr.columns:
                tooltip_cols.insert(3, "ìƒ‰ìƒêµ°:N")
            if "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in df_tr.columns:
                tooltip_cols.append("ì‚¬ìš©ëœ ë°”ì¸ë” Lot:N")

            base = alt.Chart(df_tr).encode(
                x=alt.X("_ì…ê³ ì¼_dt:T", title="ì…ê³ ì¼"),
                y=alt.Y("_ì ë„:Q", title="ì ë„(cP)"),
                tooltip=tooltip_cols
            )
            line = base.mark_line()
            points = base.mark_point(size=260).encode(color=alt.Color("Lot:N", title="Lot"))
            if show_labels:
                labels = base.mark_text(dy=-12).encode(
                    color=alt.Color("Lot:N", legend=None),
                    text="ì ë„í‘œì‹œ:N"
                )
                chart = (line + points + labels).interactive()
            else:
                chart = (line + points).interactive()

            st.altair_chart(chart, use_container_width=True)

    st.divider()

    st.subheader("ìµœê·¼ 20ê±´ (ë‹¨ì¼ìƒ‰) â€” Lot/íŒì • ë³´ì •ê°’ í¬í•¨")
    show = single_df.copy()
    show = show.sort_values(by="_ì…ê³ ì¼_dt", ascending=False)
    show_view = pd.DataFrame({
        "ì…ê³ ì¼": show["_ì…ê³ ì¼_dt"].dt.date,
        "ì‰í¬íƒ€ì…": show.get("ì‰í¬íƒ€ì…\n(HEMA/Silicone)", ""),
        "ìƒ‰ìƒêµ°": show.get("ìƒ‰ìƒêµ°", ""),
        "ì œí’ˆì½”ë“œ": show.get("ì œí’ˆì½”ë“œ", ""),
        "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": show["_Lot_fix"],
        "ì‚¬ìš©ë°”ì¸ë”Lot": show.get("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", ""),
        "BinderType(ë³´ì •)": show["_BinderType_fix"],
        "ì ë„(cP)": show["_ì ë„"],
        "ì ë„í•˜í•œ(ë³´ì •)": show["_ì ë„í•˜í•œ_fix"],
        "ì ë„ìƒí•œ(ë³´ì •)": show["_ì ë„ìƒí•œ_fix"],
        "ì ë„íŒì •(ë³´ì •)": show["_ì ë„íŒì •_fix"],
    })
    st.dataframe(show_view.head(20), use_container_width=True)

# =========================
# ì‰í¬ ì…ê³  (ë‹¨ì¼ìƒ‰ ì…ë ¥ë§Œ)
# =========================
with tab_ink_in:
    st.subheader("ë‹¨ì¼ìƒ‰ ì‰í¬ ì…ë ¥(ì…ê³ )")
    st.info("ì´ íƒ­ì€ **ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬** ì‹œíŠ¸ì— í–‰ì„ Appendí•˜ì—¬ ëˆ„ì í•©ë‹ˆë‹¤. (ë™ì‹œ ì‚¬ìš© ì‹œ ì¶©ëŒ ê°€ëŠ¥)")

    ink_types = ["HEMA", "Silicone"]
    color_groups = sorted(spec_single.get("ìƒ‰ìƒêµ°", pd.Series(dtype=object)).dropna().unique().tolist())
    product_codes = sorted(spec_single.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=object)).dropna().unique().tolist())

    binder_lots = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    binder_lots = sorted(set([x.strip() for x in binder_lots if x.strip()]), reverse=True)

    with st.form("single_form", clear_on_submit=True):
        col1, col2, col3, col4 = st.columns([1.2, 1.3, 1.5, 2.0])
        with col1:
            in_date = st.date_input("ì…ê³ ì¼", value=dt.date.today(), key=f"single_in_date_{file_sig}")
            ink_type = st.selectbox("ì‰í¬íƒ€ì…", ink_types, key=f"single_ink_type_{file_sig}")
            color_group = st.selectbox("ìƒ‰ìƒêµ°", color_groups, key=f"single_cg_{file_sig}")
        with col2:
            product_code = st.selectbox("ì œí’ˆì½”ë“œ", product_codes, key=f"single_pc_{file_sig}")
            binder_lot = st.selectbox("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", binder_lots, key=f"single_blot_{file_sig}")
        with col3:
            visc_meas = st.number_input("ì ë„ì¸¡ì •ê°’(cP)", min_value=0.0, step=1.0, format="%.1f", key=f"single_visc_{file_sig}")
            supplier = st.selectbox("ë°”ì¸ë”ì œì¡°ì²˜", ["ë‚´ë¶€", "ì™¸ì£¼"], index=0, key=f"single_supplier_{file_sig}")
        with col4:
            st.caption("ì„ íƒ: ì°©ìƒ‰ë ¥(L*a*b*) ì…ë ¥ ì‹œ, ê¸°ì¤€LABì´ ìˆìœ¼ë©´ Î”E(76)ì„ ê³„ì‚°í•´ 'ë¹„ê³ 'ì— ê¸°ë¡í•©ë‹ˆë‹¤.")
            L = st.number_input("ì°©ìƒ‰ë ¥_L*", value=0.0, step=0.1, format="%.2f", key=f"single_L_{file_sig}")
            a = st.number_input("ì°©ìƒ‰ë ¥_a*", value=0.0, step=0.1, format="%.2f", key=f"single_a_{file_sig}")
            b = st.number_input("ì°©ìƒ‰ë ¥_b*", value=0.0, step=0.1, format="%.2f", key=f"single_b_{file_sig}")
            lab_enabled = st.checkbox("L*a*b* ì…ë ¥í•¨", value=False, key=f"single_lab_en_{file_sig}")

        note = st.text_input("ë¹„ê³ ", value="", key=f"single_note_{file_sig}")
        submit_s = st.form_submit_button("ì €ì¥(ë‹¨ì¼ìƒ‰)")

    if submit_s:
        # ê¸°ì¡´ ë°ì´í„°(Lot ë³´ì • í¬í•¨)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ Lot ìƒì„±
        existing_lots = single_df["_Lot_fix"].astype(str).replace(["nan", "None"], "").str.strip()
        existing_lots = [x for x in existing_lots.tolist() if x]

        # ìƒˆ lot ìƒì„±
        pfx = lot_prefix_from_single(product_code, color_group, in_date)
        if not pfx:
            st.error("Lot ìë™ ìƒì„± ì‹¤íŒ¨: ì œí’ˆì½”ë“œ/ìƒ‰ìƒêµ°/ì…ê³ ì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            # pfx + seq ìµœëŒ“ê°’ ì°¾ê¸°
            seqs = []
            for lot in existing_lots:
                if lot.startswith(pfx):
                    m = re.match(rf"^{re.escape(pfx)}(\d{{2,}})$", lot)
                    if m:
                        try:
                            seqs.append(int(m.group(1)))
                        except Exception:
                            pass
            seq = (max(seqs) + 1) if seqs else 1
            new_lot = f"{pfx}{seq:02d}"

            binder_type = infer_binder_type_from_lot(spec_binder, binder_lot)

            # ì ë„ ê¸°ì¤€ lookup
            hit = spec_single[
                (spec_single["ìƒ‰ìƒêµ°"].astype(str).str.strip() == str(color_group).strip()) &
                (spec_single["ì œí’ˆì½”ë“œ"].astype(str).str.strip() == str(product_code).strip())
            ].copy()
            if binder_type and "BinderType" in hit.columns and len(hit) > 0:
                hit2 = hit[hit["BinderType"].astype(str).str.strip() == str(binder_type).strip()]
                if len(hit2) > 0:
                    hit = hit2

            if len(hit) == 0:
                lo, hi, visc_judge = None, None, None
                st.warning("ì ë„ ê¸°ì¤€ì„ Spec_Single_H&Sì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë°”ì¸ë”íƒ€ì… ì¡°í•© í™•ì¸)")
            else:
                lo = safe_to_float(hit.iloc[0].get("í•˜í•œ", None))
                hi = safe_to_float(hit.iloc[0].get("ìƒí•œ", None))
                visc_judge = judge_range(visc_meas, lo, hi)

            # Î”E ê¸°ë¡(ë¹„ê³ ì— ë‚¨ê¹€)
            note2 = note
            if lab_enabled:
                base_hit = base_lab[base_lab.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=str)).astype(str).str.strip() == str(product_code).strip()]
                if len(base_hit) == 1 and all(c in base_hit.columns for c in ["ê¸°ì¤€_L*", "ê¸°ì¤€_a*", "ê¸°ì¤€_b*"]):
                    ref = (
                        safe_to_float(base_hit.iloc[0].get("ê¸°ì¤€_L*", None)),
                        safe_to_float(base_hit.iloc[0].get("ê¸°ì¤€_a*", None)),
                        safe_to_float(base_hit.iloc[0].get("ê¸°ì¤€_b*", None)),
                    )
                    if None not in ref:
                        de = delta_e76((float(L), float(a), float(b)), ref)
                        note2 = (note2 + " " if note2 else "") + f"[Î”E76={de:.2f}]"
                    else:
                        note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"
                else:
                    note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"

            # âœ… ì €ì¥ì€ "í—¤ë” norm_key ê¸°ì¤€"ìœ¼ë¡œë§Œ ë§¤í•‘(ê¸°ì¡´ ë°ì´í„° ê±´ë“œë¦¼ ì—†ìŒ)
            row = {
                norm_key("ì…ê³ ì¼"): in_date,
                norm_key("ì‰í¬íƒ€ì…\n(HEMA/Silicone)"): ink_type,
                norm_key("ìƒ‰ìƒêµ°"): color_group,
                norm_key("ì œí’ˆì½”ë“œ"): product_code,
                norm_key("ë‹¨ì¼ìƒ‰ì‰í¬ Lot"): new_lot,
                norm_key("ì‚¬ìš©ëœ ë°”ì¸ë” Lot"): binder_lot,
                norm_key("ë°”ì¸ë”ì œì¡°ì²˜\n(ë‚´ë¶€/ì™¸ì£¼)"): supplier,
                norm_key("BinderType(ìë™)"): binder_type,
                norm_key("ì ë„ì¸¡ì •ê°’(cP)"): float(visc_meas),
                norm_key("ì ë„í•˜í•œ"): lo,
                norm_key("ì ë„ìƒí•œ"): hi,
                norm_key("ì ë„íŒì •"): visc_judge,
                norm_key("ì°©ìƒ‰ë ¥_L*"): float(L) if lab_enabled else None,
                norm_key("ì°©ìƒ‰ë ¥_a*"): float(a) if lab_enabled else None,
                norm_key("ì°©ìƒ‰ë ¥_b*"): float(b) if lab_enabled else None,
                norm_key("ë¹„ê³ "): note2,
            }

            try:
                append_row_to_sheet(xlsx_path, SHEET_SINGLE, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë‹¨ì¼ìƒ‰ Lot = {new_lot} / ì ë„íŒì • = {visc_judge}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

# =========================
# ë°”ì¸ë” ì…ì¶œê³  (ë°˜í’ˆ(kg) â†’ ë°”ì¸ë”ì…ê³  â†’ êµ¬ê¸€ì‹œíŠ¸ ìµœì‹ ìˆœ)
# =========================
with tab_binder:
    st.subheader("ì—…ì²´ë°˜í™˜(ë°˜í’ˆ) ì…ë ¥ (kg ë‹¨ìœ„)")
    st.caption("â€» 20kg(1í†µ) ê¸°ì¤€ì´ë”ë¼ë„ ì‹¤ì œ ë°˜í™˜ëŸ‰ì€ kg ë‹¨ìœ„ë¡œ ì…ë ¥í•©ë‹ˆë‹¤.")

    binder_names = sorted(spec_binder.get("ë°”ì¸ë”ëª…", pd.Series(dtype=object)).dropna().unique().tolist())
    binder_lots = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    binder_lots = sorted(set([x.strip() for x in binder_lots if x.strip()]), reverse=True)

    with st.form("binder_return_form", clear_on_submit=True):
        c1, c2, c3 = st.columns([1.2, 1.2, 2.6])
        with c1:
            r_date = st.date_input("ë°˜í™˜ì¼ì", value=dt.date.today(), key=f"ret_date_{file_sig}")
        with c2:
            r_type = st.selectbox("ë°”ì¸ë”íƒ€ì…", ["HEMA", "Silicone"], key=f"ret_type_{file_sig}")
        with c3:
            r_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key=f"ret_name_{file_sig}")

        c4, c5, c6 = st.columns([2.0, 1.2, 2.8])
        with c4:
            r_lot = st.selectbox("ë°”ì¸ë” Lot(ì„ íƒ)", ["(ì§ì ‘ì…ë ¥)"] + binder_lots, key=f"ret_lot_sel_{file_sig}")
            r_lot_text = st.text_input("ë°”ì¸ë” Lot ì§ì ‘ì…ë ¥", value="", key=f"ret_lot_text_{file_sig}") if r_lot == "(ì§ì ‘ì…ë ¥)" else ""
            final_lot = r_lot_text.strip() if r_lot == "(ì§ì ‘ì…ë ¥)" else r_lot
        with c5:
            r_kg = st.number_input("ë°˜í™˜ëŸ‰(kg)", min_value=0.0, step=0.5, format="%.1f", key=f"ret_kg_{file_sig}")
        with c6:
            r_note = st.text_input("ë¹„ê³ ", value="", key=f"ret_note_{file_sig}")

        submit_ret = st.form_submit_button("ë°˜í’ˆ ì €ì¥")

    if submit_ret:
        if r_kg <= 0:
            st.error("ë°˜í™˜ëŸ‰(kg)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        else:
            row = {
                norm_key("ì¼ì"): r_date,
                norm_key("ë°”ì¸ë”íƒ€ì…"): r_type,
                norm_key("ë°”ì¸ë”ëª…"): r_name,
                norm_key("ë°”ì¸ë” Lot"): final_lot,
                norm_key("ë°˜í™˜ëŸ‰(kg)"): float(r_kg),
                norm_key("ë¹„ê³ "): r_note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER_RETURN, row)
                st.success("ë°˜í’ˆ ì €ì¥ ì™„ë£Œ!")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ë°˜í’ˆ ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()

    st.subheader("ë°”ì¸ë” ì…ë ¥ (ì œì¡°/ì…ê³ ) â€” ì—¬ëŸ¬ Lot/ë‚ ì§œ ë¬¶ìŒ ì…ë ¥ ì§€ì›")
    st.caption("â€» ì—¬ëŸ¬ ë‚ ì§œì˜ Lotê°€ í•œ ë²ˆì— ì…ê³ ë˜ëŠ” ìƒí™©ì„ ê³ ë ¤í•´, ë‚ ì§œë³„/ìˆ˜ëŸ‰ë³„ ë¬¶ìŒ ì…ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.")

    input_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ê°œë³„ ì…ë ¥", "ë¬¶ìŒ ì…ë ¥(ì—¬ëŸ¬ ë‚ ì§œ/ìˆ˜ëŸ‰)"], horizontal=True, key=f"binder_input_mode_{file_sig}")

    existing_binder_lots = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    existing_binder_lots = [x.strip() for x in existing_binder_lots if x.strip()]

    if input_mode == "ê°œë³„ ì…ë ¥":
        with st.form("binder_form_single", clear_on_submit=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                mfg_date = st.date_input("ì œì¡°/ì…ê³ ì¼", value=dt.date.today(), key=f"b_single_date_{file_sig}")
                b_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key=f"b_single_name_{file_sig}")
            with col2:
                visc = st.number_input("ì ë„(cP)", min_value=0.0, step=1.0, format="%.1f", key=f"b_single_visc_{file_sig}")
                uv = st.number_input("UVí¡ê´‘ë„(ì„ íƒ)", min_value=0.0, step=0.01, format="%.3f", key=f"b_single_uv_{file_sig}")
                uv_enabled = st.checkbox("UV ê°’ ì…ë ¥í•¨", value=False, key=f"b_single_uv_en_{file_sig}")
            with col3:
                note = st.text_input("ë¹„ê³ ", value="", key=f"b_single_note_{file_sig}")
                submit_b = st.form_submit_button("ì €ì¥(ë°”ì¸ë”)")

        if submit_b:
            visc_lo, visc_hi, uv_hi, _ = get_binder_limits(spec_binder, b_name)
            lot = generate_binder_lot(spec_binder, b_name, mfg_date, existing_binder_lots)

            judge_v = judge_range(visc, visc_lo, visc_hi)
            judge_u = judge_range(uv if uv_enabled else None, None, uv_hi)
            judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

            row = {
                norm_key("ì œì¡°/ì…ê³ ì¼"): mfg_date,
                norm_key("ë°”ì¸ë”ëª…"): b_name,
                norm_key("Lot(ìë™)"): lot,
                norm_key("ì ë„(cP)"): float(visc),
                norm_key("UVí¡ê´‘ë„(ì„ íƒ)"): float(uv) if uv_enabled else None,
                norm_key("íŒì •"): judge,
                norm_key("ë¹„ê³ "): note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë°”ì¸ë” Lot = {lot}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    else:
        st.caption("í‘œì— ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰(í†µ)/ì ë„/UV/ë¹„ê³ ë¥¼ ì…ë ¥í•˜ê³  í•œ ë²ˆì— ì €ì¥í•˜ì„¸ìš”. (ë§¤ì¼ ì œì¡° X ìƒí™© ëŒ€ì‘)")

        # ê¸°ë³¸ 3ì¤„ í…œí”Œë¦¿
        base_rows = st.session_state.get(f"binder_batch_rows_{file_sig}")
        if base_rows is None:
            base_rows = [
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today(), "ë°”ì¸ë”ëª…": (binder_names[0] if binder_names else ""), "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today() - dt.timedelta(days=1), "ë°”ì¸ë”ëª…": (binder_names[0] if binder_names else ""), "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today() - dt.timedelta(days=2), "ë°”ì¸ë”ëª…": (binder_names[0] if binder_names else ""), "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
            ]
        edit_df = st.data_editor(pd.DataFrame(base_rows), use_container_width=True, num_rows="dynamic", key=f"binder_batch_editor_{file_sig}")
        submit_batch = st.button("ë¬¶ìŒ ì €ì¥(ë°”ì¸ë”)", type="primary", key=f"binder_batch_submit_{file_sig}")

        if submit_batch:
            tmp = edit_df.copy()
            tmp["ì œì¡°/ì…ê³ ì¼"] = tmp["ì œì¡°/ì…ê³ ì¼"].apply(normalize_date)
            tmp["ìˆ˜ëŸ‰(í†µ)"] = pd.to_numeric(tmp["ìˆ˜ëŸ‰(í†µ)"], errors="coerce").fillna(0).astype(int)
            tmp["ì ë„(cP)"] = pd.to_numeric(tmp["ì ë„(cP)"].astype(str).str.replace(",", "", regex=False), errors="coerce")

            tmp = tmp.dropna(subset=["ì œì¡°/ì…ê³ ì¼", "ë°”ì¸ë”ëª…", "ì ë„(cP)"])
            tmp = tmp[tmp["ìˆ˜ëŸ‰(í†µ)"] > 0]

            if len(tmp) == 0:
                st.error("ì €ì¥í•  í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰/ì ë„ ì…ë ¥ í™•ì¸)")
            else:
                rows_out = []
                existing_list = existing_binder_lots[:]
                seq_counters = {}
                tmp = tmp.sort_values(by="ì œì¡°/ì…ê³ ì¼")

                for _, r in tmp.iterrows():
                    mfg_date = r["ì œì¡°/ì…ê³ ì¼"]
                    b_name = str(r["ë°”ì¸ë”ëª…"]).strip()
                    qty = int(r["ìˆ˜ëŸ‰(í†µ)"])
                    visc = safe_to_float(r["ì ë„(cP)"])
                    uv_enabled = bool(r.get("UVì…ë ¥", False))
                    uv_val = safe_to_float(r.get("UVí¡ê´‘ë„(ì„ íƒ)", None)) if uv_enabled else None
                    note = str(r.get("ë¹„ê³ ", "")).strip()

                    visc_lo, visc_hi, uv_hi, rule = get_binder_limits(spec_binder, b_name)
                    m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip()) if rule else None
                    if not m:
                        st.error(f"[{b_name}] Lotë¶€ì—¬ê·œì¹™ í•´ì„ ì‹¤íŒ¨ (Spec_Binder í™•ì¸ í•„ìš”)")
                        st.stop()

                    prefix = m.group(1)
                    has_seq = bool(m.group(2))
                    date_str = mfg_date.strftime("%Y%m%d")

                    if (not has_seq) and qty > 1:
                        st.error(f"[{b_name}] ìˆœë²ˆ(-##)ì´ ì—†ì–´ ìˆ˜ëŸ‰ {qty}ë¥¼ ìë™ Lotë¡œ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()

                    key = (prefix, date_str)
                    if key not in seq_counters:
                        seq_counters[key] = next_seq_for_pattern(existing_list, prefix, date_str, sep="-")

                    for _i in range(qty):
                        if has_seq:
                            seq = seq_counters[key]
                            seq_counters[key] += 1
                            lot = f"{prefix}{date_str}-{seq:02d}"
                        else:
                            lot = f"{prefix}{date_str}"

                        judge_v = judge_range(visc, visc_lo, visc_hi)
                        judge_u = judge_range(uv_val, None, uv_hi) if uv_enabled else None
                        judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

                        row = {
                            norm_key("ì œì¡°/ì…ê³ ì¼"): mfg_date,
                            norm_key("ë°”ì¸ë”ëª…"): b_name,
                            norm_key("Lot(ìë™)"): lot,
                            norm_key("ì ë„(cP)"): float(visc),
                            norm_key("UVí¡ê´‘ë„(ì„ íƒ)"): float(uv_val) if uv_enabled and uv_val is not None else None,
                            norm_key("íŒì •"): judge,
                            norm_key("ë¹„ê³ "): note,
                        }
                        rows_out.append(row)
                        existing_list.append(lot)

                st.write("ì €ì¥ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 50ê±´)")
                st.dataframe(pd.DataFrame(rows_out).tail(50), use_container_width=True)

                try:
                    append_rows_to_sheet(xlsx_path, SHEET_BINDER, rows_out)
                    st.success(f"ë¬¶ìŒ ì €ì¥ ì™„ë£Œ! ì´ {len(rows_out)}ê±´ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()

    st.subheader("ë°”ì¸ë” ì…ì¶œê³  (Google Sheets ìë™ ë°˜ì˜, ìµœì‹ ìˆœ)")
    st.caption("êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ìƒˆë¡œê³ ì¹¨ ì‹œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤. (ìºì‹œ 60ì´ˆ)")

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ëª» ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì‹œíŠ¸ ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/ID í™•ì¸)")
        st.exception(e)
        st.stop()

    for _df in [df_hema, df_sil]:
        dc = detect_date_col(_df)
        if dc:
            _df["_sort_date"] = pd.to_datetime(_df[dc], errors="coerce")
            _df.sort_values(by="_sort_date", ascending=False, inplace=True)
            _df.drop(columns=["_sort_date"], inplace=True)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### HEMA (ìµœì‹ ìˆœ)")
        st.dataframe(df_hema, use_container_width=True, height=420)
    with c2:
        st.markdown("### Silicone (ìµœì‹ ìˆœ)")
        st.dataframe(df_sil, use_container_width=True, height=420)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key=f"binder_refresh_{file_sig}"):
        st.cache_data.clear()
        st.rerun()

# =========================
# Search
# =========================
with tab_search:
    st.subheader("ë¹ ë¥¸ ê²€ìƒ‰")
    c1, c2, c3 = st.columns([2, 2, 3])
    with c1:
        mode = st.selectbox("ê²€ìƒ‰ ì¢…ë¥˜", ["ë°”ì¸ë” Lot", "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°", "ê¸°ê°„(ì…ê³ ì¼)"], key=f"search_mode_{file_sig}")
    with c2:
        q = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: PCB20250112-01 / PLB25041501 ...", key=f"search_q_{file_sig}")
    with c3:
        st.caption("ğŸ’¡ ë‹¨ì¼ìƒ‰ Lot/ì œí’ˆì½”ë“œ/ìƒ‰ìƒêµ°/ê¸°ê°„ìœ¼ë¡œ ë¹ ë¥´ê²Œ í•„í„°ë§í•©ë‹ˆë‹¤.")

    if mode == "ê¸°ê°„(ì…ê³ ì¼)":
        d1, d2 = st.columns(2)
        with d1:
            start = st.date_input("ì‹œì‘ì¼", value=dt.date.today() - dt.timedelta(days=30), key=f"search_start_{file_sig}")
        with d2:
            end = st.date_input("ì¢…ë£Œì¼", value=dt.date.today(), key=f"search_end_{file_sig}")

        df = single_df.copy()
        df = df.dropna(subset=["_ì…ê³ ì¼_dt"])
        df = df[(df["_ì…ê³ ì¼_dt"].dt.date >= start) & (df["_ì…ê³ ì¼_dt"].dt.date <= end)]

        out = pd.DataFrame({
            "ì…ê³ ì¼": df["_ì…ê³ ì¼_dt"].dt.date,
            "ìƒ‰ìƒêµ°": df.get("ìƒ‰ìƒêµ°", ""),
            "ì œí’ˆì½”ë“œ": df.get("ì œí’ˆì½”ë“œ", ""),
            "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": df["_Lot_fix"],
            "ì‚¬ìš©ë°”ì¸ë”Lot": df.get("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", ""),
            "BinderType(ë³´ì •)": df["_BinderType_fix"],
            "ì ë„(cP)": df["_ì ë„"],
            "ì ë„íŒì •(ë³´ì •)": df["_ì ë„íŒì •_fix"],
        }).sort_values(by="ì…ê³ ì¼", ascending=False)
        st.dataframe(out, use_container_width=True)

    elif mode == "ë°”ì¸ë” Lot":
        b = binder_df.copy()
        if q:
            b = b[b.astype(str).apply(lambda r: r.str.contains(str(q).strip(), case=False, na=False)).any(axis=1)]
        st.subheader("ë°”ì¸ë”_ì œì¡°_ì…ê³ ")
        st.dataframe(b.sort_values(by="ì œì¡°/ì…ê³ ì¼", ascending=False) if "ì œì¡°/ì…ê³ ì¼" in b.columns else b, use_container_width=True)

        if q and "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in single_df.columns:
            s_hit = single_df[single_df["ì‚¬ìš©ëœ ë°”ì¸ë” Lot"].astype(str).str.contains(str(q).strip(), case=False, na=False)]
            st.subheader("ì—°ê²°ëœ ë‹¨ì¼ìƒ‰ (ì‚¬ìš©ëœ ë°”ì¸ë” Lot)")
            out = pd.DataFrame({
                "ì…ê³ ì¼": s_hit["_ì…ê³ ì¼_dt"].dt.date,
                "ìƒ‰ìƒêµ°": s_hit.get("ìƒ‰ìƒêµ°", ""),
                "ì œí’ˆì½”ë“œ": s_hit.get("ì œí’ˆì½”ë“œ", ""),
                "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": s_hit["_Lot_fix"],
                "ì ë„(cP)": s_hit["_ì ë„"],
                "ì ë„íŒì •(ë³´ì •)": s_hit["_ì ë„íŒì •_fix"],
            }).sort_values(by="ì…ê³ ì¼", ascending=False)
            st.dataframe(out, use_container_width=True)

    elif mode == "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot":
        s = single_df.copy()
        s["Lotê²€ìƒ‰"] = s["_Lot_fix"].astype(str)
        if q:
            s = s[s["Lotê²€ìƒ‰"].str.contains(str(q).strip(), case=False, na=False)]
        out = pd.DataFrame({
            "ì…ê³ ì¼": s["_ì…ê³ ì¼_dt"].dt.date,
            "ìƒ‰ìƒêµ°": s.get("ìƒ‰ìƒêµ°", ""),
            "ì œí’ˆì½”ë“œ": s.get("ì œí’ˆì½”ë“œ", ""),
            "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": s["_Lot_fix"],
            "ì‚¬ìš©ë°”ì¸ë”Lot": s.get("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", ""),
            "BinderType(ë³´ì •)": s["_BinderType_fix"],
            "ì ë„(cP)": s["_ì ë„"],
            "ì ë„íŒì •(ë³´ì •)": s["_ì ë„íŒì •_fix"],
        }).sort_values(by="ì…ê³ ì¼", ascending=False)
        st.dataframe(out, use_container_width=True)

    elif mode == "ì œí’ˆì½”ë“œ":
        s = single_df.copy()
        if q:
            s = s[s.get("ì œí’ˆì½”ë“œ", "").astype(str).str.contains(str(q).strip(), case=False, na=False)]
        out = pd.DataFrame({
            "ì…ê³ ì¼": s["_ì…ê³ ì¼_dt"].dt.date,
            "ìƒ‰ìƒêµ°": s.get("ìƒ‰ìƒêµ°", ""),
            "ì œí’ˆì½”ë“œ": s.get("ì œí’ˆì½”ë“œ", ""),
            "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": s["_Lot_fix"],
            "ì ë„(cP)": s["_ì ë„"],
            "ì ë„íŒì •(ë³´ì •)": s["_ì ë„íŒì •_fix"],
        }).sort_values(by="ì…ê³ ì¼", ascending=False)
        st.dataframe(out, use_container_width=True)

    elif mode == "ìƒ‰ìƒêµ°":
        s = single_df.copy()
        if q:
            s = s[s.get("ìƒ‰ìƒêµ°", "").astype(str).str.contains(str(q).strip(), case=False, na=False)]
        out = pd.DataFrame({
            "ì…ê³ ì¼": s["_ì…ê³ ì¼_dt"].dt.date,
            "ìƒ‰ìƒêµ°": s.get("ìƒ‰ìƒêµ°", ""),
            "ì œí’ˆì½”ë“œ": s.get("ì œí’ˆì½”ë“œ", ""),
            "ë‹¨ì¼ìƒ‰Lot(ë³´ì •)": s["_Lot_fix"],
            "ì ë„(cP)": s["_ì ë„"],
            "ì ë„íŒì •(ë³´ì •)": s["_ì ë„íŒì •_fix"],
        }).sort_values(by="ì…ê³ ì¼", ascending=False)
        st.dataframe(out, use_container_width=True)
