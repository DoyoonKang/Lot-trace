import streamlit as st
import pandas as pd
import altair as alt
import datetime as dt
import re
from pathlib import Path
from io import StringIO
import requests
from openpyxl import load_workbook

# ==========================================================
# Page
# ==========================================================
st.set_page_config(page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬", page_icon="ğŸ§ª", layout="wide")

st.markdown(
    """
    <style>
      .block-container { padding-top: 1.1rem; padding-bottom: 1.8rem; }
      .section-title { font-size: 1.15rem; font-weight: 800; margin: 0.2rem 0 0.2rem 0; }
      .section-sub { color: rgba(49,51,63,0.65); font-size: 0.92rem; margin-bottom: 0.6rem; }
      .kpi-note { color: rgba(49,51,63,0.70); font-size: 0.85rem; margin-top: -0.2rem; }
      div[data-testid="stExpander"] > details > summary { font-weight: 700; }
    </style>
    """,
    unsafe_allow_html=True
)

# ==========================================================
# Config
# ==========================================================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"
DEFAULT_STOCK_XLSX = "ì•¡ìƒ ì¬ê³ ì¡°ì‚¬í‘œ_ìë™ê³„ì‚° (12).xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"  # ì—†ìœ¼ë©´ ìë™ ìƒì„±

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"


# ==========================================================
# Helpers
# ==========================================================
def norm_key(x) -> str:
    if x is None:
        return ""
    s = str(x).replace("\n", " ").replace("\r", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def find_col(df: pd.DataFrame, want: str):
    w = norm_key(want)
    for c in df.columns:
        if norm_key(c) == w:
            return c
    return None

def safe_to_float(x):
    if x is None:
        return None
    if isinstance(x, float) and pd.isna(x):
        return None
    if isinstance(x, str) and x.strip() == "":
        return None
    try:
        if isinstance(x, str):
            x = x.replace(",", "")
        return float(x)
    except Exception:
        return None

def normalize_date(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        return pd.to_datetime(x).date()
    except Exception:
        return None

def ensure_sheet_exists(xlsx_path: str, sheet_name: str, headers: list[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        wb.save(xlsx_path)

def add_excel_row_number(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["_excel_row"] = df.index + 2  # í—¤ë” 1í–‰ ê°€ì •
    return df

def safe_date_bounds(series: pd.Series):
    s = pd.to_datetime(series, errors="coerce").dropna()
    if len(s) == 0:
        today = dt.date.today()
        return today, today
    return s.min().date(), s.max().date()

def detect_date_col(df: pd.DataFrame):
    for c in df.columns:
        ck = norm_key(c)
        if any(k in ck.lower() for k in ["ì¼ì", "ë‚ ì§œ", "date", "ì…ê³ ì¼", "ì¶œê³ ì¼"]):
            return c
    return None

# ==========================================================
# Color/Stock helpers  (ìš”ì²­ ë°˜ì˜: í™”ë©´ì— BLACK/RED ë“± ëŒ€ë¬¸ì í‘œì‹œ)
# ==========================================================
COLOR_KEYS = ["BLACK","BLUE","GREEN","YELLOW","RED","PINK","WHITE","OTHER"]

def normalize_color_group(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return "OTHER"
    s = str(x).strip()
    if not s or s.lower() in ("nan", "none"):
        return "OTHER"

    u = s.upper()
    # í•œêµ­ì–´/ì˜ë¬¸ í˜¼ìš© ëŒ€ì‘
    if "BLACK" in u or "ê²€ì •" in s or "í‘" in s:
        return "BLACK"
    if "WHITE" in u or "í°" in s or "ë°±" in s:
        return "WHITE"
    if "RED" in u or "ë¹¨" in s or "ì " in s:
        return "RED"
    if "YELLOW" in u or "ë…¸" in s or "í™©" in s or "ì˜" in s:
        return "YELLOW"
    if "GREEN" in u or "ì´ˆ" in s or "ë…¹" in s:
        return "GREEN"
    if "BLUE" in u or "íŒŒ" in s or "ì²­" in s:
        return "BLUE"
    if "PINK" in u or "í•‘" in s:
        return "PINK"

    if u in COLOR_KEYS:
        return u
    return "OTHER"

def normalize_product_code(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).strip()
    if not s or s.lower() in ("nan", "none"):
        return ""
    s = s.replace("â€“", "-").replace("â€”", "-").replace("âˆ’", "-")
    s = re.sub(r"\s+", " ", s).strip()
    s = s.replace("(ì•¡ìƒì‰í¬)", "").replace("ì•¡ìƒì‰í¬", "").strip()
    return s

def build_product_to_color_map(spec_single: pd.DataFrame, single_df: pd.DataFrame) -> dict[str, str]:
    mapping: dict[str, str] = {}

    sp_pc = find_col(spec_single, "ì œí’ˆì½”ë“œ")
    sp_cg = find_col(spec_single, "ìƒ‰ìƒêµ°")
    if sp_pc and sp_cg and len(spec_single):
        tmp = spec_single[[sp_pc, sp_cg]].dropna()
        tmp[sp_pc] = tmp[sp_pc].apply(normalize_product_code)
        tmp[sp_cg] = tmp[sp_cg].apply(normalize_color_group)
        for pc, g in tmp.groupby(sp_pc)[sp_cg]:
            mapping[str(pc)] = g.value_counts().idxmax()

    s_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")
    s_cg = find_col(single_df, "ìƒ‰ìƒêµ°")
    if s_pc and s_cg and len(single_df):
        tmp = single_df[[s_pc, s_cg]].dropna()
        tmp[s_pc] = tmp[s_pc].apply(normalize_product_code)
        tmp[s_cg] = tmp[s_cg].apply(normalize_color_group)
        for pc, g in tmp.groupby(s_pc)[s_cg]:
            pc = str(pc)
            if pc not in mapping:
                mapping[pc] = g.value_counts().idxmax()

    return mapping

def _parse_stock_sheet_date(sheet_name: str, today: dt.date):
    s = str(sheet_name).strip()
    m = re.match(r"^(\d{1,2})\.(\d{1,2})$", s)  # ì˜ˆ: 1.15
    if not m:
        return None
    month = int(m.group(1))
    day = int(m.group(2))
    year = today.year
    if month > (today.month + 1):
        year -= 1
    try:
        return dt.date(year, month, day)
    except ValueError:
        return None

@st.cache_data(show_spinner=False)
def load_stock_history(stock_xlsx_path: str, product_to_color: dict[str, str]) -> pd.DataFrame:
    p = Path(stock_xlsx_path)
    if not stock_xlsx_path or not p.exists():
        return pd.DataFrame()

    today = dt.date.today()
    xls = pd.ExcelFile(stock_xlsx_path, engine="openpyxl")

    frames = []
    for sh in xls.sheet_names:
        d = _parse_stock_sheet_date(sh, today)
        if d is None:
            continue

        df = pd.read_excel(xls, sheet_name=sh)
        df = df.rename(columns=lambda x: str(x).strip())

        c_div = find_col(df, "êµ¬ë¶„")
        c_item = find_col(df, "í’ˆëª©ëª…")
        c_curr = find_col(df, "ê¸ˆì¼ ì¬ê³ (kg)") or find_col(df, "ê¸ˆì¼ì¬ê³ (kg)") or find_col(df, "ì¬ê³ (kg)")
        c_used = find_col(df, "í•˜ë£¨ ì‚¬ìš©ëŸ‰(kg)") or find_col(df, "ì‚¬ìš©ëŸ‰(kg)") or find_col(df, "ì‚¬ìš©ëŸ‰")

        if not (c_item and c_curr and c_used):
            continue

        df["_division"] = df[c_div].astype(str).str.strip() if c_div else ""
        df["_product"] = df[c_item].apply(normalize_product_code)
        df["_curr"] = pd.to_numeric(df[c_curr].astype(str).str.replace(",", "", regex=False), errors="coerce")
        df["_used_raw"] = pd.to_numeric(df[c_used].astype(str).str.replace(",", "", regex=False), errors="coerce")

        df = df.dropna(subset=["_product", "_curr"])
        df["used_kg"] = df["_used_raw"].clip(lower=0).fillna(0)
        df["inbound_kg"] = (-df["_used_raw"]).clip(lower=0).fillna(0)
        df["inbound_event"] = (df["inbound_kg"] > 0).astype(int)
        df["curr_stock_kg"] = df["_curr"].fillna(0)

        df["color_group"] = df["_product"].map(product_to_color).fillna("OTHER").apply(normalize_color_group)
        df["date"] = pd.to_datetime(d)

        frames.append(df[["date","_division","_product","color_group","curr_stock_kg","used_kg","inbound_kg","inbound_event"]])

    if not frames:
        return pd.DataFrame()

    hist = pd.concat(frames, ignore_index=True)
    hist = hist.rename(columns={"_division":"division", "_product":"product_code"})
    hist = hist.sort_values(["date","division","product_code"]).reset_index(drop=True)
    return hist

def _color_scale_color_group():
    # ë„ë©”ì¸ì€ ë°˜ë“œì‹œ ë°ì´í„°ì™€ ë™ì¼í•´ì•¼ í•¨(ëŒ€ë¬¸ì)
    domain = ["BLACK","BLUE","GREEN","YELLOW","RED","PINK","WHITE","OTHER"]
    rng = ["#111111","#1f77b4","#2ca02c","#f1c40f","#d62728","#e377c2","#dddddd","#7f7f7f"]
    return alt.Scale(domain=domain, range=rng)

# ==========================================================
# Google Sheets Reader (public)
# ==========================================================
@st.cache_data(ttl=60, show_spinner=False)
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))

# ==========================================================
# Load main excel sheets (Lot ê´€ë¦¬)
# ==========================================================
@st.cache_data(show_spinner=False)
def load_dataframes(xlsx_path: str) -> dict[str, pd.DataFrame]:
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)

    out = {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "base_lab": read(SHEET_BASE_LAB),
    }
    try:
        out["binder_return"] = pd.read_excel(xlsx_path, sheet_name=SHEET_BINDER_RETURN)
    except Exception:
        out["binder_return"] = pd.DataFrame(columns=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "])
    return out

# ==========================================================
# Binder IO file upload
# ==========================================================
def _guess_hema_sil_sheets(sheet_names: list[str]):
    hema = None
    sil = None
    for s in sheet_names:
        u = str(s).upper()
        if hema is None and ("HEMA" in u or "í—¤ë§ˆ" in s):
            hema = s
        if sil is None and (("SIL" in u) or ("SILIC" in u) or ("ì‹¤ë¦¬" in s) or ("ì‹¤ë¦¬ì½˜" in s)):
            sil = s
    return hema, sil

@st.cache_data(show_spinner=False)
def load_binder_io_excel(xlsx_bytes: bytes, filename: str) -> dict[str, pd.DataFrame]:
    tmp = Path(f".binder_io_{re.sub(r'[^A-Za-z0-9_.-]','_', filename)}")
    tmp.write_bytes(xlsx_bytes)

    xls = pd.ExcelFile(tmp, engine="openpyxl")
    hema_sh, sil_sh = _guess_hema_sil_sheets(xls.sheet_names)

    out = {}
    if hema_sh:
        out["HEMA"] = pd.read_excel(xls, sheet_name=hema_sh)
    if sil_sh:
        out["Silicone"] = pd.read_excel(xls, sheet_name=sil_sh)

    if not out:
        out["ALL"] = pd.read_excel(xls, sheet_name=xls.sheet_names[0])

    # ë‚ ì§œ ì»¬ëŸ¼ ìˆìœ¼ë©´ ìµœì‹ ìˆœ ì •ë ¬
    for k, df in list(out.items()):
        if df is None or df.empty:
            continue
        dc = detect_date_col(df)
        if dc:
            df2 = df.copy()
            df2["_sort_date"] = pd.to_datetime(df2[dc], errors="coerce")
            df2 = df2.sort_values(by="_sort_date", ascending=False).drop(columns=["_sort_date"])
            out[k] = df2

    return out

# ==========================================================
# Title
# ==========================================================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("âœ… ëŒ€ì‹œë³´ë“œ | âœ… ìš”ì•½ | âœ… ì•¡ìƒì‰í¬ ì¬ê³ ê´€ë¦¬(ì¬ê³ /ì…ê³ /ì‚¬ìš©ëŸ‰) | âœ… ë°”ì¸ë” ì…ì¶œê³ (íŒŒì¼ ì—…ë¡œë“œ/êµ¬ê¸€ì‹œíŠ¸) | âœ… ë¹ ë¥¸ê²€ìƒ‰")

# ==========================================================
# Sidebar - files
# ==========================================================
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼ (Lot ê´€ë¦¬)")
    xlsx_path = st.text_input("ì—‘ì…€ íŒŒì¼ ê²½ë¡œ", value=DEFAULT_XLSX)
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"], key="lot_upload")

    st.divider()
    st.header("ì¬ê³  íŒŒì¼")
    stock_xlsx_path = st.text_input("ì¬ê³  ì—‘ì…€ íŒŒì¼ ê²½ë¡œ", value=DEFAULT_STOCK_XLSX, key="stock_path")
    uploaded_stock = st.file_uploader("ë˜ëŠ” ì¬ê³  ì—‘ì…€ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"], key="stock_upload")

# ì—…ë¡œë“œ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì‚¬ìš©(ì „ì²´ êµì²´ìš©)
if uploaded is not None:
    sig = f"{uploaded.name}:{uploaded.size}"
    if st.session_state.get("_uploaded_sig") != sig:
        tmp_path = Path(".streamlit_tmp.xlsx")
        tmp_path.write_bytes(uploaded.getvalue())
        st.session_state["_uploaded_sig"] = sig
        st.session_state["_tmp_xlsx_path"] = str(tmp_path)
    xlsx_path = st.session_state.get("_tmp_xlsx_path", xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼(Lot ê´€ë¦¬)ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì„œë²„ ì¬ì‹œì‘ ì‹œ ëˆ„ì  ì €ì¥ì€ ë³´ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)")

if uploaded_stock is not None:
    sig = f"{uploaded_stock.name}:{uploaded_stock.size}"
    if st.session_state.get("_uploaded_sig_stock") != sig:
        tmp_path = Path(".streamlit_tmp_stock.xlsx")
        tmp_path.write_bytes(uploaded_stock.getvalue())
        st.session_state["_uploaded_sig_stock"] = sig
        st.session_state["_tmp_stock_path"] = str(tmp_path)
    stock_xlsx_path = st.session_state.get("_tmp_stock_path", stock_xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼(ì¬ê³ )ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")

# ==========================================================
# Load Lot excel (ì¤‘ìš”: íŒŒì¼ ì—†ìœ¼ë©´ ë©ˆì¶”ì§€ ì•Šê³  'ë¹ˆ ë°ì´í„°'ë¡œ í™”ë©´ í‘œì‹œ)
# ==========================================================
if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ Lotê´€ë¦¬ ì—‘ì…€ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ê²½ë¡œë¥¼ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”. (í˜„ì¬ëŠ” 'ë¹ˆ ë°ì´í„°'ë¡œ í™”ë©´ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.)")

    binder_df = pd.DataFrame(columns=["ì œì¡°/ì…ê³ ì¼", "Lot(ìë™)", "íŒì •"])
    single_df = pd.DataFrame(columns=["ì…ê³ ì¼","ì ë„ì¸¡ì •ê°’(cP)","ì ë„íŒì •","ë‹¨ì¼ìƒ‰ì‰í¬ Lot","ì‚¬ìš©ëœ ë°”ì¸ë” Lot","ìƒ‰ìƒêµ°","ì œí’ˆì½”ë“œ"])
    spec_binder = pd.DataFrame()
    spec_single = pd.DataFrame(columns=["ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°"])
    base_lab = pd.DataFrame()
    binder_return_df = pd.DataFrame(columns=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "])
else:
    ensure_sheet_exists(
        xlsx_path,
        SHEET_BINDER_RETURN,
        headers=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "]
    )
    data = load_dataframes(xlsx_path)
    binder_df = data["binder"].copy()
    single_df = data["single"].copy()
    spec_binder = data["spec_binder"].copy()
    spec_single = data["spec_single"].copy()
    base_lab = data["base_lab"].copy()
    binder_return_df = data["binder_return"].copy()

# normalize dates
c_b_date = find_col(binder_df, "ì œì¡°/ì…ê³ ì¼")
c_s_date = find_col(single_df, "ì…ê³ ì¼")
if c_b_date and c_b_date in binder_df.columns:
    binder_df[c_b_date] = binder_df[c_b_date].apply(normalize_date)
if c_s_date and c_s_date in single_df.columns:
    single_df[c_s_date] = single_df[c_s_date].apply(normalize_date)

# common cols
c_s_visc = find_col(single_df, "ì ë„ì¸¡ì •ê°’(cP)")
c_s_judge = find_col(single_df, "ì ë„íŒì •")
c_s_lot = find_col(single_df, "ë‹¨ì¼ìƒ‰ì‰í¬ Lot")
c_s_blot = find_col(single_df, "ì‚¬ìš©ëœ ë°”ì¸ë” Lot")
c_s_cg = find_col(single_df, "ìƒ‰ìƒêµ°")
c_s_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")

# ==========================================================
# Tabs
# ==========================================================
tab_dash, tab_summary, tab_stock, tab_binder, tab_search = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“Œ ìš”ì•½", "ğŸ“¦ ì•¡ìƒì‰í¬ ì¬ê³ ê´€ë¦¬", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰"]
)

# ==========================================================
# Summary tab
# ==========================================================
def render_summary():
    st.markdown('<div class="section-title">ğŸ“Œ ìš”ì•½</div>', unsafe_allow_html=True)
    st.markdown('<div class="section-sub">ìƒì‚¬ê°€ â€œí•œ ë²ˆì— ì´í•´â€í•  ìˆ˜ ìˆê²Œ KPI + ê·¸ë˜í”„ 4ê°œ + ìƒì„¸(í¼ì¹¨) êµ¬ì¡°</div>', unsafe_allow_html=True)

    # ì¬ê³ (ìµœê·¼ 30ì¼)
    stock_ok = bool(stock_xlsx_path and Path(stock_xlsx_path).exists())
    product_to_color = build_product_to_color_map(spec_single, single_df)

    inv_color = pd.DataFrame()
    use_color = pd.DataFrame()
    cov_alert = pd.DataFrame()
    stock_kpis = {}

    if stock_ok:
        hist = load_stock_history(stock_xlsx_path, product_to_color)
        if not hist.empty:
            max_d = hist["date"].max().date()
            start = max(hist["date"].min().date(), max_d - dt.timedelta(days=29))
            end = max_d
            day_span = max(1, (end - start).days + 1)

            hist_f = hist[(hist["date"].dt.date >= start) & (hist["date"].dt.date <= end)].copy()
            latest_df = hist[hist["date"].dt.date == end].copy()

            stock_kpis["ì¬ê³  ìµœì‹ ì¼"] = end.isoformat()
            stock_kpis["í˜„ì¬ ì´ ì¬ê³ (kg)"] = float(latest_df["curr_stock_kg"].sum())
            stock_kpis["ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰(kg)"] = float(hist_f["used_kg"].sum())
            stock_kpis["ìµœê·¼ 30ì¼ ì…ê³ (ê±´)"] = int(hist_f["inbound_event"].sum())
            stock_kpis["í‰ê·  ì‚¬ìš©ëŸ‰(kg/ì¼)"] = float(stock_kpis["ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰(kg)"] / day_span)

            inv_color = (
                latest_df.groupby("color_group", as_index=False)["curr_stock_kg"]
                .sum().rename(columns={"curr_stock_kg": "kg"})
                .sort_values("kg", ascending=False)
            )
            use_color = (
                hist_f.groupby("color_group", as_index=False)["used_kg"]
                .sum().rename(columns={"used_kg": "kg"})
                .sort_values("kg", ascending=False)
            )

            use_by_product = hist_f.groupby("product_code", as_index=False)["used_kg"].sum()
            use_by_product["avg_daily_use"] = use_by_product["used_kg"] / day_span
            stock_by_product = latest_df.groupby("product_code", as_index=False)["curr_stock_kg"].sum().rename(
                columns={"curr_stock_kg": "stock_kg"}
            )
            cov = stock_by_product.merge(use_by_product[["product_code", "avg_daily_use"]], on="product_code", how="left")
            cov["avg_daily_use"] = cov["avg_daily_use"].fillna(0.0)
            cov["cover_days"] = cov.apply(
                lambda r: (r["stock_kg"] / r["avg_daily_use"]) if r["avg_daily_use"] > 0 else None, axis=1
            )
            cov_alert = cov[cov["cover_days"].notna()].sort_values("cover_days").head(10)
        else:
            stock_ok = False

    # ì ë„(ìµœê·¼ 30ì¼)
    visc_ok = bool(c_s_date and c_s_visc and c_s_pc and (c_s_date in single_df.columns) and (c_s_visc in single_df.columns) and (c_s_pc in single_df.columns))
    visc_kpis = {}
    daily_visc = pd.DataFrame()
    top_ng = pd.DataFrame()

    if visc_ok:
        df = single_df.copy()
        df[c_s_date] = pd.to_datetime(df[c_s_date], errors="coerce")
        df["_ì ë„"] = pd.to_numeric(df[c_s_visc].astype(str).str.replace(",", "", regex=False), errors="coerce")
        df = df.dropna(subset=[c_s_date, "_ì ë„", c_s_pc])

        if len(df):
            max_d = df[c_s_date].max().date()
            start = max(df[c_s_date].min().date(), max_d - dt.timedelta(days=29))
            df30 = df[(df[c_s_date].dt.date >= start) & (df[c_s_date].dt.date <= max_d)].copy()

            total = len(df30)
            ng = int((df30[c_s_judge] == "ë¶€ì í•©").sum()) if c_s_judge and (c_s_judge in df30.columns) else 0
            ng_rate = (ng / total * 100) if total else 0.0

            visc_kpis = {
                "ì ë„ ìµœì‹ ì¼": max_d.isoformat(),
                "ìµœê·¼ 30ì¼ ì¸¡ì •(ê±´)": total,
                "ë¶€ì í•©(ê±´)": ng,
                "ë¶€ì í•©ë¥ (%)": ng_rate,
            }

            daily_visc = (
                df30.groupby(df30[c_s_date].dt.date)
                .agg(mean_visc=("_ì ë„", "mean"), cnt=("_ì ë„", "size"))
                .reset_index()
                .rename(columns={df30.groupby(df30[c_s_date].dt.date).agg(mean_visc=("_ì ë„","mean")).reset_index().columns[0]: "date"})
            )
            daily_visc["date"] = pd.to_datetime(daily_visc["date"])

            if c_s_judge and (c_s_judge in df30.columns):
                top_ng = (
                    df30[df30[c_s_judge] == "ë¶€ì í•©"]
                    .groupby(c_s_pc).size().reset_index(name="ng_cnt")
                    .sort_values("ng_cnt", ascending=False).head(8)
                )
        else:
            visc_ok = False

    # KPIs
    a, b = st.columns(2)
    with a:
        st.markdown("#### ğŸ§¾ ì¬ê³ (ìµœê·¼ 30ì¼)")
        if not stock_ok:
            st.info("ì¬ê³  íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ê³  íŒŒì¼ ê²½ë¡œ/ì—…ë¡œë“œ ì„¤ì •)")
        else:
            k1, k2, k3, k4, k5 = st.columns([1.2, 1.7, 1.7, 1.4, 1.8])
            k1.metric("ìµœì‹ ì¼", stock_kpis["ì¬ê³  ìµœì‹ ì¼"])
            k2.metric("ì´ ì¬ê³ (kg)", f'{stock_kpis["í˜„ì¬ ì´ ì¬ê³ (kg)"]:,.1f}')
            k3.metric("30ì¼ ì‚¬ìš©ëŸ‰(kg)", f'{stock_kpis["ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰(kg)"]:,.1f}')
            k4.metric("ì…ê³ (ê±´)", f'{stock_kpis["ìµœê·¼ 30ì¼ ì…ê³ (ê±´)"]:,}')
            k5.metric("ì¼í‰ê· (kg/ì¼)", f'{stock_kpis["í‰ê·  ì‚¬ìš©ëŸ‰(kg/ì¼)"]:,.1f}')

    with b:
        st.markdown("#### ğŸ§ª ì ë„(ìµœê·¼ 30ì¼)")
        if not visc_ok:
            st.info("ë‹¨ì¼ìƒ‰ ì‹œíŠ¸ì— ì…ê³ ì¼/ì ë„ì¸¡ì •ê°’/ì œí’ˆì½”ë“œ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            k1, k2, k3 = st.columns(3)
            k1.metric("ìµœì‹ ì¼", visc_kpis["ì ë„ ìµœì‹ ì¼"])
            k2.metric("ì¸¡ì •(ê±´)", f'{visc_kpis["ìµœê·¼ 30ì¼ ì¸¡ì •(ê±´)"]:,}')
            k3.metric("ë¶€ì í•©ë¥ (%)", f'{visc_kpis["ë¶€ì í•©ë¥ (%)"]:.1f}')

    st.divider()
    st.markdown("#### ğŸ“Š í•œëˆˆì— ë³´ëŠ” ê·¸ë˜í”„")

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì¬ê³ (ìµœì‹ ì¼) â€” ìƒ‰ìƒê³„ì—´(BLACK/RED â€¦)**")
        if stock_ok and not inv_color.empty:
            ch = alt.Chart(inv_color).mark_bar().encode(
                y=alt.Y("color_group:N", sort="-x", title=""),
                x=alt.X("kg:Q", title="ì¬ê³ (kg)"),
                color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
                tooltip=[alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"), alt.Tooltip("kg:Q", title="ì¬ê³ (kg)", format=",.1f")]
            ).properties(height=260)
            st.altair_chart(ch, use_container_width=True)
        else:
            st.info("ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with c2:
        st.markdown("**ìµœê·¼ 30ì¼ í‰ê·  ì ë„(ì¼ë³„)**")
        if visc_ok and not daily_visc.empty:
            ch = alt.Chart(daily_visc).mark_line(point=True).encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("mean_visc:Q", title="í‰ê·  ì ë„(cP)"),
                tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"),
                         alt.Tooltip("mean_visc:Q", title="í‰ê· ì ë„", format=",.0f"),
                         alt.Tooltip("cnt:Q", title="ì¸¡ì •(ê±´)", format=",.0f")]
            ).properties(height=260)
            st.altair_chart(ch, use_container_width=True)
        else:
            st.info("ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    c3, c4 = st.columns(2)
    with c3:
        st.markdown("**ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰ â€” ìƒ‰ìƒê³„ì—´(BLACK/RED â€¦)**")
        if stock_ok and not use_color.empty:
            ch = alt.Chart(use_color).mark_bar().encode(
                y=alt.Y("color_group:N", sort="-x", title=""),
                x=alt.X("kg:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
                color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
                tooltip=[alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"), alt.Tooltip("kg:Q", title="ì‚¬ìš©ëŸ‰(kg)", format=",.1f")]
            ).properties(height=260)
            st.altair_chart(ch, use_container_width=True)
        else:
            st.info("ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with c4:
        st.markdown("**ë¶€ì í•© Top ì œí’ˆì½”ë“œ(ìµœê·¼ 30ì¼)**")
        if visc_ok and not top_ng.empty:
            ch = alt.Chart(top_ng).mark_bar().encode(
                y=alt.Y(f"{c_s_pc}:N", sort="-x", title=""),
                x=alt.X("ng_cnt:Q", title="ë¶€ì í•©(ê±´)"),
                tooltip=[alt.Tooltip(f"{c_s_pc}:N", title="ì œí’ˆì½”ë“œ"), alt.Tooltip("ng_cnt:Q", title="ë¶€ì í•©(ê±´)", format=",.0f")]
            ).properties(height=260)
            st.altair_chart(ch, use_container_width=True)
        else:
            st.info("ë¶€ì í•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with st.expander("ğŸ” (ìƒì„¸) ì»¤ë²„ë¦¬ì§€ ê²½ë³´ Top10 ë³´ê¸°"):
        if stock_ok and not cov_alert.empty:
            show = cov_alert.copy()
            show["stock_kg"] = show["stock_kg"].round(1)
            show["avg_daily_use"] = show["avg_daily_use"].round(2)
            show["cover_days"] = show["cover_days"].round(1)
            st.dataframe(show, use_container_width=True, height=320)
        else:
            st.info("ì»¤ë²„ë¦¬ì§€ ê³„ì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==========================================================
# Stock tab
# ==========================================================
def render_stock_tab():
    st.markdown('<div class="section-title">ğŸ“¦ ì•¡ìƒì‰í¬ ì¬ê³ ê´€ë¦¬</div>', unsafe_allow_html=True)
    st.markdown('<div class="section-sub">ì¬ê³ (í˜„ì¬) Â· ì…ê³ (ì¶”ì •) Â· ì‚¬ìš©ëŸ‰(ì¼ë³„)ì„ BLACK/RED ë“± ìƒ‰ìƒê³„ì—´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

    if not stock_xlsx_path or not Path(stock_xlsx_path).exists():
        st.error("ì¬ê³  íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ê³  íŒŒì¼ ê²½ë¡œ/ì—…ë¡œë“œ ì„¤ì •)")
        return

    product_to_color = build_product_to_color_map(spec_single, single_df)
    hist = load_stock_history(stock_xlsx_path, product_to_color)
    if hist.empty:
        st.error("ì¬ê³  ì—‘ì…€ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì‹œíŠ¸ëª…: 1.15 í˜•ì‹ / ì»¬ëŸ¼: í’ˆëª©ëª…, ê¸ˆì¼ ì¬ê³ (kg), í•˜ë£¨ ì‚¬ìš©ëŸ‰(kg) í™•ì¸)")
        return

    min_d = hist["date"].min().date()
    max_d = hist["date"].max().date()

    left, mid, right = st.columns([2.2, 2.8, 5.0])
    with left:
        quick = st.selectbox("ê¸°ê°„(ë¹ ë¥¸ ì„ íƒ)", ["ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ìµœê·¼ 90ì¼", "ì „ì²´", "ì§ì ‘ ì„ íƒ"], index=1)
    with mid:
        if quick == "ì§ì ‘ ì„ íƒ":
            start = st.date_input("ì‹œì‘ì¼", value=max(min_d, max_d - dt.timedelta(days=30)), min_value=min_d, max_value=max_d)
            end = st.date_input("ì¢…ë£Œì¼", value=max_d, min_value=min_d, max_value=max_d)
        else:
            if quick == "ìµœê·¼ 7ì¼":
                start = max(min_d, max_d - dt.timedelta(days=6))
            elif quick == "ìµœê·¼ 30ì¼":
                start = max(min_d, max_d - dt.timedelta(days=29))
            elif quick == "ìµœê·¼ 90ì¼":
                start = max(min_d, max_d - dt.timedelta(days=89))
            else:
                start = min_d
            end = max_d
            st.write(f"**{start} ~ {end}**")
    with right:
        divisions = sorted([x for x in hist["division"].dropna().unique().tolist() if str(x).strip() and str(x).lower() not in ("nan", "none")])
        sel_div = st.multiselect("êµ¬ë¶„(PL/NPL/NSL ë“±)", divisions, default=divisions)

    if start > end:
        start, end = end, start

    filt = (hist["date"].dt.date >= start) & (hist["date"].dt.date <= end)
    if sel_div:
        filt = filt & (hist["division"].isin(sel_div))
    hist_f = hist[filt].copy()

    latest_date = hist["date"].max()
    latest_df = hist[hist["date"] == latest_date].copy()
    if sel_div:
        latest_df = latest_df[latest_df["division"].isin(sel_div)].copy()

    total_stock = float(latest_df["curr_stock_kg"].sum())
    total_used = float(hist_f["used_kg"].sum())
    inbound_events = int(hist_f["inbound_event"].sum())
    day_span = max(1, (end - start).days + 1)
    avg_daily_use = total_used / day_span if day_span else 0.0

    k1, k2, k3, k4, k5 = st.columns([1.4, 1.6, 1.6, 1.6, 1.8])
    k1.metric("ì¬ê³  ìµœì‹ ì¼", latest_date.date().isoformat())
    k2.metric("í˜„ì¬ ì´ ì¬ê³ (kg)", f"{total_stock:,.1f}")
    k3.metric("ê¸°ê°„ ì´ ì‚¬ìš©ëŸ‰(kg)", f"{total_used:,.1f}")
    k4.metric("ê¸°ê°„ ì…ê³ (ê±´)", f"{inbound_events:,}")
    k5.metric("í‰ê·  ì¼ ì‚¬ìš©ëŸ‰(kg/ì¼)", f"{avg_daily_use:,.1f}")

    st.markdown('<div class="kpi-note">â€» ì…ê³ (kg/ê±´)ëŠ” "í•˜ë£¨ ì‚¬ìš©ëŸ‰"ì´ ìŒìˆ˜ë¡œ ê¸°ì…ëœ ê²½ìš°(ì¬ê³  ì¦ê°€)ë¥¼ ì…ê³ ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)
    st.divider()

    inv = latest_df.groupby("color_group", as_index=False)["curr_stock_kg"].sum().rename(columns={"curr_stock_kg":"kg"}).sort_values("kg", ascending=False)
    use = hist_f.groupby("color_group", as_index=False)["used_kg"].sum().rename(columns={"used_kg":"kg"}).sort_values("kg", ascending=False)

    def bar_chart(df: pd.DataFrame, value_title: str):
        if df.empty:
            return None
        return alt.Chart(df).mark_bar().encode(
            y=alt.Y("color_group:N", sort="-x", title="ìƒ‰ìƒê³„ì—´"),
            x=alt.X("kg:Q", title=value_title),
            color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
            tooltip=[alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"), alt.Tooltip("kg:Q", title=value_title, format=",.1f")],
        ).properties(height=240)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### 1) í˜„ì¬ ì¬ê³ (ìµœì‹ ì¼) â€” ìƒ‰ìƒê³„ì—´")
        ch = bar_chart(inv, "ì¬ê³ (kg)")
        st.altair_chart(ch, use_container_width=True) if ch else st.info("í‘œì‹œí•  ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    with c2:
        st.markdown("### 2) ê¸°ê°„ ì‚¬ìš©ëŸ‰ â€” ìƒ‰ìƒê³„ì—´")
        ch = bar_chart(use, "ì‚¬ìš©ëŸ‰(kg)")
        st.altair_chart(ch, use_container_width=True) if ch else st.info("í‘œì‹œí•  ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    st.markdown("### 3) ì¼ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì´(kg)")

    present = [k for k in COLOR_KEYS if k in hist_f["color_group"].unique().tolist()]
    default_keys = [k for k in present if k != "OTHER"][:5] or present
    sel_keys = st.multiselect("í‘œì‹œí•  ìƒ‰ìƒê³„ì—´", COLOR_KEYS, default=default_keys)

    daily = hist_f[hist_f["color_group"].isin(sel_keys)].groupby(["date","color_group"], as_index=False)["used_kg"].sum()
    total = hist_f.groupby("date", as_index=False)["used_kg"].sum().rename(columns={"used_kg":"TOTAL"})

    line = alt.Chart(daily).mark_line(point=True).encode(
        x=alt.X("date:T", title="ë‚ ì§œ"),
        y=alt.Y("used_kg:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
        color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=alt.Legend(title="ìƒ‰ìƒê³„ì—´")),
        tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"), alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"), alt.Tooltip("used_kg:Q", title="ì‚¬ìš©ëŸ‰(kg)", format=",.1f")]
    )
    total_line = alt.Chart(total).mark_line(point=True, strokeDash=[6,3]).encode(
        x="date:T", y=alt.Y("TOTAL:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
        tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"), alt.Tooltip("TOTAL:Q", title="TOTAL(kg)", format=",.1f")]
    )
    st.altair_chart((line + total_line).interactive(), use_container_width=True)

    st.divider()
    st.markdown("### 4) ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼) ê²½ë³´ (í’ˆëª©)")
    target_days = st.slider("ëª©í‘œ ì»¤ë²„ë¦¬ì§€(ì¼)", 3, 30, 14, 1)
    alert_days = st.slider("ê²½ë³´ ê¸°ì¤€(ì¼)", 1, 21, 7, 1)

    use_by_product = hist_f.groupby("product_code", as_index=False)["used_kg"].sum()
    use_by_product["avg_daily_use"] = use_by_product["used_kg"] / day_span
    stock_by_product = latest_df.groupby("product_code", as_index=False)["curr_stock_kg"].sum().rename(columns={"curr_stock_kg":"stock_kg"})
    cov = stock_by_product.merge(use_by_product[["product_code","avg_daily_use"]], on="product_code", how="left")
    cov["avg_daily_use"] = cov["avg_daily_use"].fillna(0.0)
    cov["cover_days"] = cov.apply(lambda r: (r["stock_kg"]/r["avg_daily_use"]) if r["avg_daily_use"]>0 else None, axis=1)
    cov["need_order_kg"] = cov.apply(lambda r: max(0.0, target_days*r["avg_daily_use"]-r["stock_kg"]) if r["avg_daily_use"]>0 else None, axis=1)

    alert_df = cov[(cov["cover_days"].notna()) & (cov["cover_days"] <= float(alert_days))].sort_values("cover_days").head(20)
    if alert_df.empty:
        st.success("âœ… ê²½ë³´ ê¸°ì¤€ ì´í•˜(ì»¤ë²„ë¦¬ì§€ ë¶€ì¡±) í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        tmp = alert_df.copy()
        tmp["stock_kg"] = tmp["stock_kg"].round(1)
        tmp["avg_daily_use"] = tmp["avg_daily_use"].round(2)
        tmp["cover_days"] = tmp["cover_days"].round(1)
        tmp["need_order_kg"] = tmp["need_order_kg"].round(1)
        st.warning(f"âš ï¸ ì»¤ë²„ë¦¬ì§€ {alert_days}ì¼ ì´í•˜ í’ˆëª©(ìƒìœ„ 20ê°œ)")
        st.dataframe(tmp, use_container_width=True, height=360)

# ==========================================================
# Dashboard tab
# ==========================================================
def render_dashboard():
    b_total = len(binder_df)
    s_total = len(single_df)

    c_b_judge = find_col(binder_df, "íŒì •")
    b_ng = int((binder_df[c_b_judge] == "ë¶€ì í•©").sum()) if c_b_judge and (c_b_judge in binder_df.columns) else 0
    s_ng = int((single_df[c_s_judge] == "ë¶€ì í•©").sum()) if c_s_judge and (c_s_judge in single_df.columns) else 0

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ë°”ì¸ë” ê¸°ë¡", f"{b_total:,}")
    c2.metric("ë°”ì¸ë” ë¶€ì í•©", f"{b_ng:,}")
    c3.metric("ë‹¨ì¼ìƒ‰ ê¸°ë¡", f"{s_total:,}")
    c4.metric("ë‹¨ì¼ìƒ‰(ì ë„) ë¶€ì í•©", f"{s_ng:,}")

    st.divider()
    st.subheader("ë‹¨ì¼ìƒ‰ ë°ì´í„° ëª©ë¡(í•„í„°)")

    if not (c_s_date and c_s_visc and c_s_pc and (c_s_date in single_df.columns) and (c_s_visc in single_df.columns) and (c_s_pc in single_df.columns)):
        st.warning("ë‹¨ì¼ìƒ‰ ì‹œíŠ¸ì—ì„œ ì…ê³ ì¼/ì ë„ì¸¡ì •ê°’/ì œí’ˆì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    df = single_df.copy()
    df[c_s_date] = pd.to_datetime(df[c_s_date], errors="coerce")
    dmin, dmax = safe_date_bounds(df[c_s_date])

    f1, f2, f3 = st.columns([1.2, 1.2, 3.0])
    with f1:
        start = st.date_input("ì‹œì‘ì¼", value=max(dmin, dmax - dt.timedelta(days=90)))
    with f2:
        end = st.date_input("ì¢…ë£Œì¼", value=dmax)
    with f3:
        pcs = sorted(df[c_s_pc].dropna().astype(str).unique().tolist())
        sel_pc = st.multiselect("ì œí’ˆì½”ë“œ", pcs, default=[])

    if start > end:
        start, end = end, start

    df = df[(df[c_s_date].dt.date >= start) & (df[c_s_date].dt.date <= end)]
    if sel_pc:
        df = df[df[c_s_pc].astype(str).isin(sel_pc)]

    view = pd.DataFrame({
        "ì…ê³ ì¼": df[c_s_date].dt.date,
        "ìƒ‰ìƒêµ°": df[c_s_cg].apply(normalize_color_group) if c_s_cg and (c_s_cg in df.columns) else None,
        "ì œí’ˆì½”ë“œ": df[c_s_pc],
        "ë‹¨ì¼ìƒ‰Lot": df[c_s_lot] if c_s_lot and (c_s_lot in df.columns) else None,
        "ì‚¬ìš©ë°”ì¸ë”Lot": df[c_s_blot] if c_s_blot and (c_s_blot in df.columns) else None,
        "ì ë„(cP)": pd.to_numeric(df[c_s_visc].astype(str).str.replace(",", "", regex=False), errors="coerce"),
        "ì ë„íŒì •": df[c_s_judge] if c_s_judge and (c_s_judge in df.columns) else None,
    }).dropna(subset=["ì…ê³ ì¼"]).sort_values("ì…ê³ ì¼", ascending=False)

    st.dataframe(view, use_container_width=True, height=320)

# ==========================================================
# Binder IO tab
# ==========================================================
def render_binder_io():
    st.subheader("ë°”ì¸ë” ì…ì¶œê³  ë‚´ì—­ (íŒŒì¼ ì—…ë¡œë“œ / êµ¬ê¸€ì‹œíŠ¸)")
    st.caption("âœ… ë°”ì¸ë” ì…ì¶œê³  ë‚´ì—­ íŒŒì¼(.xlsx)ì„ ì—…ë¡œë“œí•˜ë©´, ì—…ë¡œë“œ ì¦‰ì‹œ ì•„ë˜ì— ì…ì¶œê³  í‘œê°€ ë°”ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")

    binder_io_file = st.file_uploader("ë°”ì¸ë” ì…ì¶œê³  ë‚´ì—­ íŒŒì¼ ì—…ë¡œë“œ(.xlsx)", type=["xlsx"], key="binder_io_upload")
    if binder_io_file is not None:
        try:
            io_data = load_binder_io_excel(binder_io_file.getvalue(), binder_io_file.name)
            st.success("ì—…ë¡œë“œ íŒŒì¼ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
            if "HEMA" in io_data and "Silicone" in io_data:
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown("### HEMA (íŒŒì¼)")
                    st.dataframe(io_data["HEMA"], use_container_width=True, height=420)
                with c2:
                    st.markdown("### Silicone (íŒŒì¼)")
                    st.dataframe(io_data["Silicone"], use_container_width=True, height=420)
            else:
                key = list(io_data.keys())[0]
                st.markdown(f"### {key} (íŒŒì¼)")
                st.dataframe(io_data[key], use_container_width=True, height=520)
        except Exception as e:
            st.error("ì—…ë¡œë“œ íŒŒì¼ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ í˜•ì‹/ì‹œíŠ¸ êµ¬ì¡° í™•ì¸)")
            st.exception(e)

    st.divider()
    st.subheader("ë°”ì¸ë” ì…ì¶œê³  (Google Sheets ìë™ ë°˜ì˜)")
    st.caption("êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ì´ í™”ë©´ì€ ìƒˆë¡œê³ ì¹¨ ì‹œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤. (ìºì‹œ 60ì´ˆ)")

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ëª» ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì‹œíŠ¸ ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/ID í™•ì¸)")
        st.exception(e)
        return

    for _df in [df_hema, df_sil]:
        dc = detect_date_col(_df)
        if dc:
            _df["_sort_date"] = pd.to_datetime(_df[dc], errors="coerce")
            _df.sort_values(by="_sort_date", ascending=False, inplace=True)
            _df.drop(columns=["_sort_date"], inplace=True)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### HEMA (êµ¬ê¸€ì‹œíŠ¸)")
        st.dataframe(df_hema, use_container_width=True, height=420)
    with c2:
        st.markdown("### Silicone (êµ¬ê¸€ì‹œíŠ¸)")
        st.dataframe(df_sil, use_container_width=True, height=420)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"):
        st.cache_data.clear()
        st.rerun()

# ==========================================================
# Search tab
# ==========================================================
def render_search():
    st.subheader("ë¹ ë¥¸ê²€ìƒ‰")
    mode = st.selectbox("ê²€ìƒ‰ ì¢…ë¥˜", ["ë°”ì¸ë” Lot", "ë‹¨ì¼ìƒ‰ Lot", "ì œí’ˆì½”ë“œ"])
    q = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: PCB20250112-01 / PLB25041501 / PL-835-1 ...")

    # prep
    s_df = single_df.copy()
    if c_s_date and (c_s_date in s_df.columns):
        s_df[c_s_date] = pd.to_datetime(s_df[c_s_date], errors="coerce")
    b_df = binder_df.copy()
    if c_b_date and (c_b_date in b_df.columns):
        b_df[c_b_date] = pd.to_datetime(b_df[c_b_date], errors="coerce")

    def text_filter(df: pd.DataFrame, cols: list[str], text: str) -> pd.DataFrame:
        if not text:
            return df.iloc[0:0]
        t = str(text).strip()
        if not t:
            return df.iloc[0:0]
        mask = False
        for c in cols:
            if c and c in df.columns:
                mask = mask | df[c].astype(str).str.contains(t, case=False, na=False)
        return df[mask]

    if mode == "ë°”ì¸ë” Lot":
        c_bl = find_col(b_df, "Lot(ìë™)")
        hit_b = text_filter(b_df, [c_bl], q)
        st.markdown("#### ë°”ì¸ë”_ì œì¡°_ì…ê³ ")
        st.dataframe(add_excel_row_number(hit_b), use_container_width=True)

        if q and c_s_blot and (c_s_blot in s_df.columns):
            hit_s = s_df[s_df[c_s_blot].astype(str).str.contains(str(q).strip(), case=False, na=False)]
            st.markdown("#### ì—°ê²°ëœ ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ (ì‚¬ìš©ëœ ë°”ì¸ë” Lot)")
            st.dataframe(add_excel_row_number(hit_s), use_container_width=True)

    elif mode == "ë‹¨ì¼ìƒ‰ Lot":
        hit = text_filter(s_df, [c_s_lot], q)
        st.dataframe(add_excel_row_number(hit), use_container_width=True)

    else:  # ì œí’ˆì½”ë“œ
        hit = text_filter(s_df, [c_s_pc], q)
        st.dataframe(add_excel_row_number(hit), use_container_width=True)

# ==========================================================
# Render tabs
# ==========================================================
with tab_dash:
    render_dashboard()

with tab_summary:
    render_summary()

with tab_stock:
    render_stock_tab()

with tab_binder:
    render_binder_io()

with tab_search:
    render_search()
