import altair as alt
import streamlit as st
import pandas as pd
import datetime as dt
import re
from pathlib import Path
from io import StringIO
import requests
from openpyxl import load_workbook

st.set_page_config(
    page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬",
    page_icon="ğŸ§ª",
    layout="wide",
)

# =========================================================
# Config
# =========================================================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"  # kg ë‹¨ìœ„ ë°˜í™˜ ê¸°ë¡

COLOR_CODE = {
    "Black": "B",
    "White": "W",
    "Blue": "U",
    "Green": "G",
    "Yellow": "Y",
    "Red": "R",
    "Pink": "P",
}

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"

# =========================================================
# Utils (text / columns)
# =========================================================
def norm_key(x) -> str:
    """ì»¬ëŸ¼/í—¤ë” ë¹„êµë¥¼ ìœ„í•´: ì¤„ë°”ê¿ˆ ì œê±° + ê³µë°± ì •ë¦¬ + ì–‘ë ê³µë°± ì œê±°"""
    if x is None:
        return ""
    s = str(x)
    s = s.replace("\n", " ").replace("\r", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def normalize_df_columns(df: pd.DataFrame) -> pd.DataFrame:
    """pandas DataFrame ì»¬ëŸ¼ëª…ì„ ì •ê·œí™”(ì¤„ë°”ê¿ˆ/ê³µë°±)í•´ì„œ ë‚´ë¶€ ì²˜ë¦¬ ì¼ê´€ì„± í™•ë³´"""
    df = df.copy()
    cols = [norm_key(c) for c in df.columns]
    # ì¤‘ë³µ ì»¬ëŸ¼ëª… ë°©ì§€
    seen = {}
    new_cols = []
    for c in cols:
        if c not in seen:
            seen[c] = 0
            new_cols.append(c)
        else:
            seen[c] += 1
            new_cols.append(f"{c}__{seen[c]}")
    df.columns = new_cols
    return df

def find_col(df: pd.DataFrame, candidates: list[str]) -> str | None:
    """ì •ê·œí™”ëœ ì»¬ëŸ¼ëª… ê¸°ì¤€ìœ¼ë¡œ: (1) ì •í™• ì¼ì¹˜ -> (2) í¬í•¨/ìœ ì‚¬ ë§¤ì¹­"""
    if df is None or df.empty:
        return None
    cols = list(df.columns)
    norm_map = {c: norm_key(c) for c in cols}
    # 1) exact
    cand_norms = [norm_key(c) for c in candidates]
    for c in cols:
        if norm_map[c] in cand_norms:
            return c
    # 2) contains (most strict first)
    for cn in cand_norms:
        for c in cols:
            if cn and (cn in norm_map[c] or norm_map[c].startswith(cn) or cn.startswith(norm_map[c])):
                return c
    return None

def safe_to_float(x):
    if x is None:
        return None
    if isinstance(x, float) and pd.isna(x):
        return None
    if isinstance(x, str) and x.strip() == "":
        return None
    try:
        if isinstance(x, str):
            x = x.replace(",", "")
        return float(x)
    except Exception:
        return None

def normalize_date(x):
    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip() == ""):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        d = pd.to_datetime(x, errors="coerce")
        if pd.isna(d):
            return None
        return d.date()
    except Exception:
        return None

def safe_date_bounds(s: pd.Series):
    s = pd.to_datetime(s, errors="coerce").dropna()
    if len(s) == 0:
        today = dt.date.today()
        return today, today
    return s.min().date(), s.max().date()

def judge_range(value, lo, hi):
    v = safe_to_float(value)
    if v is None:
        return None
    if lo is not None and v < float(lo):
        return "ë¶€ì í•©"
    if hi is not None and v > float(hi):
        return "ë¶€ì í•©"
    return "ì í•©"

def delta_e76(lab1, lab2):
    return float(((lab1[0]-lab2[0])**2 + (lab1[1]-lab2[1])**2 + (lab1[2]-lab2[2])**2) ** 0.5)

# =========================================================
# Google Sheets reader
# =========================================================
@st.cache_data(ttl=60, show_spinner=False)
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))

# =========================================================
# Excel IO
# =========================================================
def ensure_sheet_exists(xlsx_path: str, sheet_name: str, headers: list[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        wb.save(xlsx_path)

@st.cache_data(show_spinner=False)
def load_excel(xlsx_path: str) -> dict:
    """ìºì‹œ ë¡œë”© (ì“°ê¸° í›„ì—ëŠ” st.cache_data.clear() í•„ìš”)"""
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)
    return {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "base_lab": read(SHEET_BASE_LAB),
    }

def append_row_to_sheet_by_norm(xlsx_path: str, sheet_name: str, row_by_norm: dict):
    """ì—‘ì…€ 1í–‰ í—¤ë”(ì›ë³¸) ê¸°ì¤€ìœ¼ë¡œ append. row_by_norm í‚¤ëŠ” norm_key(í—¤ë”)ë¡œ ì¤€ë‹¤."""
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    out = []
    for h in headers:
        if h is None:
            out.append(None)
            continue
        out.append(row_by_norm.get(norm_key(h), None))
    ws.append(out)
    wb.save(xlsx_path)

def append_rows_to_sheet_by_norm(xlsx_path: str, sheet_name: str, rows_by_norm: list[dict]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    for row_by_norm in rows_by_norm:
        out = []
        for h in headers:
            if h is None:
                out.append(None)
                continue
            out.append(row_by_norm.get(norm_key(h), None))
        ws.append(out)
    wb.save(xlsx_path)

# =========================================================
# Spec helpers
# =========================================================
def get_binder_limits(spec_binder: pd.DataFrame, binder_name: str):
    df = spec_binder[spec_binder["ë°”ì¸ë”ëª…"].astype(str) == str(binder_name)].copy()
    visc = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("ì ë„", na=False)]
    uv = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("UV", na=False)]

    visc_lo = safe_to_float(visc["í•˜í•œ"].dropna().iloc[0]) if len(visc["í•˜í•œ"].dropna()) else None
    visc_hi = safe_to_float(visc["ìƒí•œ"].dropna().iloc[0]) if len(visc["ìƒí•œ"].dropna()) else None
    uv_hi = safe_to_float(uv["ìƒí•œ"].dropna().iloc[0]) if len(uv["ìƒí•œ"].dropna()) else None
    rule = df["Lotë¶€ì—¬ê·œì¹™"].dropna().iloc[0] if "Lotë¶€ì—¬ê·œì¹™" in df.columns and len(df["Lotë¶€ì—¬ê·œì¹™"].dropna()) else None
    return visc_lo, visc_hi, uv_hi, rule

def infer_binder_type_from_lot(spec_binder: pd.DataFrame, binder_lot: str):
    """Spec_Binderì˜ Lotë¶€ì—¬ê·œì¹™ prefixë¡œ ë°”ì¸ë”ëª…ì„ ì—­ì¶”ì •(=BinderType(ìë™) ê°’ìœ¼ë¡œ ì‚¬ìš©)"""
    if not binder_lot:
        return None
    lot = str(binder_lot).strip()
    rules = (
        spec_binder[["ë°”ì¸ë”ëª…", "Lotë¶€ì—¬ê·œì¹™"]]
        .dropna()
        .drop_duplicates()
        .to_dict("records")
    )
    for r in rules:
        rule = str(r["Lotë¶€ì—¬ê·œì¹™"]).strip()
        m = re.match(r"^([A-Za-z0-9]+)\+", rule)
        if m and lot.startswith(m.group(1)):
            return str(r["ë°”ì¸ë”ëª…"])
    return None

def next_seq_for_pattern(existing_lots: pd.Series, prefix: str, date_str: str, sep: str = "-"):
    lots = existing_lots.dropna().astype(str).tolist()
    seqs = []
    for lot in lots:
        lot = str(lot).strip()
        if not lot.startswith(prefix + date_str):
            continue
        rest = lot[len(prefix + date_str):]
        if sep and rest.startswith(sep):
            rest = rest[len(sep):]
        m = re.match(r"^(\d+)", rest)
        if m:
            try:
                seqs.append(int(m.group(1)))
            except Exception:
                pass
    return (max(seqs) + 1) if seqs else 1

def generate_binder_lot(spec_binder: pd.DataFrame, binder_name: str, mfg_date: dt.date, existing_binder_lots: pd.Series):
    _, _, _, rule = get_binder_limits(spec_binder, binder_name)
    m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip()) if rule else None
    if not m:
        code = re.sub(r"\W+", "", str(binder_name))[:6].upper()
        return f"{code}{mfg_date.strftime('%Y%m%d')}-01"

    prefix = m.group(1)
    has_seq = bool(m.group(2))
    date_str = mfg_date.strftime("%Y%m%d")
    if has_seq:
        seq = next_seq_for_pattern(existing_binder_lots, prefix, date_str, sep="-")
        return f"{prefix}{date_str}-{seq:02d}"
    return f"{prefix}{date_str}"

def generate_single_lot_prefix(product_code: str, color_group: str, in_date: dt.date):
    code = (product_code or "").strip()
    color_code = COLOR_CODE.get(color_group)
    if not color_code or not in_date:
        return None
    if code.startswith("NPL"):
        prefix = "NPL"
    elif code.startswith("PL"):
        prefix = "PL"
    elif code.startswith("SL") or code.startswith("NSL"):
        prefix = "SL"
    else:
        prefix = "PL"
    date_str = in_date.strftime("%y%m%d")
    return f"{prefix}{color_code}{date_str}"

def compute_single_lots(df: pd.DataFrame, col_in_date: str, col_pc: str, col_cg: str, col_lot_existing: str | None):
    """ê¸°ì¡´ lot ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜(ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤) ì¤‘ë³µì´ ë§ì•„ë„, 'í‘œì‹œìš©' lotë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¬ìƒì„±"""
    out = pd.Series([None] * len(df), index=df.index, dtype="object")

    exist = None
    if col_lot_existing and col_lot_existing in df.columns:
        exist = df[col_lot_existing].astype(str)
        exist = exist.where(~exist.isna(), "")
        exist = exist.replace(["nan", "None"], "", regex=False).astype(str)

    # 1) ê°€ëŠ¥í•œ ê¸°ì¡´ ê°’ ë¨¼ì € ì‚¬ìš©
    if exist is not None:
        out = exist.where(exist.str.strip() != "", None)

    # 2) ë¹„ì–´ìˆëŠ” í–‰ì€ ê·œì¹™ ê¸°ë°˜ ìƒì„± (prefix+date) + seq
    #    seqëŠ” ë™ì¼ prefix+date ì•ˆì—ì„œ ê¸°ì¡´ lotì˜ ìµœëŒ€ seq ì´í›„ë¶€í„° ì´ì–´ì„œ ë¶€ì—¬
    df2 = df.copy()
    df2["_d"] = pd.to_datetime(df2[col_in_date], errors="coerce").dt.date
    df2["_prefix"] = df2.apply(lambda r: generate_single_lot_prefix(str(r.get(col_pc, "")).strip(), str(r.get(col_cg, "")).strip(), r.get("_d")), axis=1)

    # ê¸°ì¡´ seq íŒŒì‹±
    max_seq = {}
    if exist is not None:
        for v, p in zip(exist.tolist(), df2["_prefix"].tolist()):
            if not p:
                continue
            if not v or str(v).strip() == "":
                continue
            sv = str(v).strip()
            if not sv.startswith(p):
                continue
            rest = sv[len(p):]
            m = re.match(r"^(\d{2,})$", rest)
            if m:
                try:
                    max_seq[p] = max(max_seq.get(p, 0), int(m.group(1)))
                except Exception:
                    pass

    # ìƒì„±
    # ë‚ ì§œ/í–‰ìˆœì„œë¡œ ì•ˆì •ì  ì¬í˜„
    order = df2.sort_values(by=["_d"]).index.tolist()
    counters = {}
    for idx in order:
        if pd.notna(out.loc[idx]) and str(out.loc[idx]).strip() != "":
            continue
        p = df2.loc[idx, "_prefix"]
        if not p:
            continue
        if p not in counters:
            counters[p] = max_seq.get(p, 0) + 1
        seq = counters[p]
        counters[p] += 1
        out.loc[idx] = f"{p}{seq:02d}"

    return out

def compute_binder_lots(df: pd.DataFrame, col_date: str, col_name: str, col_lot_existing: str | None, spec_binder: pd.DataFrame):
    """ë°”ì¸ë” lot(í‘œì‹œìš©) ì¬ìƒì„± (ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤ ëŒ€ì‘)"""
    out = pd.Series([None] * len(df), index=df.index, dtype="object")

    exist = None
    if col_lot_existing and col_lot_existing in df.columns:
        exist = df[col_lot_existing].astype(str)
        exist = exist.where(~exist.isna(), "")
        exist = exist.replace(["nan", "None"], "", regex=False).astype(str)
        out = exist.where(exist.str.strip() != "", None)

    # rule prefix ê¸°ë°˜ ìƒì„±
    df2 = df.copy()
    df2["_d"] = pd.to_datetime(df2[col_date], errors="coerce").dt.date
    df2["_name"] = df2[col_name].astype(str).str.strip()

    # rule prefix/seq ì—¬ë¶€
    rule_map = {}
    for _, r in spec_binder.dropna(subset=["ë°”ì¸ë”ëª…", "Lotë¶€ì—¬ê·œì¹™"]).drop_duplicates(subset=["ë°”ì¸ë”ëª…"]).iterrows():
        m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(r["Lotë¶€ì—¬ê·œì¹™"]).strip())
        if m:
            rule_map[str(r["ë°”ì¸ë”ëª…"])] = (m.group(1), bool(m.group(2)))

    # ê¸°ì¡´ seq íŒŒì‹±
    max_seq = {}
    if exist is not None:
        for lot, name, d in zip(exist.tolist(), df2["_name"].tolist(), df2["_d"].tolist()):
            if not lot or str(lot).strip() == "":
                continue
            if not name or name not in rule_map or not d:
                continue
            prefix, has_seq = rule_map[name]
            ds = d.strftime("%Y%m%d")
            base = f"{prefix}{ds}"
            if not str(lot).startswith(base):
                continue
            if has_seq:
                rest = str(lot)[len(base):]
                if rest.startswith("-"):
                    rest = rest[1:]
                m = re.match(r"^(\d+)", rest)
                if m:
                    try:
                        key = (prefix, ds)
                        max_seq[key] = max(max_seq.get(key, 0), int(m.group(1)))
                    except Exception:
                        pass

    counters = {}
    order = df2.sort_values(by=["_d"]).index.tolist()
    for idx in order:
        if pd.notna(out.loc[idx]) and str(out.loc[idx]).strip() != "":
            continue
        name = df2.loc[idx, "_name"]
        d = df2.loc[idx, "_d"]
        if not name or not d or name not in rule_map:
            continue
        prefix, has_seq = rule_map[name]
        ds = d.strftime("%Y%m%d")
        if has_seq:
            key = (prefix, ds)
            if key not in counters:
                counters[key] = max_seq.get(key, 0) + 1
            seq = counters[key]
            counters[key] += 1
            out.loc[idx] = f"{prefix}{ds}-{seq:02d}"
        else:
            out.loc[idx] = f"{prefix}{ds}"

    return out

def compute_single_spec_row(spec_single: pd.DataFrame, color_group: str, product_code: str, binder_type: str | None):
    """Spec_Single_H&Sì—ì„œ ì ë„ í•˜í•œ/ìƒí•œ ì°¾ê¸°"""
    df = spec_single.copy()
    if "ìƒ‰ìƒêµ°" in df.columns:
        df = df[df["ìƒ‰ìƒêµ°"].astype(str) == str(color_group)]
    if "ì œí’ˆì½”ë“œ" in df.columns:
        df = df[df["ì œí’ˆì½”ë“œ"].astype(str) == str(product_code)]
    # BinderType ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í•„í„°
    bt_col = find_col(df, ["BinderType", "BinderType(ìë™)", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë” íƒ€ì…", "Binder Type"])
    if bt_col and binder_type:
        df2 = df[df[bt_col].astype(str) == str(binder_type)]
        if len(df2) > 0:
            df = df2
    if len(df) == 0:
        return None, None
    lo = safe_to_float(df["í•˜í•œ"].iloc[0]) if "í•˜í•œ" in df.columns else None
    hi = safe_to_float(df["ìƒí•œ"].iloc[0]) if "ìƒí•œ" in df.columns else None
    return lo, hi

def extract_or_compute_de76(single_view: pd.DataFrame, base_lab: pd.DataFrame) -> pd.Series:
    base = base_lab.copy()
    if "ì œí’ˆì½”ë“œ" in base.columns:
        base["ì œí’ˆì½”ë“œ"] = base["ì œí’ˆì½”ë“œ"].astype(str).str.strip()

    out = pd.Series([None] * len(single_view), index=single_view.index, dtype="float")

    if "ë¹„ê³ " in single_view.columns:
        pat = re.compile(r"\[\s*Î”E76\s*=\s*([0-9]+(?:\.[0-9]+)?)\s*\]")
        for idx, val in single_view["ë¹„ê³ "].items():
            if pd.isna(val):
                continue
            m = pat.search(str(val))
            if m:
                try:
                    out.loc[idx] = float(m.group(1))
                except Exception:
                    pass

    need_cols = ["ì œí’ˆì½”ë“œ", "ì°©ìƒ‰ë ¥_L*", "ì°©ìƒ‰ë ¥_a*", "ì°©ìƒ‰ë ¥_b*"]
    if all(c in single_view.columns for c in need_cols) and all(c in base.columns for c in ["ê¸°ì¤€_L*", "ê¸°ì¤€_a*", "ê¸°ì¤€_b*", "ì œí’ˆì½”ë“œ"]):
        base_map = base.set_index("ì œí’ˆì½”ë“œ")[["ê¸°ì¤€_L*", "ê¸°ì¤€_a*", "ê¸°ì¤€_b*"]].to_dict("index")
        for idx, row in single_view.iterrows():
            if pd.notna(out.loc[idx]):
                continue
            pc = row.get("ì œí’ˆì½”ë“œ", None)
            if pc is None or pd.isna(pc):
                continue
            pc = str(pc).strip()
            if pc not in base_map:
                continue
            L = safe_to_float(row.get("ì°©ìƒ‰ë ¥_L*", None))
            a = safe_to_float(row.get("ì°©ìƒ‰ë ¥_a*", None))
            b = safe_to_float(row.get("ì°©ìƒ‰ë ¥_b*", None))
            if None in (L, a, b):
                continue
            ref = base_map[pc]
            ref_lab = (safe_to_float(ref["ê¸°ì¤€_L*"]), safe_to_float(ref["ê¸°ì¤€_a*"]), safe_to_float(ref["ê¸°ì¤€_b*"]))
            if None in ref_lab:
                continue
            out.loc[idx] = delta_e76((L, a, b), ref_lab)
    return out

# =========================================================
# Derived views (í•µì‹¬: ì—‘ì…€ ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤ì—ë„ ê°’ì´ ì•ˆ ì‚¬ë¼ì§€ê²Œ "ì•±ì—ì„œ ì¬ê³„ì‚°")
# =========================================================
def build_views(binder_raw: pd.DataFrame, single_raw: pd.DataFrame, spec_binder_raw: pd.DataFrame, spec_single_raw: pd.DataFrame, base_lab_raw: pd.DataFrame):
    binder = normalize_df_columns(binder_raw)
    single = normalize_df_columns(single_raw)
    spec_binder = normalize_df_columns(spec_binder_raw)
    spec_single = normalize_df_columns(spec_single_raw)
    base_lab = normalize_df_columns(base_lab_raw)

    # ---- binder view
    b_date = find_col(binder, ["ì œì¡°/ì…ê³ ì¼", "ì œì¡°ì…ê³ ì¼", "ì…ê³ ì¼", "ì¼ì"])
    b_name = find_col(binder, ["ë°”ì¸ë”ëª…", "Binder", "ë°”ì¸ë”"])
    b_lot = find_col(binder, ["Lot(ìë™)", "Lot", "LOT"])
    b_visc = find_col(binder, ["ì ë„(cP)", "ì ë„", "Viscosity"])
    b_uv = find_col(binder, ["UVí¡ê´‘ë„(ì„ íƒ)", "UVí¡ê´‘ë„", "UV"])

    binder_view = binder.copy()
    if b_date:
        binder_view["_date"] = pd.to_datetime(binder_view[b_date], errors="coerce").dt.date
    else:
        binder_view["_date"] = None

    # lot (í‘œì‹œìš©)
    if b_date and b_name:
        binder_view["_lot_calc"] = compute_binder_lots(binder_view, b_date, b_name, b_lot, spec_binder)
    else:
        binder_view["_lot_calc"] = binder_view[b_lot] if b_lot else None

    # íŒì •(í‘œì‹œìš©) - ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤ ëŒ€ì‘
    if b_name and b_visc:
        lo_hi = {}
        for bn in spec_binder.get("ë°”ì¸ë”ëª…", pd.Series(dtype=object)).dropna().unique().tolist():
            lo, hi, uv_hi, _ = get_binder_limits(spec_binder, bn)
            lo_hi[str(bn)] = (lo, hi, uv_hi)
        def _bj(r):
            name = str(r.get(b_name, "")).strip()
            v = safe_to_float(r.get(b_visc, None))
            u = safe_to_float(r.get(b_uv, None)) if (b_uv and pd.notna(r.get(b_uv, None))) else None
            if name not in lo_hi:
                return None
            lo, hi, uv_hi = lo_hi[name]
            jv = judge_range(v, lo, hi)
            ju = judge_range(u, None, uv_hi) if u is not None else None
            if jv == "ë¶€ì í•©" or ju == "ë¶€ì í•©":
                return "ë¶€ì í•©"
            if jv == "ì í•©" or ju == "ì í•©":
                return "ì í•©"
            return None
        binder_view["_judge_calc"] = binder_view.apply(_bj, axis=1)
    else:
        binder_view["_judge_calc"] = None

    # ---- single view
    s_date = find_col(single, ["ì…ê³ ì¼", "ì œì¡°ì¼ì", "ì œì¡°/ì…ê³ ì¼", "ë‚ ì§œ"])
    s_type = find_col(single, ["ì‰í¬íƒ€ì… (HEMA/Silicone)", "ì‰í¬íƒ€ì…", "InkType"])
    s_cg = find_col(single, ["ìƒ‰ìƒêµ°", "ColorGroup"])
    s_pc = find_col(single, ["ì œí’ˆì½”ë“œ", "ProductCode"])
    s_lot = find_col(single, ["ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot", "ë‹¨ì¼ìƒ‰ì‰í¬Lot", "ë‹¨ì¼ìƒ‰Lot"])
    s_blot = find_col(single, ["ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ì‚¬ìš© ë°”ì¸ë” Lot", "ë°”ì¸ë” Lot", "BinderLot"])
    s_visc = find_col(single, ["ì ë„ì¸¡ì •ê°’(cP)", "ì ë„ì¸¡ì •ê°’ (cP)", "ì ë„(cP)", "ì ë„ì¸¡ì •ê°’"])

    single_view = single.copy()
    single_view["_date"] = pd.to_datetime(single_view[s_date], errors="coerce").dt.date if s_date else None
    # lot calc (ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤ ëŒ€ì‘)
    if s_date and s_pc and s_cg:
        single_view["_lot_calc"] = compute_single_lots(single_view, s_date, s_pc, s_cg, s_lot)
    else:
        single_view["_lot_calc"] = single_view[s_lot] if s_lot else None

    # binder type calc
    if s_blot:
        single_view["_binder_type_calc"] = single_view[s_blot].apply(lambda x: infer_binder_type_from_lot(spec_binder, x))
    else:
        single_view["_binder_type_calc"] = None

    # spec/judge calc
    def _spec_lo(r):
        if not (s_cg and s_pc):
            return None
        return compute_single_spec_row(spec_single, str(r.get(s_cg, "")).strip(), str(r.get(s_pc, "")).strip(), r.get("_binder_type_calc"))[0]
    def _spec_hi(r):
        if not (s_cg and s_pc):
            return None
        return compute_single_spec_row(spec_single, str(r.get(s_cg, "")).strip(), str(r.get(s_pc, "")).strip(), r.get("_binder_type_calc"))[1]

    single_view["_spec_lo"] = single_view.apply(_spec_lo, axis=1) if (s_cg and s_pc) else None
    single_view["_spec_hi"] = single_view.apply(_spec_hi, axis=1) if (s_cg and s_pc) else None

    if s_visc:
        single_view["_visc"] = single_view[s_visc].apply(safe_to_float)
        single_view["_judge"] = single_view.apply(lambda r: judge_range(r.get("_visc"), r.get("_spec_lo"), r.get("_spec_hi")), axis=1)
    else:
        single_view["_visc"] = None
        single_view["_judge"] = None

    # Î”E76
    # NOTE: ì›ë³¸ ì»¬ëŸ¼ëª…(ì°©ìƒ‰ë ¥_*)ëŠ” ì •ê·œí™” í›„ì—ë„ ë™ì¼í•˜ë‹¤ê³  ê°€ì •
    single_view["_Î”E76"] = extract_or_compute_de76(single_view, base_lab)

    # display columns (ì •ê·œí™”ëœ ì›ë³¸ ìœ ì§€ + íŒŒìƒ)
    return binder_view, single_view, spec_binder, spec_single, base_lab

# =========================================================
# Spec editor (ëŒ€ì‹œë³´ë“œì—ì„œ í•˜í•œ/ìƒí•œ ìˆ˜ì •)
# =========================================================
def update_spec_single_bounds(xlsx_path: str, edited_df: pd.DataFrame):
    """Spec_Single_H&S ì‹œíŠ¸ì—ì„œ (ìƒ‰ìƒêµ°, ì œí’ˆì½”ë“œ, BinderType) í‚¤ë¡œ í•˜í•œ/ìƒí•œë§Œ ì—…ë°ì´íŠ¸"""
    wb = load_workbook(xlsx_path)
    if SHEET_SPEC_SINGLE not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {SHEET_SPEC_SINGLE}")
    ws = wb[SHEET_SPEC_SINGLE]

    headers = [c.value for c in ws[1]]
    hmap = {norm_key(h): i+1 for i, h in enumerate(headers) if h is not None}

    # required
    ck = [k for k in ["ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ"] if k not in hmap]
    if ck:
        raise ValueError(f"Spec_Single_H&S í—¤ë” ëˆ„ë½: {ck}")

    col_cg = hmap["ìƒ‰ìƒêµ°"]
    col_pc = hmap["ì œí’ˆì½”ë“œ"]
    col_bt = hmap.get("bindertype") or hmap.get("bindertype(ìë™)") or hmap.get("ë°”ì¸ë”íƒ€ì…") or hmap.get("binder type")
    col_lo = hmap.get("í•˜í•œ")
    col_hi = hmap.get("ìƒí•œ")
    if col_lo is None or col_hi is None:
        raise ValueError("Spec_Single_H&Sì—ì„œ 'í•˜í•œ' ë˜ëŠ” 'ìƒí•œ' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # build key -> row index
    key_to_row = {}
    for r in range(2, ws.max_row + 1):
        cg = ws.cell(row=r, column=col_cg).value
        pc = ws.cell(row=r, column=col_pc).value
        bt = ws.cell(row=r, column=col_bt).value if col_bt else None
        key = (str(cg).strip() if cg is not None else "", str(pc).strip() if pc is not None else "", str(bt).strip() if bt is not None else "")
        key_to_row[key] = r

    updated = 0
    for _, row in edited_df.iterrows():
        cg = str(row.get("ìƒ‰ìƒêµ°", "")).strip()
        pc = str(row.get("ì œí’ˆì½”ë“œ", "")).strip()
        bt = str(row.get("BinderType", "")).strip() if "BinderType" in edited_df.columns else ""
        key = (cg, pc, bt)

        if key not in key_to_row:
            # BinderType ì—†ëŠ” í‚¤ë¡œë„ ì‹œë„
            key2 = (cg, pc, "")
            if key2 not in key_to_row:
                continue
            r = key_to_row[key2]
        else:
            r = key_to_row[key]

        ws.cell(row=r, column=col_lo).value = safe_to_float(row.get("í•˜í•œ", None))
        ws.cell(row=r, column=col_hi).value = safe_to_float(row.get("ìƒí•œ", None))
        updated += 1

    wb.save(xlsx_path)
    return updated

# =========================================================
# UI - File selection
# =========================================================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("âœ… ëŒ€ì‹œë³´ë“œ(ëª©ë¡/í‰ê· /ì¶”ì´)  |  âœ… ì‰í¬ ì…ê³ (ì—‘ì…€ ëˆ„ì )  |  âœ… ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸ ìµœì‹ ìˆœ)  |  âœ… ë°˜í’ˆ(kg) ê¸°ë¡")

with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼")
    xlsx_path = st.text_input(
        "ì—‘ì…€ íŒŒì¼ ê²½ë¡œ",
        value=DEFAULT_XLSX,
        help="ë¡œì»¬ ì‹¤í–‰ ì‹œ, app.pyì™€ ê°™ì€ í´ë”ì— ì—‘ì…€ì„ ë‘ë©´ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(ì—…ë¡œë“œ ëª¨ë“œ: ì„œë²„ ì €ì¥ ë³´ì¥ X)", type=["xlsx"])

# ì—…ë¡œë“œ íŒŒì¼ì€ 'ì²˜ìŒ 1íšŒë§Œ' tmpë¡œ ë³µì‚¬ (rerun ë•Œ ë®ì–´ì“°ê¸° ë°©ì§€)
if uploaded is not None:
    upload_sig = f"{uploaded.name}:{uploaded.size}"
    if st.session_state.get("_uploaded_sig") != upload_sig:
        tmp_path = Path(".streamlit_tmp.xlsx")
        tmp_path.write_bytes(uploaded.getvalue())
        st.session_state["_uploaded_sig"] = upload_sig
        st.session_state["_tmp_xlsx_path"] = str(tmp_path)
    xlsx_path = st.session_state.get("_tmp_xlsx_path", xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì´ ëª¨ë“œì—ì„œëŠ” ì„œë²„ ì¬ì‹œì‘ ì‹œ ëˆ„ì  ë³´ì¥ì´ ì–´ë µìŠµë‹ˆë‹¤.)")

if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.stop()

ensure_sheet_exists(
    xlsx_path,
    SHEET_BINDER_RETURN,
    headers=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "]
)

# Load
raw = load_excel(xlsx_path)
binder_view, single_view, spec_binder, spec_single, base_lab = build_views(
    raw["binder"], raw["single"], raw["spec_binder"], raw["spec_single"], raw["base_lab"]
)

single_ver = str(pd.to_datetime(single_view.get("_date", pd.Series(dtype=object)), errors="coerce").max())

# Tabs
tab_dash, tab_ink_in, tab_binder, tab_search = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "âœï¸ ì‰í¬ ì…ê³ ", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰"]
)

# =========================================================
# Dashboard (ê·¸ë˜í”„/í‘œëŠ” ì—¬ê¸°ë§Œ)
# =========================================================
with tab_dash:
    # KPIs
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ë°”ì¸ë” ê¸°ë¡", f"{len(binder_view):,}")
    c2.metric("ë°”ì¸ë” ë¶€ì í•©(í‘œì‹œìš©)", f"{int((binder_view.get('_judge_calc')=='ë¶€ì í•©').sum()):,}")
    c3.metric("ë‹¨ì¼ìƒ‰ ê¸°ë¡", f"{len(single_view):,}")
    c4.metric("ë‹¨ì¼ìƒ‰(ì ë„) ë¶€ì í•©(í‘œì‹œìš©)", f"{int((single_view.get('_judge')=='ë¶€ì í•©').sum()):,}")

    st.divider()

    # ---- Spec Editor
    with st.expander("ğŸ› ï¸ (ê´€ë¦¬ì) ë‹¨ì¼ìƒ‰ ì ë„ ìŠ¤í™(í•˜í•œ/ìƒí•œ) ìˆ˜ì •", expanded=False):
        st.caption("ëŒ€ì‹œë³´ë“œì—ì„œ **Spec_Single_H&S**ì˜ ì ë„ í•˜í•œ/ìƒí•œì„ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ì¥í•˜ë©´ ì¦‰ì‹œ ê·¸ë˜í”„ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        spec_show_cols = []
        for c in ["ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ"]:
            if c in spec_single.columns:
                spec_show_cols.append(c)
        bt_col = find_col(spec_single, ["BinderType", "BinderType(ìë™)", "ë°”ì¸ë”íƒ€ì…", "binder type"])
        if bt_col:
            spec_show_cols.append(bt_col)
        for c in ["í•˜í•œ", "ìƒí•œ"]:
            if c in spec_single.columns:
                spec_show_cols.append(c)

        spec_df = spec_single[spec_show_cols].copy() if spec_show_cols else spec_single.copy()
        # í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ í‘œì‹œ(í¸ì§‘ìš©)
        if bt_col and bt_col in spec_df.columns:
            spec_df = spec_df.rename(columns={bt_col: "BinderType"})

        edited = st.data_editor(
            spec_df,
            use_container_width=True,
            num_rows="dynamic",
            key="spec_editor",
            hide_index=True
        )

        col_save1, col_save2 = st.columns([1, 5])
        with col_save1:
            if st.button("ìŠ¤í™ ì €ì¥", type="primary"):
                try:
                    updated = update_spec_single_bounds(xlsx_path, edited)
                    st.success(f"ìŠ¤í™ ì €ì¥ ì™„ë£Œ: {updated}í–‰ ì—…ë°ì´íŠ¸")
                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"ìŠ¤í™ ì €ì¥ ì‹¤íŒ¨: {e}")

        with col_save2:
            st.info("â€» ìŠ¤í™ ì €ì¥ì€ **í•˜í•œ/ìƒí•œë§Œ** ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/BinderType ê¸°ì¤€)")

    st.divider()

    # ---- 1) List
    st.subheader("1) ë‹¨ì¼ìƒ‰ ë°ì´í„° ëª©ë¡ (ì—‘ì…€í˜• ë³´ê¸°)")
    need_cols = ["_date", "_lot_calc", "_visc"]
    if any(c not in single_view.columns for c in need_cols):
        st.warning("ë‹¨ì¼ìƒ‰ ë°ì´í„°ì—ì„œ í‘œì‹œìš© íŒŒìƒ ì»¬ëŸ¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì‹œíŠ¸ êµ¬ì¡° í™•ì¸ í•„ìš”)")
        st.caption("í˜„ì¬ ì»¬ëŸ¼: " + ", ".join(list(single_view.columns)[:60]))
    else:
        df_list = single_view.copy()
        df_list["_date"] = pd.to_datetime(df_list["_date"], errors="coerce")
        dmin, dmax = safe_date_bounds(df_list["_date"])

        f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.6, 2.0])
        with f1:
            start = st.date_input("ì‹œì‘ì¼(ëª©ë¡)", value=max(dmin, dmax - dt.timedelta(days=90)), key=f"list_start_{single_ver}")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼(ëª©ë¡)", value=dmax, key=f"list_end_{single_ver}")
        with f3:
            cg_col = find_col(df_list, ["ìƒ‰ìƒêµ°"])
            cg_opts = sorted([x for x in df_list[cg_col].dropna().unique().tolist()]) if cg_col else []
            cg = st.multiselect("ìƒ‰ìƒêµ°(ëª©ë¡)", cg_opts, key=f"list_cg_{single_ver}")
        with f4:
            pc_col = find_col(df_list, ["ì œí’ˆì½”ë“œ"])
            pc_opts = sorted([x for x in df_list[pc_col].dropna().unique().tolist()]) if pc_col else []
            pc = st.multiselect("ì œí’ˆì½”ë“œ(ëª©ë¡)", pc_opts, key=f"list_pc_{single_ver}")

        if start > end:
            start, end = end, start

        df_list = df_list[(df_list["_date"].dt.date >= start) & (df_list["_date"].dt.date <= end)]
        if cg and cg_col:
            df_list = df_list[df_list[cg_col].isin(cg)]
        if pc and pc_col:
            df_list = df_list[df_list[pc_col].isin(pc)]

        blot_col = find_col(df_list, ["ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ë°”ì¸ë” Lot"])
        view = pd.DataFrame({
            "ì œì¡°ì¼ì": df_list["_date"].dt.date,
            "ìƒ‰ìƒêµ°": df_list[cg_col] if cg_col else None,
            "ì œí’ˆì½”ë“œ": df_list[pc_col] if pc_col else None,
            "ë‹¨ì¼ìƒ‰Lot(í‘œì‹œìš©)": df_list["_lot_calc"],
            "ì‚¬ìš©ëœë°”ì¸ë”": df_list[blot_col] if blot_col else None,
            "BinderType(í‘œì‹œìš©)": df_list["_binder_type_calc"],
            "ì ë„(cP)": pd.to_numeric(df_list["_visc"], errors="coerce"),
            "ì ë„í•˜í•œ(í‘œì‹œìš©)": df_list["_spec_lo"],
            "ì ë„ìƒí•œ(í‘œì‹œìš©)": df_list["_spec_hi"],
            "ì ë„íŒì •(í‘œì‹œìš©)": df_list["_judge"],
            "ìƒ‰ì°¨(Î”E76)": df_list["_Î”E76"],
        }).sort_values(by="ì œì¡°ì¼ì", ascending=False)

        st.dataframe(view, use_container_width=True, height=320)

        st.divider()
        st.subheader("1-1) ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì  + ê°’ í‘œì‹œ)")

        mean_df = (
            view.dropna(subset=["ìƒ‰ìƒêµ°", "ì ë„(cP)"])
            .groupby("ìƒ‰ìƒêµ°", as_index=False)["ì ë„(cP)"]
            .mean()
            .rename(columns={"ì ë„(cP)": "í‰ê· ì ë„(cP)"})
        )
        if len(mean_df) == 0:
            st.info("í‘œì‹œí•  í‰ê·  ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            mean_df["í‰ê· ì ë„í‘œì‹œ"] = mean_df["í‰ê· ì ë„(cP)"].round(0).astype("Int64").astype(str)
            base = alt.Chart(mean_df).encode(
                x=alt.X("ìƒ‰ìƒêµ°:N", sort=sorted(mean_df["ìƒ‰ìƒêµ°"].unique().tolist()), title="ìƒ‰ìƒêµ°"),
                y=alt.Y("í‰ê· ì ë„(cP):Q", title="í‰ê·  ì ë„(cP)"),
                tooltip=["ìƒ‰ìƒêµ°:N", "í‰ê· ì ë„(cP):Q"]
            )
            points = base.mark_circle(size=260)
            labels = base.mark_text(dx=10, dy=-10).encode(text="í‰ê· ì ë„í‘œì‹œ:N")
            st.altair_chart((points + labels).interactive(), use_container_width=True)

    st.divider()

    # ---- 2) Trend
    st.subheader("2) ë‹¨ì¼ìƒ‰ ì ë„ ë³€í™” ì¶”ì´ (Lotë³„)")
    st.caption("Lotë³„ ì…ê³ ì¼ ê¸°ì¤€ ì ë„ ë³€í™”ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. (ì  í¬ê²Œ + ë¼ë²¨ + ìŠ¤í™ ë¹¨ê°„ì„ )")

    # required
    cg_col = find_col(single_view, ["ìƒ‰ìƒêµ°"])
    pc_col = find_col(single_view, ["ì œí’ˆì½”ë“œ"])
    blot_col = find_col(single_view, ["ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ë°”ì¸ë” Lot"])

    df = single_view.copy()
    df = df.dropna(subset=["_date", "_visc"])
    df = df[df["_lot_calc"].astype(str).str.strip() != ""]

    if len(df) == 0:
        st.info("ì…ê³ ì¼/ì ë„/Lot ê°’ì´ ë¹„ì–´ìˆì–´ ì¶”ì´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì—‘ì…€ ìˆ˜ì‹ ê²°ê³¼ê°€ ë¹„ì–´ë„ ì•±ì´ ì¬ê³„ì‚°í•´ì•¼ ì •ìƒì¸ë°, í˜„ì¬ëŠ” ì›ì²œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.)")
        with st.expander("ğŸ” ì§„ë‹¨(ì»¬ëŸ¼ í™•ì¸)"):
            st.write("ë‹¨ì¼ìƒ‰ ì»¬ëŸ¼:", list(single_view.columns))
    else:
        dmin, dmax = safe_date_bounds(pd.to_datetime(df["_date"], errors="coerce"))

        f1, f2, f3, f4, f5 = st.columns([1.2, 1.2, 1.6, 2.0, 1.0])
        with f1:
            start = st.date_input("ì‹œì‘ì¼(ì¶”ì´)", value=max(dmin, dmax - dt.timedelta(days=90)), key=f"trend_start_{single_ver}")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼(ì¶”ì´)", value=dmax, key=f"trend_end_{single_ver}")
        with f3:
            cg_opts = sorted([x for x in df[cg_col].dropna().unique().tolist()]) if cg_col else []
            cg = st.multiselect("ìƒ‰ìƒêµ°(ì¶”ì´)", cg_opts, key=f"trend_cg_{single_ver}")
        with f4:
            pc_opts = sorted([x for x in df[pc_col].dropna().unique().tolist()]) if pc_col else []
            pc = st.multiselect("ì œí’ˆì½”ë“œ(ì¶”ì´)", pc_opts, key=f"trend_pc_{single_ver}")
        with f5:
            show_labels = st.checkbox("ë¼ë²¨ í‘œì‹œ", value=True, key=f"trend_labels_{single_ver}")

        if start > end:
            start, end = end, start

        df = df[(pd.to_datetime(df["_date"], errors="coerce").dt.date >= start) & (pd.to_datetime(df["_date"], errors="coerce").dt.date <= end)]
        if cg and cg_col:
            df = df[df[cg_col].isin(cg)]
        if pc and pc_col:
            df = df[df[pc_col].isin(pc)]

        lot_list = sorted(df["_lot_calc"].dropna().unique().tolist())
        default_pick = lot_list[-5:] if len(lot_list) > 5 else lot_list
        pick = st.multiselect("í‘œì‹œí•  ë‹¨ì¼ìƒ‰ Lot(ë³µìˆ˜ ì„ íƒ)", lot_list, default=default_pick, key=f"trend_lots_{single_ver}")
        if pick:
            df = df[df["_lot_calc"].isin(pick)]

        if len(df) == 0:
            st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„/ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë¡œíŠ¸ í•„í„° í™•ì¸)")
        else:
            df = df.copy()
            df["_date_ts"] = pd.to_datetime(df["_date"], errors="coerce")
            df = df.sort_values("_date_ts")
            df["ì ë„í‘œì‹œ"] = pd.to_numeric(df["_visc"], errors="coerce").round(0).astype("Int64").astype(str)

            # ìŠ¤í™ ì„ (ë¹¨ê°„) â€” í•„í„°ëœ ë°ì´í„°ì—ì„œ ëŒ€í‘œê°’ ê²°ì •
            lo_vals = pd.to_numeric(df["_spec_lo"], errors="coerce").dropna().unique().tolist()
            hi_vals = pd.to_numeric(df["_spec_hi"], errors="coerce").dropna().unique().tolist()
            spec_mode = None
            spec_lo = None
            spec_hi = None
            if len(lo_vals) == 1 and len(hi_vals) == 1:
                spec_mode = "unique"
                spec_lo = float(lo_vals[0])
                spec_hi = float(hi_vals[0])
            elif len(lo_vals) + len(hi_vals) > 0:
                # ì—¬ëŸ¬ ìŠ¤í™ì´ ì„ì´ë©´ ëŒ€í‘œê°’ì„ ì„ íƒ
                spec_mode = st.radio(
                    "ìŠ¤í™ ë¹¨ê°„ì„  í‘œì‹œ ë°©ì‹",
                    ["í‘œì‹œ ì•ˆí•¨", "ëŒ€í‘œê°’(ìµœì†Œí•˜í•œ/ìµœëŒ€ìƒí•œ)"],
                    horizontal=True,
                    index=1,
                    key=f"spec_mode_{single_ver}"
                )
                if spec_mode == "ëŒ€í‘œê°’(ìµœì†Œí•˜í•œ/ìµœëŒ€ìƒí•œ)":
                    spec_lo = float(min(lo_vals)) if len(lo_vals) else None
                    spec_hi = float(max(hi_vals)) if len(hi_vals) else None

            tooltip_cols = ["_date_ts:T", "_lot_calc:N", "_visc:Q"]
            if pc_col:
                tooltip_cols.insert(2, f"{pc_col}:N")
            if cg_col:
                tooltip_cols.insert(3, f"{cg_col}:N")
            if blot_col:
                tooltip_cols.append(f"{blot_col}:N")
            tooltip_cols += ["_judge:N"]

            base = alt.Chart(df).encode(
                x=alt.X("_date_ts:T", title="ì…ê³ ì¼"),
                y=alt.Y("_visc:Q", title="ì ë„(cP)"),
                tooltip=tooltip_cols
            )

            line = base.mark_line()
            points = base.mark_point(size=260).encode(color=alt.Color("_lot_calc:N", title="Lot"))

            layers = [line, points]

            if show_labels:
                labels = base.mark_text(dy=-12).encode(
                    color=alt.Color("_lot_calc:N", legend=None),
                    text="ì ë„í‘œì‹œ:N"
                )
                layers.append(labels)

            # spec red lines
            if spec_lo is not None:
                lo_df = pd.DataFrame({"y": [spec_lo], "label": [f"Spec Lower: {spec_lo:,.0f}"]})
                layers.append(
                    alt.Chart(lo_df).mark_rule(color="red").encode(y="y:Q")
                )
                layers.append(
                    alt.Chart(lo_df).mark_text(color="red", align="left", dx=6, dy=-6).encode(
                        y="y:Q",
                        text="label:N"
                    )
                )
            if spec_hi is not None:
                hi_df = pd.DataFrame({"y": [spec_hi], "label": [f"Spec Upper: {spec_hi:,.0f}"]})
                layers.append(
                    alt.Chart(hi_df).mark_rule(color="red").encode(y="y:Q")
                )
                layers.append(
                    alt.Chart(hi_df).mark_text(color="red", align="left", dx=6, dy=-6).encode(
                        y="y:Q",
                        text="label:N"
                    )
                )

            st.altair_chart(alt.layer(*layers).interactive(), use_container_width=True)

    st.divider()
    st.subheader("ìµœê·¼ 20ê±´ (ë‹¨ì¼ìƒ‰, í‘œì‹œìš© Lot/ìŠ¤í™ í¬í•¨)")
    show = single_view.copy()
    show["_date_ts"] = pd.to_datetime(show.get("_date", None), errors="coerce")
    show = show.sort_values(by="_date_ts", ascending=False)
    show_cols = []
    # ì›ë³¸ ì£¼ìš” ì»¬ëŸ¼
    for c in ["ì…ê³ ì¼", "ì‰í¬íƒ€ì… (HEMA/Silicone)", "ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ", "ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ë°”ì¸ë”ì œì¡°ì²˜ (ë‚´ë¶€/ì™¸ì£¼)", "ì ë„ì¸¡ì •ê°’(cP)"]:
        cc = find_col(show, [c])
        if cc:
            show_cols.append(cc)
    # í‘œì‹œìš© íŒŒìƒ
    show_cols += ["_lot_calc", "_binder_type_calc", "_spec_lo", "_spec_hi", "_judge", "_Î”E76"]
    st.dataframe(show[show_cols].head(20), use_container_width=True)

# =========================================================
# ì‰í¬ ì…ê³  (ë‹¨ì¼ìƒ‰ ì…ë ¥)
# =========================================================
with tab_ink_in:
    st.subheader("ë‹¨ì¼ìƒ‰ ì‰í¬ ì…ê³  ì…ë ¥")
    st.info("ì´ íƒ­ì€ **ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬** ì‹œíŠ¸ì— í–‰ì„ ì¶”ê°€(Append)í•˜ì—¬ ëˆ„ì í•©ë‹ˆë‹¤. (ì—‘ì…€ ìˆ˜ì‹ ê¸°ë°˜ ì»¬ëŸ¼ì€ ì•±ì—ì„œ ì¬ê³„ì‚°í•˜ë¯€ë¡œ, ê¸°ì¡´ ë°ì´í„°ê°€ Streamlitì—ì„œ 'ì‚¬ë¼ì§€ì§€' ì•ŠìŠµë‹ˆë‹¤.)")

    # options
    ink_types = ["HEMA", "Silicone"]
    cg_col_spec = find_col(spec_single, ["ìƒ‰ìƒêµ°"])
    pc_col_spec = find_col(spec_single, ["ì œí’ˆì½”ë“œ"])
    color_groups = sorted(spec_single[cg_col_spec].dropna().unique().tolist()) if cg_col_spec else sorted(COLOR_CODE.keys())
    product_codes = sorted(spec_single[pc_col_spec].dropna().unique().tolist()) if pc_col_spec else []

    # binder lot options: binder_viewì˜ í‘œì‹œìš© lot ì‚¬ìš©
    binder_lots = binder_view.get("_lot_calc", pd.Series(dtype=object)).dropna().astype(str).tolist()
    binder_lots = sorted(set([x.strip() for x in binder_lots if x.strip()]), reverse=True)

    with st.form("single_form", clear_on_submit=True):
        col1, col2, col3, col4 = st.columns([1.2, 1.3, 1.5, 2.0])
        with col1:
            in_date = st.date_input("ì…ê³ ì¼", value=dt.date.today(), key="single_in_date")
            ink_type = st.selectbox("ì‰í¬íƒ€ì…", ink_types, key="single_ink_type")
            color_group = st.selectbox("ìƒ‰ìƒêµ°", color_groups, key="single_cg")
        with col2:
            product_code = st.selectbox("ì œí’ˆì½”ë“œ", product_codes, key="single_pc") if product_codes else st.text_input("ì œí’ˆì½”ë“œ(ì§ì ‘ì…ë ¥)", value="", key="single_pc_text")
            binder_lot = st.selectbox("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", binder_lots, key="single_blot") if binder_lots else st.text_input("ì‚¬ìš©ëœ ë°”ì¸ë” Lot(ì§ì ‘ì…ë ¥)", value="", key="single_blot_text")
        with col3:
            visc_meas = st.number_input("ì ë„ì¸¡ì •ê°’(cP)", min_value=0.0, step=1.0, format="%.1f", key="single_visc")
            supplier = st.selectbox("ë°”ì¸ë”ì œì¡°ì²˜", ["ë‚´ë¶€", "ì™¸ì£¼"], index=0, key="single_supplier")
        with col4:
            st.caption("ì„ íƒ: ì°©ìƒ‰ë ¥(L*a*b*) ì…ë ¥ ì‹œ, ê¸°ì¤€LABì´ ìˆìœ¼ë©´ Î”E(76)ì„ ìë™ ê³„ì‚°í•´ 'ë¹„ê³ 'ì— ê¸°ë¡í•©ë‹ˆë‹¤.")
            L = st.number_input("ì°©ìƒ‰ë ¥_L*", value=0.0, step=0.1, format="%.2f", key="single_L")
            a = st.number_input("ì°©ìƒ‰ë ¥_a*", value=0.0, step=0.1, format="%.2f", key="single_a")
            b = st.number_input("ì°©ìƒ‰ë ¥_b*", value=0.0, step=0.1, format="%.2f", key="single_b")
            lab_enabled = st.checkbox("L*a*b* ì…ë ¥í•¨", value=False, key="single_lab_en")

        note = st.text_input("ë¹„ê³ ", value="", key="single_note")
        submit_s = st.form_submit_button("ì €ì¥(ë‹¨ì¼ìƒ‰)")

    if submit_s:
        # normalize direct inputs
        product_code = product_code.strip() if isinstance(product_code, str) else str(product_code).strip()
        binder_lot = binder_lot.strip() if isinstance(binder_lot, str) else str(binder_lot).strip()

        binder_type = infer_binder_type_from_lot(spec_binder, binder_lot)

        lo, hi = compute_single_spec_row(spec_single, color_group, product_code, binder_type)
        visc_judge = judge_range(visc_meas, lo, hi)

        # lot generation (ì•± ê¸°ì¤€)
        # - ê¸°ì¡´ df(í‘œì‹œìš© lot í¬í•¨)ì—ì„œ íŒ¨í„´ë³„ seq ì´ì–´ë¶™ì„
        prefix = generate_single_lot_prefix(product_code, color_group, in_date)
        if not prefix:
            st.error("ë‹¨ì¼ìƒ‰ Lot ìë™ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë‚ ì§œ í™•ì¸)")
        else:
            exist_lots = single_view.get("_lot_calc", pd.Series(dtype=object)).dropna().astype(str)
            # prefix ê¸°ë°˜ ìµœëŒ€ seq
            seqs = []
            for v in exist_lots.tolist():
                sv = str(v).strip()
                if sv.startswith(prefix):
                    rest = sv[len(prefix):]
                    m = re.match(r"^(\d{2,})$", rest)
                    if m:
                        try:
                            seqs.append(int(m.group(1)))
                        except Exception:
                            pass
            seq = (max(seqs) + 1) if seqs else 1
            new_lot = f"{prefix}{seq:02d}"

            # Î”E -> note
            note2 = note
            if lab_enabled:
                base_hit = base_lab[base_lab.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=str)).astype(str).str.strip() == str(product_code).strip()]
                if len(base_hit) == 1 and all(c in base_hit.columns for c in ["ê¸°ì¤€_L*", "ê¸°ì¤€_a*", "ê¸°ì¤€_b*"]):
                    base = (
                        safe_to_float(base_hit.iloc[0]["ê¸°ì¤€_L*"]),
                        safe_to_float(base_hit.iloc[0]["ê¸°ì¤€_a*"]),
                        safe_to_float(base_hit.iloc[0]["ê¸°ì¤€_b*"]),
                    )
                    if None not in base:
                        de = delta_e76((float(L), float(a), float(b)), base)
                        note2 = (note2 + " " if note2 else "") + f"[Î”E76={de:.2f}]"
                    else:
                        note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"
                else:
                    note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"

            # ì—‘ì…€ append (ìˆ˜ì‹ ìºì‹œ ìœ ì‹¤ ì˜í–¥ ìµœì†Œí™”ë¥¼ ìœ„í•´, ìˆ˜ì‹ì—´ë„ 'ê°’'ìœ¼ë¡œ ì±„ì›€)
            row_by_norm = {
                "ì…ê³ ì¼": in_date,
                "ì‰í¬íƒ€ì… (HEMA/Silicone)": ink_type,
                "ìƒ‰ìƒêµ°": color_group,
                "ì œí’ˆì½”ë“œ": product_code,
                "ë‹¨ì¼ìƒ‰ì‰í¬ Lot": new_lot,
                "ì‚¬ìš©ëœ ë°”ì¸ë” Lot": binder_lot,
                "ë°”ì¸ë”ì œì¡°ì²˜ (ë‚´ë¶€/ì™¸ì£¼)": supplier,
                "BinderType(ìë™)": binder_type,
                "ì ë„ì¸¡ì •ê°’(cP)": float(visc_meas),
                "ì ë„í•˜í•œ": lo,
                "ì ë„ìƒí•œ": hi,
                "ì ë„íŒì •": visc_judge,
                "ì°©ìƒ‰ë ¥_L*": float(L) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_a*": float(a) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_b*": float(b) if lab_enabled else None,
                "ë¹„ê³ ": note2,
            }

            try:
                append_row_to_sheet_by_norm(xlsx_path, SHEET_SINGLE, row_by_norm)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë‹¨ì¼ìƒ‰ Lot = {new_lot} / ì ë„íŒì • = {visc_judge}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

# =========================================================
# ë°”ì¸ë” ì…ì¶œê³  (ì…ë ¥/ë°˜í’ˆ/êµ¬ê¸€ì‹œíŠ¸ ë³´ê¸°)
# =========================================================
with tab_binder:
    st.subheader("ì—…ì²´ë°˜í™˜(ë°˜í’ˆ) ì…ë ¥ (kg ë‹¨ìœ„)")
    st.caption("â€» 20kg(1í†µ) ê¸°ì¤€ì´ë”ë¼ë„, ì‹¤ì œ ë°˜í™˜ëŸ‰ì€ kg ë‹¨ìœ„ë¡œ ì…ë ¥í•©ë‹ˆë‹¤. (ì¬ê³ ìš”ì•½ì€ ì œê±°ë¨)")

    binder_names = sorted(spec_binder.get("ë°”ì¸ë”ëª…", pd.Series(dtype=object)).dropna().unique().tolist())
    binder_lots = binder_view.get("_lot_calc", pd.Series(dtype=object)).dropna().astype(str).tolist()
    binder_lots = sorted(set([x.strip() for x in binder_lots if x.strip()]), reverse=True)

    with st.form("binder_return_form", clear_on_submit=True):
        c1, c2, c3 = st.columns([1.2, 1.2, 2.6])
        with c1:
            r_date = st.date_input("ë°˜í™˜ì¼ì", value=dt.date.today(), key="ret_date")
        with c2:
            r_type = st.selectbox("ë°”ì¸ë”íƒ€ì…", ["HEMA", "Silicone"], key="ret_type")
        with c3:
            r_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="ret_name")

        c4, c5, c6 = st.columns([2.0, 1.2, 2.8])
        with c4:
            r_lot = st.selectbox("ë°”ì¸ë” Lot(ì„ íƒ)", ["(ì§ì ‘ì…ë ¥)"] + binder_lots, key="ret_lot_sel")
            r_lot_text = st.text_input("ë°”ì¸ë” Lot ì§ì ‘ì…ë ¥", value="", key="ret_lot_text") if r_lot == "(ì§ì ‘ì…ë ¥)" else ""
            final_lot = r_lot_text.strip() if r_lot == "(ì§ì ‘ì…ë ¥)" else r_lot
        with c5:
            r_kg = st.number_input("ë°˜í™˜ëŸ‰(kg)", min_value=0.0, step=0.5, format="%.1f", key="ret_kg")
        with c6:
            r_note = st.text_input("ë¹„ê³ ", value="", key="ret_note")

        submit_ret = st.form_submit_button("ë°˜í’ˆ ì €ì¥")

    if submit_ret:
        if r_kg <= 0:
            st.error("ë°˜í™˜ëŸ‰(kg)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        else:
            row_by_norm = {
                "ì¼ì": r_date,
                "ë°”ì¸ë”íƒ€ì…": r_type,
                "ë°”ì¸ë”ëª…": r_name,
                "ë°”ì¸ë” Lot": final_lot,
                "ë°˜í™˜ëŸ‰(kg)": float(r_kg),
                "ë¹„ê³ ": r_note,
            }
            try:
                append_row_to_sheet_by_norm(xlsx_path, SHEET_BINDER_RETURN, row_by_norm)
                st.success("ë°˜í’ˆ ì €ì¥ ì™„ë£Œ!")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ë°˜í’ˆ ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()

    st.subheader("ë°”ì¸ë” ì…ë ¥ (ì œì¡°/ì…ê³ ) â€” ì—¬ëŸ¬ Lot/ë‚ ì§œ ì¼ê´„ ì…ë ¥ ì§€ì›")
    st.caption("â€» ë°”ì¸ë”ëŠ” ì—¬ëŸ¬ ë‚ ì§œì˜ Lotê°€ í•œ ë²ˆì— ì…ê³ ë  ìˆ˜ ìˆì–´, ë‚ ì§œë³„/ìˆ˜ëŸ‰ë³„ë¡œ ë¬¶ìŒ ì…ë ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.")

    input_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ê°œë³„ ì…ë ¥", "ë¬¶ìŒ ì…ë ¥(ì—¬ëŸ¬ ë‚ ì§œ/ìˆ˜ëŸ‰)"], horizontal=True, key="binder_input_mode")

    # ê¸°ì¡´ ë°”ì¸ë” lot ê³„ì‚°ìš© existing
    existing_binder_lots = binder_view.get("_lot_calc", pd.Series(dtype=str)).dropna().astype(str)

    if input_mode == "ê°œë³„ ì…ë ¥":
        with st.form("binder_form_single", clear_on_submit=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                mfg_date = st.date_input("ì œì¡°/ì…ê³ ì¼", value=dt.date.today(), key="b_single_date")
                b_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="b_single_name")
            with col2:
                visc = st.number_input("ì ë„(cP)", min_value=0.0, step=1.0, format="%.1f", key="b_single_visc")
                uv = st.number_input("UVí¡ê´‘ë„(ì„ íƒ)", min_value=0.0, step=0.01, format="%.3f", key="b_single_uv")
                uv_enabled = st.checkbox("UV ê°’ ì…ë ¥í•¨", value=False, key="b_single_uv_en")
            with col3:
                note = st.text_input("ë¹„ê³ ", value="", key="b_single_note")
                submit_b = st.form_submit_button("ì €ì¥(ë°”ì¸ë”)")

        if submit_b:
            visc_lo, visc_hi, uv_hi, _ = get_binder_limits(spec_binder, b_name)
            lot = generate_binder_lot(spec_binder, b_name, mfg_date, existing_binder_lots)
            judge_v = judge_range(visc, visc_lo, visc_hi)
            judge_u = judge_range(uv if uv_enabled else None, None, uv_hi)
            judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

            row_by_norm = {
                "ì œì¡°/ì…ê³ ì¼": mfg_date,
                "ë°”ì¸ë”ëª…": b_name,
                "Lot(ìë™)": lot,
                "ì ë„(cP)": float(visc),
                "UVí¡ê´‘ë„(ì„ íƒ)": float(uv) if uv_enabled else None,
                "íŒì •": judge,
                "ë¹„ê³ ": note,
            }
            try:
                append_row_to_sheet_by_norm(xlsx_path, SHEET_BINDER, row_by_norm)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë°”ì¸ë” Lot = {lot}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    else:
        st.caption("ì•„ë˜ í‘œì— ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰(í†µ)/ì ë„/UV/ë¹„ê³ ë¥¼ ì…ë ¥í•˜ê³ , í•œ ë²ˆì— ì €ì¥í•˜ì„¸ìš”.")
        base_rows = st.session_state.get("binder_batch_rows")
        if base_rows is None:
            base_rows = [
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today(), "ë°”ì¸ë”ëª…": binder_names[0] if binder_names else "", "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today() - dt.timedelta(days=1), "ë°”ì¸ë”ëª…": binder_names[0] if binder_names else "", "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
                {"ì œì¡°/ì…ê³ ì¼": dt.date.today() - dt.timedelta(days=2), "ë°”ì¸ë”ëª…": binder_names[0] if binder_names else "", "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
            ]
        edit_df = pd.DataFrame(base_rows)
        edit_df = st.data_editor(edit_df, use_container_width=True, num_rows="dynamic", key="binder_batch_editor")
        submit_batch = st.button("ë¬¶ìŒ ì €ì¥(ë°”ì¸ë”)", type="primary", key="binder_batch_submit")

        if submit_batch:
            tmp = edit_df.copy()
            tmp["ì œì¡°/ì…ê³ ì¼"] = tmp["ì œì¡°/ì…ê³ ì¼"].apply(normalize_date)
            tmp["ìˆ˜ëŸ‰(í†µ)"] = pd.to_numeric(tmp["ìˆ˜ëŸ‰(í†µ)"], errors="coerce").fillna(0).astype(int)
            tmp["ì ë„(cP)"] = pd.to_numeric(tmp["ì ë„(cP)"].astype(str).str.replace(",", "", regex=False), errors="coerce")

            tmp = tmp.dropna(subset=["ì œì¡°/ì…ê³ ì¼", "ë°”ì¸ë”ëª…", "ì ë„(cP)"])
            tmp = tmp[tmp["ìˆ˜ëŸ‰(í†µ)"] > 0]
            if len(tmp) == 0:
                st.error("ì €ì¥í•  í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰/ì ë„ ì…ë ¥ í™•ì¸)")
                st.stop()

            existing_list = existing_binder_lots.dropna().astype(str).tolist()
            seq_counters = {}
            rows_out, preview_out = [], []
            tmp = tmp.sort_values(by="ì œì¡°/ì…ê³ ì¼")

            for _, r in tmp.iterrows():
                mfg_date = r["ì œì¡°/ì…ê³ ì¼"]
                b_name = str(r["ë°”ì¸ë”ëª…"]).strip()
                qty = int(r["ìˆ˜ëŸ‰(í†µ)"])
                visc = safe_to_float(r["ì ë„(cP)"])
                uv_enabled = bool(r.get("UVì…ë ¥", False))
                uv_val = safe_to_float(r.get("UVí¡ê´‘ë„(ì„ íƒ)", None)) if uv_enabled else None
                note = str(r.get("ë¹„ê³ ", "")).strip()

                visc_lo, visc_hi, uv_hi, rule = get_binder_limits(spec_binder, b_name)
                m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip()) if rule else None
                if not m:
                    st.error(f"[{b_name}] Lotë¶€ì—¬ê·œì¹™ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Spec_Binder í™•ì¸ í•„ìš”)")
                    st.stop()

                prefix = m.group(1)
                has_seq = bool(m.group(2))
                date_str = mfg_date.strftime("%Y%m%d")

                if (not has_seq) and qty > 1:
                    st.error(f"[{b_name}] Lotë¶€ì—¬ê·œì¹™ì— ìˆœë²ˆ(-##)ì´ ì—†ì–´ ì—¬ëŸ¬ í†µ(ìˆ˜ëŸ‰={qty})ì„ ìë™ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                key = (prefix, date_str)
                if key not in seq_counters:
                    seq_counters[key] = next_seq_for_pattern(pd.Series(existing_list), prefix, date_str, sep="-")

                for _i in range(qty):
                    if has_seq:
                        seq = seq_counters[key]
                        seq_counters[key] += 1
                        lot = f"{prefix}{date_str}-{seq:02d}"
                    else:
                        lot = f"{prefix}{date_str}"

                    judge_v = judge_range(visc, visc_lo, visc_hi)
                    judge_u = judge_range(uv_val, None, uv_hi) if uv_enabled else None
                    judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

                    row_by_norm = {
                        "ì œì¡°/ì…ê³ ì¼": mfg_date,
                        "ë°”ì¸ë”ëª…": b_name,
                        "Lot(ìë™)": lot,
                        "ì ë„(cP)": float(visc) if visc is not None else None,
                        "UVí¡ê´‘ë„(ì„ íƒ)": float(uv_val) if uv_enabled and uv_val is not None else None,
                        "íŒì •": judge,
                        "ë¹„ê³ ": note,
                    }
                    rows_out.append(row_by_norm)
                    preview_out.append(row_by_norm)
                    existing_list.append(lot)

            st.write("ì €ì¥ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 50ê±´)")
            st.dataframe(pd.DataFrame(preview_out).tail(50), use_container_width=True)

            try:
                append_rows_to_sheet_by_norm(xlsx_path, SHEET_BINDER, rows_out)
                st.success(f"ë¬¶ìŒ ì €ì¥ ì™„ë£Œ! ì´ {len(rows_out)}ê±´ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()
    st.subheader("ë°”ì¸ë” ì…ì¶œê³  (Google Sheets ìë™ ë°˜ì˜, ìµœì‹ ìˆœ)")
    st.caption("êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ì´ í™”ë©´ì€ ìƒˆë¡œê³ ì¹¨ ì‹œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤. (ìºì‹œ 60ì´ˆ)")

    def detect_date_col(df: pd.DataFrame):
        candidates = []
        for c in df.columns:
            ck = norm_key(c)
            if any(k in ck for k in ["ì¼ì", "ë‚ ì§œ", "date", "ì…ê³ ì¼", "ì¶œê³ ì¼"]):
                candidates.append(c)
        return candidates[0] if candidates else None

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ëª» ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì‹œíŠ¸ ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/ID í™•ì¸)")
        st.exception(e)
        st.stop()

    for _df in [df_hema, df_sil]:
        dc = detect_date_col(_df)
        if dc:
            _df["_sort_date"] = pd.to_datetime(_df[dc], errors="coerce")
            _df.sort_values(by="_sort_date", ascending=False, inplace=True)
            _df.drop(columns=["_sort_date"], inplace=True)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### HEMA (ìµœì‹ ìˆœ)")
        st.dataframe(df_hema, use_container_width=True, height=420)
    with c2:
        st.markdown("### Silicone (ìµœì‹ ìˆœ)")
        st.dataframe(df_sil, use_container_width=True, height=420)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key="binder_refresh"):
        st.cache_data.clear()
        st.rerun()

# =========================================================
# Search (placeholder)
# =========================================================
with tab_search:
    st.info("ë¹ ë¥¸ê²€ìƒ‰ì€ í•„ìš”í•˜ì‹œë©´ ì¡°ê±´(ê¸°ê°„/ì œí’ˆ/ìƒ‰ìƒêµ°/ë°”ì¸ë”Lot/íŒì •)ê¹Œì§€ í™•ì¥í•´ë“œë¦´ê²Œìš”.")
