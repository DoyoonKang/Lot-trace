import altair as alt
import streamlit as st
import pandas as pd
import datetime as dt
import re
from pathlib import Path
from openpyxl import load_workbook
import requests
from io import StringIO
from typing import Optional, List, Dict


# =========================
# Page Config (ë”± 1ë²ˆë§Œ!)
# =========================
st.set_page_config(
    page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬",
    page_icon="ğŸ§ª",
    layout="wide",
)


# =========================
# Google Sheets (Public) Reader
# =========================
@st.cache_data(ttl=60, show_spinner=False)
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))


# =========================
# Config
# =========================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BINDER_VISC = "Binder_Visc"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"

# ì—…ì²´ ë°˜í™˜(ë°˜í’ˆ) ê¸°ë¡ìš© ì‹œíŠ¸
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"

COLOR_CODE = {
    "Black": "B",
    "White": "W",
    "Blue": "U",
    "Green": "G",
    "Yellow": "Y",
    "Red": "R",
    "Pink": "P",
}

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"


# =========================
# Helpers
# =========================
def _read_excel_from_path(xlsx_path: str) -> Dict[str, pd.DataFrame]:
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)

    return {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "binder_visc": read(SHEET_BINDER_VISC),
        "base_lab": read(SHEET_BASE_LAB),
    }


@st.cache_data(show_spinner=False)
def load_data(xlsx_path: str) -> Dict[str, pd.DataFrame]:
    return _read_excel_from_path(xlsx_path)


def normalize_date(x):
    if pd.isna(x):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        return pd.to_datetime(x).date()
    except Exception:
        return None


def delta_e76(lab1, lab2):
    return float(((lab1[0] - lab2[0]) ** 2 + (lab1[1] - lab2[1]) ** 2 + (lab1[2] - lab2[2]) ** 2) ** 0.5)


def extract_delta_e_from_note(note: str):
    if note is None or pd.isna(note):
        return None
    s = str(note)
    m = re.search(r"\[Î”E76=([0-9]+(?:\.[0-9]+)?)\]", s)
    if m:
        try:
            return float(m.group(1))
        except Exception:
            return None
    return None


def get_binder_limits(spec_binder: pd.DataFrame, binder_name: str):
    df = spec_binder[spec_binder["ë°”ì¸ë”ëª…"] == binder_name].copy()
    visc = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("ì ë„", na=False)]
    uv = df[df["ì‹œí—˜í•­ëª©"].astype(str).str.contains("UV", na=False)]

    visc_lo = float(visc["í•˜í•œ"].dropna().iloc[0]) if len(visc["í•˜í•œ"].dropna()) else None
    visc_hi = float(visc["ìƒí•œ"].dropna().iloc[0]) if len(visc["ìƒí•œ"].dropna()) else None
    uv_hi = float(uv["ìƒí•œ"].dropna().iloc[0]) if len(uv["ìƒí•œ"].dropna()) else None
    rule = (
        df["Lotë¶€ì—¬ê·œì¹™"].dropna().iloc[0]
        if "Lotë¶€ì—¬ê·œì¹™" in df.columns and len(df["Lotë¶€ì—¬ê·œì¹™"].dropna())
        else None
    )
    return visc_lo, visc_hi, uv_hi, rule


def parse_binder_rule_prefix(rule: Optional[str], binder_name_fallback: str):
    if rule:
        m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip())
        if m:
            prefix = m.group(1)
            has_seq = bool(m.group(2))
            return prefix, has_seq
    prefix = re.sub(r"\W+", "", str(binder_name_fallback))[:6].upper()
    return prefix, True


def infer_binder_type_from_lot(spec_binder: pd.DataFrame, binder_lot: str):
    if not binder_lot:
        return None
    rules = (
        spec_binder[["ë°”ì¸ë”ëª…", "Lotë¶€ì—¬ê·œì¹™"]]
        .dropna()
        .drop_duplicates()
        .to_dict("records")
    )
    for r in rules:
        rule = str(r["Lotë¶€ì—¬ê·œì¹™"])
        m = re.match(r"^([A-Za-z0-9]+)\+", rule)
        if m:
            prefix = m.group(1)
            if str(binder_lot).startswith(prefix):
                return r["ë°”ì¸ë”ëª…"]
    return None


def next_seq_for_pattern(existing_lots: pd.Series, prefix: str, date_str: str, sep: str = "-"):
    lots = existing_lots.dropna().astype(str).tolist()
    seqs = []
    for lot in lots:
        if not lot.startswith(prefix + date_str):
            continue
        rest = lot[len(prefix + date_str):]
        if sep and rest.startswith(sep):
            rest = rest[len(sep):]
        m = re.match(r"^(\d+)", rest)
        if m:
            try:
                seqs.append(int(m.group(1)))
            except Exception:
                pass
    return (max(seqs) + 1) if seqs else 1


def generate_binder_lot(prefix: str, mfg_date: dt.date, seq: Optional[int]):
    date_str = mfg_date.strftime("%Y%m%d")
    if seq is None:
        return f"{prefix}{date_str}"
    return f"{prefix}{date_str}-{seq:02d}"


def generate_single_lot(single_df: pd.DataFrame, product_code: str, color_group: str, in_date: dt.date):
    code = (product_code or "").strip()
    color_code = COLOR_CODE.get(color_group)
    if not color_code:
        return None

    if code.startswith("NPL"):
        prefix = "NPL"
    elif code.startswith("PL"):
        prefix = "PL"
    elif code.startswith("SL") or code.startswith("NSL"):
        prefix = "SL"
    else:
        prefix = "PL"

    date_str = in_date.strftime("%y%m%d")
    patt_prefix = f"{prefix}{color_code}{date_str}"
    lots = single_df.get("ë‹¨ì¼ìƒ‰ì‰í¬ Lot", pd.Series(dtype=str)).dropna().astype(str).tolist()

    seqs = []
    for lot in lots:
        if lot.startswith(patt_prefix):
            rest = lot[len(patt_prefix):]
            m = re.match(r"^(\d{2,})", rest)
            if m:
                seqs.append(int(m.group(1)))
    seq = (max(seqs) + 1) if seqs else 1
    return f"{patt_prefix}{seq:02d}"


def judge_range(value, lo, hi):
    if value is None or pd.isna(value):
        return None
    try:
        v = float(value)
    except Exception:
        return None
    if lo is not None and v < float(lo):
        return "ë¶€ì í•©"
    if hi is not None and v > float(hi):
        return "ë¶€ì í•©"
    return "ì í•©"


def ensure_sheet_with_headers(xlsx_path: str, sheet_name: str, headers: List[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        wb.save(xlsx_path)


def append_row_to_sheet(xlsx_path: str, sheet_name: str, row: dict):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    values = [row.get(h, None) for h in headers]
    ws.append(values)
    wb.save(xlsx_path)


def append_rows_to_sheet(xlsx_path: str, sheet_name: str, rows: List[dict]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    for row in rows:
        values = [row.get(h, None) for h in headers]
        ws.append(values)
    wb.save(xlsx_path)


def df_quick_filter(df: pd.DataFrame, text: str, cols: List[str]):
    if not text:
        return df
    t = str(text).strip()
    if not t:
        return df
    mask = False
    for c in cols:
        if c not in df.columns:
            continue
        mask = mask | df[c].astype(str).str.contains(t, case=False, na=False)
    return df[mask]


def sort_df_by_any_date_col(df: pd.DataFrame):
    if df is None or len(df) == 0:
        return df
    candidates = ["ì¼ì", "ë‚ ì§œ", "ì…ì¶œê³ ì¼", "ì…ê³ ì¼", "ì¶œê³ ì¼", "Date", "date"]
    hit = None
    for c in candidates:
        if c in df.columns:
            hit = c
            break
    if hit is None:
        return df
    tmp = df.copy()
    tmp["_sort_date"] = pd.to_datetime(tmp[hit], errors="coerce")
    tmp = tmp.sort_values("_sort_date", ascending=False).drop(columns=["_sort_date"])
    return tmp


# =========================
# UI Header
# =========================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("ìƒì‚¬ìš©(ìš”ì•½â†’í‘œâ†’ê·¸ë˜í”„) íë¦„ìœ¼ë¡œ í•œëˆˆì— ë³´ì´ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.")


# =========================
# Data file selection (Excel)
# =========================
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼")
    xlsx_path_input = st.text_input(
        "ì—‘ì…€ íŒŒì¼ ê²½ë¡œ(ê¶Œì¥)",
        value=DEFAULT_XLSX,
        help="ê°€ëŠ¥í•˜ë©´ íŒŒì¼ ê²½ë¡œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹œëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤."
    )
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(ì—…ë¡œë“œ ëª¨ë“œëŠ” ì„¸ì…˜/ë‹¤ìš´ë¡œë“œ ë°©ì‹)", type=["xlsx"])

# ì—…ë¡œë“œ ëª¨ë“œ: ìµœì´ˆ 1íšŒë§Œ tmpì— ì €ì¥í•˜ê³ , ì´í›„ rerun ë•Œ ë®ì–´ì“°ì§€ ì•ŠìŒ
xlsx_path = xlsx_path_input
if uploaded is not None:
    if "_work_xlsx_path" not in st.session_state:
        tmp_path = Path(st.session_state.get("_tmp_xlsx_path", "WORK_LotTrace.xlsx"))
        tmp_path.write_bytes(uploaded.getvalue())
        st.session_state["_work_xlsx_path"] = str(tmp_path)
        st.session_state["_uploaded_bytes"] = uploaded.getvalue()
    xlsx_path = st.session_state["_work_xlsx_path"]

    st.sidebar.info("ì—…ë¡œë“œ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì…ë ¥ ëˆ„ì ì€ í˜„ì¬ ì„¸ì…˜ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    try:
        current_bytes = Path(xlsx_path).read_bytes()
        st.sidebar.download_button(
            "í˜„ì¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ(ëˆ„ì ë³¸)",
            data=current_bytes,
            file_name="ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_UPDATED.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    except Exception:
        pass

    if st.sidebar.button("ì—…ë¡œë“œ ì›ë³¸ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°(ì´ˆê¸°í™”)"):
        Path(xlsx_path).write_bytes(st.session_state.get("_uploaded_bytes", uploaded.getvalue()))
        st.cache_data.clear()
        st.rerun()

if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.stop()

# ë°˜í’ˆ ì‹œíŠ¸ ë³´ì¥
ensure_sheet_with_headers(
    xlsx_path,
    SHEET_BINDER_RETURN,
    headers=["ë°˜í’ˆì¼ì", "ë°”ì¸ë”ëª…", "ê´€ë ¨ Lot(ì„ íƒ)", "ë°˜í’ˆìˆ˜ëŸ‰(kg)", "ë¹„ê³ "]
)

data = load_data(xlsx_path)
binder_df = data["binder"].copy()
single_df = data["single"].copy()
spec_binder = data["spec_binder"].copy()
spec_single = data["spec_single"].copy()
base_lab = data["base_lab"].copy()

if "ì œì¡°/ì…ê³ ì¼" in binder_df.columns:
    binder_df["ì œì¡°/ì…ê³ ì¼"] = binder_df["ì œì¡°/ì…ê³ ì¼"].apply(normalize_date)
if "ì…ê³ ì¼" in single_df.columns:
    single_df["ì…ê³ ì¼"] = single_df["ì…ê³ ì¼"].apply(normalize_date)


# =========================
# Tabs
# =========================
tab_dash, tab_ink_in, tab_binder, tab_search = st.tabs(
    ["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "âœï¸ ì‰í¬ ì…ê³ ", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰"]
)


# =========================
# 1) Dashboard (í‘œ/ê·¸ë˜í”„ëŠ” ì—¬ê¸°ë§Œ)
# =========================
with tab_dash:
    with st.expander("ğŸ“Œ ì´ í™”ë©´(ëŒ€ì‹œë³´ë“œ) ì½ëŠ” ë°©ë²•", expanded=True):
        st.markdown(
            """
- **ìƒë‹¨ ìš”ì•½**: ìµœê·¼ 30ì¼ ê¸°ì¤€ *ì…ê³ /ë¶€ì í•©/í‰ê·  ì ë„/ìµœì‹ ì¼*ì„ í•œ ë²ˆì— ë´…ë‹ˆë‹¤.  
- **ë‹¨ì¼ìƒ‰ í‘œ(ì—‘ì…€í˜•)**: ê¸°ê°„/ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë°”ì¸ë”Lot/ê²€ìƒ‰ìœ¼ë¡œ ì¢í˜€ì„œ í™•ì¸í•©ë‹ˆë‹¤.  
- **ìƒ‰ìƒêµ° í‰ê·  ì ë„(ì +ê°’)**: ìƒ‰ìƒêµ° í‰ê· ë§Œ ë¹ ë¥´ê²Œ ë¹„êµí•©ë‹ˆë‹¤.  
- **Lot ì¶”ì´**: ì„ íƒ Lotì˜ ì ë„ ë³€í™”ë¥¼ ì‹œê°„ ìˆœìœ¼ë¡œ ë´…ë‹ˆë‹¤.
            """
        )

    st.divider()

    today = dt.date.today()
    days = 30

    s_df = single_df.copy()
    s_df["_ì…ê³ ì¼_dt"] = pd.to_datetime(s_df.get("ì…ê³ ì¼", pd.Series(dtype=str)), errors="coerce")
    s_recent = s_df[s_df["_ì…ê³ ì¼_dt"].dt.date >= (today - dt.timedelta(days=days))].copy()
    s_recent_total = len(s_recent)
    s_recent_ng = int((s_recent.get("ì ë„íŒì •", pd.Series(dtype=str)) == "ë¶€ì í•©").sum()) if "ì ë„íŒì •" in s_recent.columns else 0
    s_recent_ng_rate = (s_recent_ng / s_recent_total * 100.0) if s_recent_total else 0.0
    s_recent_mean = float(pd.to_numeric(s_recent.get("ì ë„ì¸¡ì •ê°’(cP)", pd.Series(dtype=float)), errors="coerce").dropna().mean()) if s_recent_total else 0.0
    s_latest = s_df["_ì…ê³ ì¼_dt"].max()
    s_latest_txt = s_latest.date().isoformat() if pd.notna(s_latest) else "-"

    b_df = binder_df.copy()
    b_df["_ì¼ì_dt"] = pd.to_datetime(b_df.get("ì œì¡°/ì…ê³ ì¼", pd.Series(dtype=str)), errors="coerce")
    b_recent = b_df[b_df["_ì¼ì_dt"].dt.date >= (today - dt.timedelta(days=days))].copy()
    b_recent_total = len(b_recent)
    b_recent_ng = int((b_recent.get("íŒì •", pd.Series(dtype=str)) == "ë¶€ì í•©").sum()) if "íŒì •" in b_recent.columns else 0
    b_latest = b_df["_ì¼ì_dt"].max()
    b_latest_txt = b_latest.date().isoformat() if pd.notna(b_latest) else "-"

    c1, c2, c3, c4, c5 = st.columns([1.3, 1.3, 1.3, 1.3, 1.8])
    c1.metric(f"ìµœê·¼ {days}ì¼ ë‹¨ì¼ìƒ‰ ì…ê³ ", f"{s_recent_total:,}")
    c2.metric(f"ìµœê·¼ {days}ì¼ ë‹¨ì¼ìƒ‰ ë¶€ì í•©", f"{s_recent_ng:,}", f"{s_recent_ng_rate:.1f}%")
    c3.metric(f"ìµœê·¼ {days}ì¼ ë‹¨ì¼ìƒ‰ í‰ê·  ì ë„", f"{s_recent_mean:,.0f} cP")
    c4.metric(f"ìµœê·¼ {days}ì¼ ë°”ì¸ë” ì…ê³ ", f"{b_recent_total:,}", f"ë¶€ì í•© {b_recent_ng:,}")
    c5.metric("ë°ì´í„° ìµœì‹ ì¼", f"ë‹¨ì¼ìƒ‰ {s_latest_txt} / ë°”ì¸ë” {b_latest_txt}")

    st.divider()

    # 1) ë‹¨ì¼ìƒ‰ í‘œ(ì—‘ì…€í˜•)
    st.subheader("1) ë‹¨ì¼ìƒ‰ ë°ì´í„° (ì—‘ì…€ í˜•íƒœ)")

    df_view = single_df.copy()
    df_view["ìƒ‰ì°¨ê°’(Î”E76)"] = df_view.get("ë¹„ê³ ", pd.Series(dtype=str)).apply(extract_delta_e_from_note)

    col_map = {
        "ì…ê³ ì¼": "ì œì¡°ì¼ì(=ì…ê³ ì¼)",
        "ìƒ‰ìƒêµ°": "ìƒ‰ìƒêµ°",
        "ì œí’ˆì½”ë“œ": "ì œí’ˆì½”ë“œ",
        "ì‚¬ìš©ëœ ë°”ì¸ë” Lot": "ì‚¬ìš©ëœë°”ì¸ë”Lot",
        "ì ë„ì¸¡ì •ê°’(cP)": "ì ë„(cP)",
        "ìƒ‰ì°¨ê°’(Î”E76)": "ìƒ‰ì°¨ê°’(Î”E76)",
    }
    keep_cols = [c for c in col_map.keys() if c in df_view.columns]
    df_show = df_view[keep_cols].rename(columns=col_map)

    df_show["_date"] = pd.to_datetime(df_show.get("ì œì¡°ì¼ì(=ì…ê³ ì¼)", pd.Series(dtype=str)), errors="coerce")
    dmin = df_show["_date"].min()
    dmax = df_show["_date"].max()
    dmin = dmin.date() if pd.notna(dmin) else today - dt.timedelta(days=90)
    dmax = dmax.date() if pd.notna(dmax) else today

    f1, f2, f3, f4, f5 = st.columns([1.2, 1.2, 1.4, 1.6, 2.2])
    with f1:
        start = st.date_input("ê¸°ê°„ ì‹œì‘", value=max(dmin, dmax - dt.timedelta(days=90)), key="tbl_start")
    with f2:
        end = st.date_input("ê¸°ê°„ ì¢…ë£Œ", value=dmax, key="tbl_end")
    with f3:
        cg_list = sorted(df_show["ìƒ‰ìƒêµ°"].dropna().astype(str).unique().tolist()) if "ìƒ‰ìƒêµ°" in df_show.columns else []
        cg_pick = st.multiselect("ìƒ‰ìƒêµ°", cg_list, key="tbl_cg")
    with f4:
        pc_list = sorted(df_show["ì œí’ˆì½”ë“œ"].dropna().astype(str).unique().tolist()) if "ì œí’ˆì½”ë“œ" in df_show.columns else []
        pc_pick = st.multiselect("ì œí’ˆì½”ë“œ", pc_list, key="tbl_pc")
    with f5:
        q = st.text_input("ê²€ìƒ‰(ë°”ì¸ë”Lot/ì œí’ˆì½”ë“œ ë“±)", value="", key="tbl_q")

    if start > end:
        start, end = end, start

    df_filtered = df_show.copy()
    df_filtered = df_filtered[(df_filtered["_date"].dt.date >= start) & (df_filtered["_date"].dt.date <= end)]

    if cg_pick and "ìƒ‰ìƒêµ°" in df_filtered.columns:
        df_filtered = df_filtered[df_filtered["ìƒ‰ìƒêµ°"].astype(str).isin([str(x) for x in cg_pick])]
    if pc_pick and "ì œí’ˆì½”ë“œ" in df_filtered.columns:
        df_filtered = df_filtered[df_filtered["ì œí’ˆì½”ë“œ"].astype(str).isin([str(x) for x in pc_pick])]

    if q.strip():
        qq = q.strip()
        mask = False
        for c in ["ì‚¬ìš©ëœë°”ì¸ë”Lot", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°"]:
            if c in df_filtered.columns:
                mask = mask | df_filtered[c].astype(str).str.contains(qq, case=False, na=False)
        df_filtered = df_filtered[mask]

    df_filtered = df_filtered.sort_values("_date", ascending=False).drop(columns=["_date"])
    if "ìƒ‰ì°¨ê°’(Î”E76)" in df_filtered.columns:
        df_filtered["ìƒ‰ì°¨ê°’(Î”E76)"] = pd.to_numeric(df_filtered["ìƒ‰ì°¨ê°’(Î”E76)"], errors="coerce").round(2)

    st.caption(f"í‘œì‹œ ê±´ìˆ˜: {len(df_filtered):,}ê±´")
    st.dataframe(df_filtered, use_container_width=True, height=280)

    st.divider()

    # ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì +ê°’)
    st.subheader("ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì  + í‰ê· ê°’ í‘œì‹œ)")

    if "ìƒ‰ìƒêµ°" in single_df.columns and "ì ë„ì¸¡ì •ê°’(cP)" in single_df.columns:
        mean_df = (
            single_df[["ìƒ‰ìƒêµ°", "ì ë„ì¸¡ì •ê°’(cP)"]]
            .dropna()
            .assign(**{"ì ë„ì¸¡ì •ê°’(cP)": pd.to_numeric(single_df["ì ë„ì¸¡ì •ê°’(cP)"], errors="coerce")})
            .dropna()
            .groupby("ìƒ‰ìƒêµ°", as_index=False)["ì ë„ì¸¡ì •ê°’(cP)"]
            .mean()
            .rename(columns={"ì ë„ì¸¡ì •ê°’(cP)": "í‰ê· ì ë„"})
            .sort_values("í‰ê· ì ë„", ascending=False)
        )

        pts = alt.Chart(mean_df).mark_point(size=220).encode(
            y=alt.Y("ìƒ‰ìƒêµ°:N", title="ìƒ‰ìƒêµ°", sort=mean_df["ìƒ‰ìƒêµ°"].tolist()),
            x=alt.X("í‰ê· ì ë„:Q", title="í‰ê·  ì ë„(cP)"),
            tooltip=[alt.Tooltip("ìƒ‰ìƒêµ°:N"), alt.Tooltip("í‰ê· ì ë„:Q", format=".1f")],
        )
        txt = alt.Chart(mean_df).mark_text(dx=10).encode(
            y=alt.Y("ìƒ‰ìƒêµ°:N", sort=mean_df["ìƒ‰ìƒêµ°"].tolist()),
            x="í‰ê· ì ë„:Q",
            text=alt.Text("í‰ê· ì ë„:Q", format=".0f"),
        )
        st.altair_chart((pts + txt).interactive(), use_container_width=True)
    else:
        st.info("ë‹¨ì¼ìƒ‰ ë°ì´í„°ì— 'ìƒ‰ìƒêµ°' ë˜ëŠ” 'ì ë„ì¸¡ì •ê°’(cP)' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # 2) Lot ì¶”ì´(ì  í¬ê²Œ + ë¼ë²¨ í† ê¸€)
    st.subheader("2) ë‹¨ì¼ìƒ‰ ì ë„ ë³€í™” ì¶”ì´ (Lotë³„)")
    st.caption("ì ì€ í¬ê²Œ í‘œì‹œë˜ë©°, í•„ìš” ì‹œ ì ë„ê°’ ë¼ë²¨ë„ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    df = single_df.copy()
    need_cols = ["ì…ê³ ì¼", "ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ì ë„ì¸¡ì •ê°’(cP)"]
    miss = [c for c in need_cols if c not in df.columns]
    if miss:
        st.warning(f"ë‹¨ì¼ìƒ‰ ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {miss}")
    else:
        df = df.dropna(subset=need_cols).copy()
        df["ì…ê³ ì¼"] = pd.to_datetime(df["ì…ê³ ì¼"], errors="coerce")
        df = df.dropna(subset=["ì…ê³ ì¼"]).sort_values("ì…ê³ ì¼")

        f1, f2, f3, f4, f5 = st.columns([1.2, 1.2, 1.6, 2.0, 1.0])
        with f1:
            dmin = df["ì…ê³ ì¼"].min().date()
            dmax = df["ì…ê³ ì¼"].max().date()
            start = st.date_input("ì‹œì‘ì¼", value=max(dmin, dmax - dt.timedelta(days=90)), key="trend_start")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼", value=dmax, key="trend_end")
        with f3:
            cg = st.multiselect("ìƒ‰ìƒêµ°", sorted(df["ìƒ‰ìƒêµ°"].dropna().unique().tolist()) if "ìƒ‰ìƒêµ°" in df.columns else [], key="trend_cg")
        with f4:
            pc = st.multiselect("ì œí’ˆì½”ë“œ", sorted(df["ì œí’ˆì½”ë“œ"].dropna().unique().tolist()) if "ì œí’ˆì½”ë“œ" in df.columns else [], key="trend_pc")
        with f5:
            show_labels = st.checkbox("ì ë„ê°’ í‘œì‹œ", value=True, key="trend_labels")

        if start > end:
            start, end = end, start

        df = df[(df["ì…ê³ ì¼"].dt.date >= start) & (df["ì…ê³ ì¼"].dt.date <= end)]
        if cg and "ìƒ‰ìƒêµ°" in df.columns:
            df = df[df["ìƒ‰ìƒêµ°"].isin(cg)]
        if pc and "ì œí’ˆì½”ë“œ" in df.columns:
            df = df[df["ì œí’ˆì½”ë“œ"].isin(pc)]

        lot_list = sorted(df["ë‹¨ì¼ìƒ‰ì‰í¬ Lot"].astype(str).unique().tolist())
        default_pick = lot_list[-5:] if len(lot_list) > 5 else lot_list
        pick = st.multiselect("í‘œì‹œí•  ë‹¨ì¼ìƒ‰ Lot(ë³µìˆ˜ ì„ íƒ)", lot_list, default=default_pick, key="trend_lots")
        if pick:
            df = df[df["ë‹¨ì¼ìƒ‰ì‰í¬ Lot"].astype(str).isin(pick)]

        if len(df) == 0:
            st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df = df.sort_values("ì…ê³ ì¼")
            tooltip_cols = ["ì…ê³ ì¼:T", "ë‹¨ì¼ìƒ‰ì‰í¬ Lot:N", "ì ë„ì¸¡ì •ê°’(cP):Q"]

            base = alt.Chart(df).encode(
                x=alt.X("ì…ê³ ì¼:T", title="ì…ê³ ì¼"),
                y=alt.Y("ì ë„ì¸¡ì •ê°’(cP):Q", title="ì ë„(cP)"),
                color=alt.Color("ë‹¨ì¼ìƒ‰ì‰í¬ Lot:N", title="Lot"),
                tooltip=tooltip_cols,
            )
            line = base.mark_line()
            points = base.mark_point(size=260)

            chart = line + points
            if show_labels and len(df) <= 250:
                labels = alt.Chart(df).mark_text(dx=10, dy=-10).encode(
                    x="ì…ê³ ì¼:T",
                    y="ì ë„ì¸¡ì •ê°’(cP):Q",
                    color=alt.Color("ë‹¨ì¼ìƒ‰ì‰í¬ Lot:N", legend=None),
                    text=alt.Text("ì ë„ì¸¡ì •ê°’(cP):Q", format=".0f"),
                )
                chart = chart + labels
            elif show_labels and len(df) > 250:
                st.info("ë°ì´í„°ê°€ ë§ì•„ ë¼ë²¨ í‘œì‹œëŠ” ìë™ìœ¼ë¡œ ìƒëµí–ˆìŠµë‹ˆë‹¤(250ê±´ ì´í•˜ì—ì„œë§Œ í‘œì‹œ).")

            st.altair_chart(chart.interactive(), use_container_width=True)


# =========================
# 2) ì‰í¬ ì…ê³  (ë‹¨ì¼ìƒ‰ ì…ë ¥)
# =========================
with tab_ink_in:
    st.subheader("ë‹¨ì¼ìƒ‰ ì‰í¬ ì…ë ¥")

    ink_types = ["HEMA", "Silicone"]
    color_groups = sorted(spec_single["ìƒ‰ìƒêµ°"].dropna().unique().tolist())
    product_codes = sorted(spec_single["ì œí’ˆì½”ë“œ"].dropna().unique().tolist())

    binder_lots = binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).tolist()
    binder_lots = sorted(set(binder_lots), reverse=True)

    with st.form("single_form", clear_on_submit=True):
        col1, col2, col3, col4 = st.columns([1.2, 1.3, 1.5, 2.0])
        with col1:
            in_date = st.date_input("ì…ê³ ì¼", value=dt.date.today(), key="single_in_date")
            ink_type = st.selectbox("ì‰í¬íƒ€ì…", ink_types)
            color_group = st.selectbox("ìƒ‰ìƒêµ°", color_groups)
        with col2:
            product_code = st.selectbox("ì œí’ˆì½”ë“œ", product_codes)
            binder_lot = st.selectbox("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", binder_lots)
        with col3:
            visc_meas = st.number_input("ì ë„ì¸¡ì •ê°’(cP)", min_value=0.0, step=1.0, format="%.1f")
            supplier = st.selectbox("ë°”ì¸ë”ì œì¡°ì²˜", ["ë‚´ë¶€", "ì™¸ì£¼"], index=0)
        with col4:
            st.caption("ì„ íƒ: ì°©ìƒ‰ë ¥(L*a*b*) ì…ë ¥ ì‹œ Î”E(76)ì„ ë¹„ê³ ì— ìë™ ê¸°ë¡í•©ë‹ˆë‹¤.")
            L = st.number_input("ì°©ìƒ‰ë ¥_L*", value=0.0, step=0.1, format="%.2f")
            a = st.number_input("ì°©ìƒ‰ë ¥_a*", value=0.0, step=0.1, format="%.2f")
            b = st.number_input("ì°©ìƒ‰ë ¥_b*", value=0.0, step=0.1, format="%.2f")
            lab_enabled = st.checkbox("L*a*b* ì…ë ¥í•¨", value=False)

        note = st.text_input("ë¹„ê³ ", value="", key="single_note")
        submit_s = st.form_submit_button("ì €ì¥(ë‹¨ì¼ìƒ‰)", type="primary")

    if submit_s:
        binder_type = infer_binder_type_from_lot(spec_binder, binder_lot)

        spec_hit = spec_single[
            (spec_single["ìƒ‰ìƒêµ°"] == color_group) &
            (spec_single["ì œí’ˆì½”ë“œ"] == product_code)
        ].copy()

        if binder_type and "BinderType" in spec_hit.columns:
            spec_hit = spec_hit[spec_hit["BinderType"] == binder_type]

        if len(spec_hit) == 0:
            lo, hi = None, None
            visc_judge = None
            st.warning("ì ë„ ê¸°ì¤€ì„ Spec_Single_H&Sì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ë°”ì¸ë”íƒ€ì… ì¡°í•© í™•ì¸)")
        else:
            lo = float(spec_hit["í•˜í•œ"].iloc[0])
            hi = float(spec_hit["ìƒí•œ"].iloc[0])
            visc_judge = judge_range(visc_meas, lo, hi)

        new_lot = generate_single_lot(single_df, product_code, color_group, in_date)
        if new_lot is None:
            st.error("ë‹¨ì¼ìƒ‰ Lot ìë™ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ° ë§¤í•‘ í™•ì¸ í•„ìš”)")
        else:
            note2 = note
            if lab_enabled:
                base_hit = base_lab[base_lab.get("ì œí’ˆì½”ë“œ", pd.Series(dtype=str)) == product_code]
                if len(base_hit) == 1:
                    base = (float(base_hit.iloc[0]["ê¸°ì¤€_L*"]), float(base_hit.iloc[0]["ê¸°ì¤€_a*"]), float(base_hit.iloc[0]["ê¸°ì¤€_b*"]))
                    de = delta_e76((L, a, b), base)
                    note2 = (note2 + " " if note2 else "") + f"[Î”E76={de:.2f}]"
                else:
                    note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"

            row = {
                "ì…ê³ ì¼": in_date,
                "ì‰í¬íƒ€ì…\n(HEMA/Silicone)": ink_type,
                "ìƒ‰ìƒêµ°": color_group,
                "ì œí’ˆì½”ë“œ": product_code,
                "ë‹¨ì¼ìƒ‰ì‰í¬ Lot": new_lot,
                "ì‚¬ìš©ëœ ë°”ì¸ë” Lot": binder_lot,
                "ë°”ì¸ë”ì œì¡°ì²˜\n(ë‚´ë¶€/ì™¸ì£¼)": supplier,
                "BinderType(ìë™)": binder_type,
                "ì ë„ì¸¡ì •ê°’(cP)": float(visc_meas),
                "ì ë„í•˜í•œ": lo,
                "ì ë„ìƒí•œ": hi,
                "ì ë„íŒì •": visc_judge,
                "ì°©ìƒ‰ë ¥_L*": float(L) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_a*": float(a) if lab_enabled else None,
                "ì°©ìƒ‰ë ¥_b*": float(b) if lab_enabled else None,
                "ë¹„ê³ ": note2,
            }

            try:
                append_row_to_sheet(xlsx_path, SHEET_SINGLE, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë‹¨ì¼ìƒ‰ Lot = {new_lot} / ì ë„íŒì • = {visc_judge}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")


# =========================
# 3) ë°”ì¸ë” ì…ì¶œê³ 
# =========================
with tab_binder:
    st.subheader("ë°”ì¸ë” ì…ì¶œê³ ")

    # ì—…ì²´ ë°˜í™˜ ì…ë ¥(kg)
    st.markdown("### âœ… ì—…ì²´ ë°˜í™˜(ë°˜í’ˆ) ì…ë ¥ (kg ë‹¨ìœ„)")
    binder_names = sorted(spec_binder["ë°”ì¸ë”ëª…"].dropna().unique().tolist())
    binder_lot_choices = sorted(binder_df.get("Lot(ìë™)", pd.Series(dtype=str)).dropna().astype(str).unique().tolist(), reverse=True)

    with st.form("binder_return_form", clear_on_submit=True):
        c1, c2, c3, c4 = st.columns([1.2, 1.6, 2.0, 1.4])
        with c1:
            ret_date = st.date_input("ë°˜í’ˆì¼ì", value=dt.date.today(), key="ret_date")
        with c2:
            ret_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="ret_name")
        with c3:
            ret_lot = st.selectbox("ê´€ë ¨ Lot(ì„ íƒ)", ["(ì„ íƒì•ˆí•¨)"] + binder_lot_choices, key="ret_lot")
        with c4:
            ret_kg = st.number_input("ë°˜í’ˆìˆ˜ëŸ‰(kg)", min_value=0.0, step=0.1, format="%.1f", key="ret_kg")
        ret_note = st.text_input("ë¹„ê³ ", value="", key="ret_note")
        ret_submit = st.form_submit_button("ë°˜í’ˆ ì €ì¥", type="primary")

    if ret_submit:
        if ret_kg <= 0:
            st.error("ë°˜í’ˆìˆ˜ëŸ‰(kg)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        else:
            row = {
                "ë°˜í’ˆì¼ì": ret_date,
                "ë°”ì¸ë”ëª…": ret_name,
                "ê´€ë ¨ Lot(ì„ íƒ)": "" if ret_lot == "(ì„ íƒì•ˆí•¨)" else ret_lot,
                "ë°˜í’ˆìˆ˜ëŸ‰(kg)": float(ret_kg),
                "ë¹„ê³ ": ret_note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER_RETURN, row)
                st.success("ë°˜í’ˆ ì €ì¥ ì™„ë£Œ!")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()

    # ì—‘ì…€ ë°”ì¸ë” ê¸°ë¡(í™•ì¸ìš©)
    st.markdown("### ğŸ“Œ ì—‘ì…€ ë°”ì¸ë” ê¸°ë¡(ìµœì‹ ìˆœ, ìµœê·¼ 50ê±´)")
    if "ì œì¡°/ì…ê³ ì¼" in binder_df.columns:
        st.dataframe(binder_df.sort_values("ì œì¡°/ì…ê³ ì¼", ascending=False).head(50), use_container_width=True)
    else:
        st.dataframe(binder_df.head(50), use_container_width=True)

    st.divider()

    # êµ¬ê¸€ì‹œíŠ¸ ì¡°íšŒ(ìµœì‹ ìˆœ)
    st.markdown("### ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸) ì¡°íšŒ - ìµœì‹ ìˆœ")
    st.caption("â€» ì—¬ê¸° í‘œëŠ” êµ¬ê¸€ì‹œíŠ¸ì´ë©°, ìœ„ ì…ë ¥(ì—‘ì…€ ì €ì¥)ê³¼ëŠ” ë³„ê°œì…ë‹ˆë‹¤.")

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.exception(e)
        st.stop()

    df_hema = sort_df_by_any_date_col(df_hema)
    df_sil = sort_df_by_any_date_col(df_sil)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### HEMA (ìµœì‹ ìˆœ)")
        st.dataframe(df_hema, use_container_width=True)
    with c2:
        st.markdown("#### Silicon (ìµœì‹ ìˆœ)")
        st.dataframe(df_sil, use_container_width=True)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key="binder_refresh"):
        st.cache_data.clear()
        st.rerun()


# =========================
# 4) Search
# =========================
with tab_search:
    c1, c2, c3 = st.columns([2, 2, 3])
    with c1:
        mode = st.selectbox("ê²€ìƒ‰ ì¢…ë¥˜", ["ë°”ì¸ë” Lot", "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°", "ê¸°ê°„(ì…ê³ ì¼)"])
    with c2:
        q = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: PCB20250112-01 / PLB25041501 / PL-835-1 ...")
    with c3:
        st.write("")
        st.caption("ğŸ’¡ ë°”ì¸ë” Lot ê²€ìƒ‰: ë°”ì¸ë” ì •ë³´ + ì—°ê²°ëœ ë‹¨ì¼ìƒ‰ ì‰í¬ ëª©ë¡ì„ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    if mode == "ê¸°ê°„(ì…ê³ ì¼)":
        d1, d2 = st.columns(2)
        with d1:
            start = st.date_input("ì‹œì‘ì¼", value=dt.date.today() - dt.timedelta(days=30), key="search_start")
        with d2:
            end = st.date_input("ì¢…ë£Œì¼", value=dt.date.today(), key="search_end")
        df = single_df.copy()
        if "ì…ê³ ì¼" in df.columns:
            df = df[df["ì…ê³ ì¼"].between(start, end)]
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        st.dataframe(df, use_container_width=True)

    elif mode == "ë°”ì¸ë” Lot":
        b = binder_df.copy()
        b_hit = df_quick_filter(b, q, ["Lot(ìë™)", "ë°”ì¸ë”ëª…", "ë¹„ê³ "])
        st.subheader("ë°”ì¸ë”_ì œì¡°_ì…ê³ ")
        if "ì œì¡°/ì…ê³ ì¼" in b_hit.columns:
            st.dataframe(b_hit.sort_values(by="ì œì¡°/ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(b_hit, use_container_width=True)

        if q and "ì‚¬ìš©ëœ ë°”ì¸ë” Lot" in single_df.columns:
            s_hit = single_df[single_df["ì‚¬ìš©ëœ ë°”ì¸ë” Lot"].astype(str).str.contains(str(q).strip(), case=False, na=False)]
            st.subheader("ì—°ê²°ëœ ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ (ì‚¬ìš©ëœ ë°”ì¸ë” Lot)")
            if "ì…ê³ ì¼" in s_hit.columns:
                st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
            else:
                st.dataframe(s_hit, use_container_width=True)

    elif mode == "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ì‚¬ìš©ëœ ë°”ì¸ë” Lot", "ìƒ‰ìƒêµ°", "ë¹„ê³ "])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)

    elif mode == "ì œí’ˆì½”ë“œ":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ì œí’ˆì½”ë“œ"])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)

    elif mode == "ìƒ‰ìƒêµ°":
        s = single_df.copy()
        s_hit = df_quick_filter(s, q, ["ìƒ‰ìƒêµ°"])
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        if "ì…ê³ ì¼" in s_hit.columns:
            st.dataframe(s_hit.sort_values(by="ì…ê³ ì¼", ascending=False), use_container_width=True)
        else:
            st.dataframe(s_hit, use_container_width=True)
