import altair as alt
import streamlit as st
import pandas as pd
import datetime as dt
import re
from pathlib import Path
from openpyxl import load_workbook
import requests
from io import StringIO

# ==========================================================
# Page Config (ë”± 1ë²ˆë§Œ)
# ==========================================================
st.set_page_config(
    page_title="ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬",
    page_icon="ğŸ§ª",
    layout="wide",
)


# ==========================================================
# Simple UI Style (ì„ì› ë³´ê³ ìš© ê°€ì‹œì„± ê°•í™”)
# ==========================================================
st.markdown(
    """
    <style>
      /* ì „ì²´ í­/ì—¬ë°± */
      .block-container { padding-top: 1.1rem; padding-bottom: 1.8rem; }

      /* ì„¹ì…˜ ì œëª© ëŠë‚Œ */
      .section-title {
        font-size: 1.15rem;
        font-weight: 700;
        margin: 0.2rem 0 0.2rem 0;
      }
      .section-sub {
        color: rgba(49,51,63,0.65);
        font-size: 0.92rem;
        margin-bottom: 0.6rem;
      }

      /* KPI ì¹´ë“œ ëŠë‚Œ(ê¸°ë³¸ metric ë³´ì¡°) */
      .kpi-note {
        color: rgba(49,51,63,0.70);
        font-size: 0.85rem;
        margin-top: -0.2rem;
      }

      /* expander í—¤ë” ê°•ì¡° */
      div[data-testid="stExpander"] > details > summary {
        font-weight: 700;
      }
    </style>
    """,
    unsafe_allow_html=True
)


# ==========================================================
# Google Sheets (Public) Reader
# ==========================================================
@st.cache_data(ttl=60, show_spinner=False)  # 60ì´ˆë§ˆë‹¤ ìµœì‹ ê°’ ê°±ì‹ 
def read_gsheet_csv(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    """Public/Link-shared Google Sheet ë¥¼ CSVë¡œ ì½ì–´ì˜µë‹ˆë‹¤."""
    base = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq"
    r = requests.get(base, params={"tqx": "out:csv", "sheet": sheet_name}, timeout=20)
    r.raise_for_status()
    r.encoding = "utf-8"
    return pd.read_csv(StringIO(r.text))

# ==========================================================
# Config
# ==========================================================
DEFAULT_XLSX = "ì•¡ìƒì‰í¬_Lotì¶”ì ê´€ë¦¬_FINAL.xlsx"
DEFAULT_STOCK_XLSX = "ì•¡ìƒ ì¬ê³ ì¡°ì‚¬í‘œ_ìë™ê³„ì‚° (12).xlsx"

SHEET_BINDER = "ë°”ì¸ë”_ì œì¡°_ì…ê³ "
SHEET_SINGLE = "ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬"
SHEET_SPEC_BINDER = "Spec_Binder"
SHEET_SPEC_SINGLE = "Spec_Single_H&S"
SHEET_BASE_LAB = "ê¸°ì¤€LAB"
SHEET_BINDER_RETURN = "ë°”ì¸ë”_ì—…ì²´ë°˜í™˜"  # kg ë‹¨ìœ„ ë°˜í™˜ ê¸°ë¡(ì—†ìœ¼ë©´ ìë™ ìƒì„±)

COLOR_CODE = {
    "Black": "B",
    "White": "W",
    "Blue": "U",
    "Green": "G",
    "Yellow": "Y",
    "Red": "R",
    "Pink": "P",
}

# ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸)
BINDER_SHEET_ID = "1H2fFxnf5AvpSlu-uoZ4NpTv8LYLNwTNAzvlntRQ7FS8"
BINDER_SHEET_HEMA = "HEMA ë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"
BINDER_SHEET_SIL = "Siliconë°”ì¸ë” ì…ì¶œê³  ê´€ë¦¬ëŒ€ì¥"

# ==========================================================
# Helpers
# ==========================================================
def norm_key(x) -> str:
    """í—¤ë”/ì»¬ëŸ¼ ë¹„êµìš©: ì¤„ë°”ê¿ˆ ì œê±° + ê³µë°± ì •ë¦¬"""
    if x is None:
        return ""
    s = str(x)
    s = s.replace("\n", " ").replace("\r", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def find_col(df: pd.DataFrame, want: str) -> str | None:
    """dfì—ì„œ want(ì¤„ë°”ê¿ˆ/ê³µë°± ë¬´ì‹œ)ì™€ ë™ì¼í•œ ì»¬ëŸ¼ëª…ì„ ì°¾ì•„ ë°˜í™˜"""
    w = norm_key(want)
    for c in df.columns:
        if norm_key(c) == w:
            return c
    return None

def safe_to_float(x):
    if x is None:
        return None
    if isinstance(x, float) and pd.isna(x):
        return None
    if isinstance(x, str) and x.strip() == "":
        return None
    try:
        if isinstance(x, str):
            x = x.replace(",", "")
        return float(x)
    except Exception:
        return None

def normalize_date(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return None
    if isinstance(x, (dt.date, dt.datetime)):
        return x.date() if isinstance(x, dt.datetime) else x
    try:
        return pd.to_datetime(x).date()
    except Exception:
        return None

def delta_e76(lab1, lab2) -> float:
    return float(((lab1[0]-lab2[0])**2 + (lab1[1]-lab2[1])**2 + (lab1[2]-lab2[2])**2) ** 0.5)

def ensure_sheet_exists(xlsx_path: str, sheet_name: str, headers: list[str]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        ws = wb.create_sheet(sheet_name)
        ws.append(headers)
        wb.save(xlsx_path)

def append_row_to_sheet(xlsx_path: str, sheet_name: str, row: dict):
    """
    ì—‘ì…€ í—¤ë”(1í–‰) ê¸°ì¤€ìœ¼ë¡œ append.
    row dictëŠ” 'í—¤ë” ì›ë¬¸' ë˜ëŠ” norm_key(í—¤ë”) í‚¤ë¡œ ê°’ì´ ìˆìœ¼ë©´ ì±„ì›€.
    """
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    values = []
    for h in headers:
        if h is None:
            values.append(None)
            continue
        v = row.get(h, None)
        if v is None:
            v = row.get(norm_key(h), None)
        values.append(v)
    ws.append(values)
    wb.save(xlsx_path)

def append_rows_to_sheet(xlsx_path: str, sheet_name: str, rows: list[dict]):
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    headers = [c.value for c in ws[1]]
    for row in rows:
        values = []
        for h in headers:
            if h is None:
                values.append(None)
                continue
            v = row.get(h, None)
            if v is None:
                v = row.get(norm_key(h), None)
            values.append(v)
        ws.append(values)
    wb.save(xlsx_path)

def update_sheet_cells(xlsx_path: str, sheet_name: str, updates: list[tuple[int, str, object]]):
    """
    updates: (excel_row_number, header_name, value)
    header_nameì€ ì‹œíŠ¸ 1í–‰ì— ìˆëŠ” í—¤ë”ì™€ ë™ì¼í•´ì•¼ í•¨.
    """
    if not updates:
        return
    wb = load_workbook(xlsx_path)
    if sheet_name not in wb.sheetnames:
        raise ValueError(f"Sheet not found: {sheet_name}")
    ws = wb[sheet_name]
    header_map = {}
    for j, cell in enumerate(ws[1], start=1):
        header_map[str(cell.value)] = j

    for r, h, v in updates:
        if h not in header_map:
            # í—¤ë”ê°€ ì™„ì „íˆ ë™ì¼í•˜ì§€ ì•Šì€ ê²½ìš° norm_keyë¡œ í•œ ë²ˆ ë” ë§¤ì¹­
            for hh, col_j in header_map.items():
                if norm_key(hh) == norm_key(h):
                    header_map[h] = col_j
                    break
        if h not in header_map:
            continue
        col = header_map[h]

        # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬
        if isinstance(v, pd.Timestamp):
            v = v.to_pydatetime()
        ws.cell(row=int(r), column=int(col)).value = v

    wb.save(xlsx_path)

@st.cache_data(show_spinner=False)
def load_dataframes(xlsx_path: str) -> dict[str, pd.DataFrame]:
    """pandasë¡œ ì‹œíŠ¸ ì½ê¸°(í‘œì‹œ/ë¶„ì„ìš©)."""
    def read(name: str) -> pd.DataFrame:
        return pd.read_excel(xlsx_path, sheet_name=name)

    out = {
        "binder": read(SHEET_BINDER),
        "single": read(SHEET_SINGLE),
        "spec_binder": read(SHEET_SPEC_BINDER),
        "spec_single": read(SHEET_SPEC_SINGLE),
        "base_lab": read(SHEET_BASE_LAB),
    }
    # ë°˜í™˜ ì‹œíŠ¸ëŠ” ì—†ì„ ìˆ˜ë„ ìˆìŒ
    try:
        out["binder_return"] = read(SHEET_BINDER_RETURN)
    except Exception:
        out["binder_return"] = pd.DataFrame(columns=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "])
    return out

def infer_binder_name_from_lot(spec_binder: pd.DataFrame, binder_lot: str):
    """Lot prefix ê·œì¹™ìœ¼ë¡œ ë°”ì¸ë”ëª…(=BinderType ì—­í• ) ì¶”ì •."""
    if not binder_lot:
        return None
    lot = str(binder_lot).strip()
    c_name = find_col(spec_binder, "ë°”ì¸ë”ëª…")
    c_rule = find_col(spec_binder, "Lotë¶€ì—¬ê·œì¹™")
    if not c_name or not c_rule:
        return None

    rules = spec_binder[[c_name, c_rule]].dropna().drop_duplicates().to_dict("records")
    for r in rules:
        rule = str(r[c_rule])
        m = re.match(r"^([A-Za-z0-9]+)\+", rule)
        if m and lot.startswith(m.group(1)):
            return r[c_name]
    return None

def get_binder_limits(spec_binder: pd.DataFrame, binder_name: str):
    c_name = find_col(spec_binder, "ë°”ì¸ë”ëª…")
    c_item = find_col(spec_binder, "ì‹œí—˜í•­ëª©")
    c_lo = find_col(spec_binder, "í•˜í•œ")
    c_hi = find_col(spec_binder, "ìƒí•œ")
    c_rule = find_col(spec_binder, "Lotë¶€ì—¬ê·œì¹™")
    if not all([c_name, c_item, c_lo, c_hi]):
        return None, None, None, None

    df = spec_binder[spec_binder[c_name] == binder_name].copy()
    visc = df[df[c_item].astype(str).str.contains("ì ë„", na=False)]
    uv = df[df[c_item].astype(str).str.contains("UV", na=False)]

    visc_lo = safe_to_float(visc[c_lo].dropna().iloc[0]) if len(visc[c_lo].dropna()) else None
    visc_hi = safe_to_float(visc[c_hi].dropna().iloc[0]) if len(visc[c_hi].dropna()) else None
    uv_hi = safe_to_float(uv[c_hi].dropna().iloc[0]) if len(uv[c_hi].dropna()) else None
    rule = df[c_rule].dropna().iloc[0] if c_rule and len(df[c_rule].dropna()) else None
    return visc_lo, visc_hi, uv_hi, rule

def next_seq_for_pattern(existing_lots: pd.Series, prefix: str, date_str: str, sep: str = "-") -> int:
    lots = existing_lots.dropna().astype(str).tolist()
    seqs = []
    for lot in lots:
        lot = str(lot).strip()
        if not lot.startswith(prefix + date_str):
            continue
        rest = lot[len(prefix + date_str):]
        if sep and rest.startswith(sep):
            rest = rest[len(sep):]
        m = re.match(r"^(\d+)", rest)
        if m:
            try:
                seqs.append(int(m.group(1)))
            except Exception:
                pass
    return (max(seqs) + 1) if seqs else 1

def generate_binder_lot(spec_binder: pd.DataFrame, binder_name: str, mfg_date: dt.date, existing_binder_lots: pd.Series):
    _, _, _, rule = get_binder_limits(spec_binder, binder_name)
    if not rule:
        code = re.sub(r"\W+", "", binder_name)[:6].upper()
        return f"{code}{mfg_date.strftime('%Y%m%d')}-01"

    m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip())
    if not m:
        code = re.sub(r"\W+", "", binder_name)[:6].upper()
        return f"{code}{mfg_date.strftime('%Y%m%d')}-01"

    prefix = m.group(1)
    has_seq = bool(m.group(2))
    date_str = mfg_date.strftime("%Y%m%d")
    if has_seq:
        seq = next_seq_for_pattern(existing_binder_lots, prefix, date_str, sep="-")
        return f"{prefix}{date_str}-{seq:02d}"
    return f"{prefix}{date_str}"

def generate_single_lot(single_df: pd.DataFrame, product_code: str, color_group: str, in_date: dt.date):
    code = (product_code or "").strip()
    color_code = COLOR_CODE.get(color_group)
    if not color_code:
        return None

    if code.startswith("NPL"):
        prefix = "NPL"
    elif code.startswith("PL"):
        prefix = "PL"
    elif code.startswith("SL") or code.startswith("NSL"):
        prefix = "SL"
    else:
        prefix = "PL"

    date_str = in_date.strftime("%y%m%d")
    patt_prefix = f"{prefix}{color_code}{date_str}"

    c_lot = find_col(single_df, "ë‹¨ì¼ìƒ‰ì‰í¬ Lot")
    lots = single_df[c_lot].dropna().astype(str).tolist() if c_lot else []
    seqs = []
    for lot in lots:
        lot = str(lot).strip()
        if lot.startswith(patt_prefix):
            rest = lot[len(patt_prefix):]
            m = re.match(r"^(\d{2,})", rest)
            if m:
                seqs.append(int(m.group(1)))
    seq = (max(seqs) + 1) if seqs else 1
    return f"{patt_prefix}{seq:02d}"

def judge_range(value, lo, hi):
    v = safe_to_float(value)
    if v is None:
        return None
    if lo is not None and v < float(lo):
        return "ë¶€ì í•©"
    if hi is not None and v > float(hi):
        return "ë¶€ì í•©"
    return "ì í•©"

def extract_de76_from_note(note: str | None):
    if not note:
        return None
    m = re.search(r"\[\s*Î”E76\s*=\s*([0-9]+(?:\.[0-9]+)?)\s*\]", str(note))
    if not m:
        return None
    try:
        return float(m.group(1))
    except Exception:
        return None

def compute_de76_series(single_df: pd.DataFrame, base_lab: pd.DataFrame) -> pd.Series:
    """ë¹„ê³ ì˜ [Î”E76=..] ë˜ëŠ” ì°©ìƒ‰ë ¥/ê¸°ì¤€LABë¡œ Î”E76 ê³„ì‚°."""
    c_note = find_col(single_df, "ë¹„ê³ ")
    out = pd.Series([None] * len(single_df), index=single_df.index, dtype="float")

    if c_note:
        for idx, val in single_df[c_note].items():
            de = extract_de76_from_note(None if pd.isna(val) else str(val))
            if de is not None:
                out.loc[idx] = de

    # ì°©ìƒ‰ë ¥ ê¸°ë°˜ ê³„ì‚°
    c_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")
    cL = find_col(single_df, "ì°©ìƒ‰ë ¥_L*")
    ca = find_col(single_df, "ì°©ìƒ‰ë ¥_a*")
    cb = find_col(single_df, "ì°©ìƒ‰ë ¥_b*")
    b_pc = find_col(base_lab, "ì œí’ˆì½”ë“œ")
    bL = find_col(base_lab, "ê¸°ì¤€_L*")
    ba = find_col(base_lab, "ê¸°ì¤€_a*")
    bb = find_col(base_lab, "ê¸°ì¤€_b*")
    if not all([c_pc, cL, ca, cb, b_pc, bL, ba, bb]):
        return out

    base = base_lab.copy()
    base[b_pc] = base[b_pc].astype(str).str.strip()
    base_map = base.set_index(b_pc)[[bL, ba, bb]].to_dict("index")

    for idx, row in single_df.iterrows():
        if pd.notna(out.loc[idx]):
            continue
        pc = row.get(c_pc, None)
        if pd.isna(pc):
            continue
        pc = str(pc).strip()
        if pc not in base_map:
            continue
        L = safe_to_float(row.get(cL))
        a = safe_to_float(row.get(ca))
        b = safe_to_float(row.get(cb))
        if None in (L, a, b):
            continue
        ref = base_map[pc]
        rL = safe_to_float(ref[bL]); ra = safe_to_float(ref[ba]); rb = safe_to_float(ref[bb])
        if None in (rL, ra, rb):
            continue
        out.loc[idx] = delta_e76((L, a, b), (rL, ra, rb))
    return out

def safe_date_bounds(series: pd.Series):
    s = pd.to_datetime(series, errors="coerce").dropna()
    if len(s) == 0:
        today = dt.date.today()
        return today, today
    return s.min().date(), s.max().date()

def detect_date_col(df: pd.DataFrame):
    for c in df.columns:
        ck = norm_key(c)
        if any(k in ck for k in ["ì¼ì", "ë‚ ì§œ", "date", "ì…ê³ ì¼", "ì¶œê³ ì¼"]):
            return c
    return None

def detect_lot_col(df: pd.DataFrame):
    """êµ¬ê¸€ì‹œíŠ¸/ì—‘ì…€ì—ì„œ Lot ì»¬ëŸ¼ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
    for c in df.columns:
        ck = norm_key(c).lower()
        if 'lot' in ck or 'ë¡œíŠ¸' in ck:
            return c
    return None

def add_excel_row_number(df: pd.DataFrame) -> pd.DataFrame:
    """ì—‘ì…€ 1í–‰ì´ í—¤ë”ë¼ê³  ê°€ì •í•  ë•Œ, ë°ì´í„° row ë²ˆí˜¸ = index+2."""
    df = df.copy()
    df["_excel_row"] = df.index + 2
    return df

# ==========================================================
# Stock (ì¬ê³ /ë°œì£¼/ì‚¬ìš©ëŸ‰) - ë³„ë„ íƒ­
# ==========================================================
def normalize_color_group(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return "Other"
    s = str(x).strip()
    if not s or s.lower() in ("nan", "none"):
        return "Other"
    u = s.upper()
    # í•œê¸€/ì˜ë¬¸ í˜¼ìš© ë°©ì–´
    if "BLACK" in u or "ê²€ì •" in s or "í‘" in s:
        return "Black"
    if "WHITE" in u or "í°" in s or "ë°±" in s:
        return "White"
    if "RED" in u or "ë¹¨" in s or "ì " in s:
        return "Red"
    if "YELLOW" in u or "ë…¸" in s or "í™©" in s or "ì˜" in s:
        return "Yellow"
    if "GREEN" in u or "ì´ˆ" in s or "ë…¹" in s:
        return "Green"
    if "BLUE" in u or "íŒŒ" in s or "ì²­" in s:
        return "Blue"
    if "PINK" in u or "í•‘" in s:
        return "Pink"
    # ì´ë¯¸ í‘œì¤€í˜•ì´ë©´
    if s in ["Black","White","Red","Yellow","Green","Blue","Pink"]:
        return s
    return "Other"


def normalize_product_code(x) -> str:
    """ì œí’ˆì½”ë“œ/í’ˆëª©ëª… ë¬¸ìì—´ ì •ê·œí™” (ê³µë°±/íŠ¹ìˆ˜ í•˜ì´í”ˆ/ì ‘ë¯¸ì–´ ì°¨ì´ í¡ìˆ˜)"""
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).strip()
    if not s or s.lower() in ("nan", "none"):
        return ""
    # íŠ¹ìˆ˜ í•˜ì´í”ˆ â†’ ì¼ë°˜ í•˜ì´í”ˆ
    s = s.replace("â€“", "-").replace("â€”", "-").replace("âˆ’", "-")
    # ë‹¤ì¤‘ ê³µë°± ì œê±°
    s = re.sub(r"\s+", " ", s).strip()
    # í”í•œ ì ‘ë¯¸/ì ‘ë‘ ì œê±°(í•„ìš” ì‹œ í™•ì¥)
    s = s.replace("(ì•¡ìƒì‰í¬)", "").replace("ì•¡ìƒì‰í¬", "").strip()
    return s

def build_product_to_color_map(spec_single: pd.DataFrame, single_df: pd.DataFrame) -> dict[str, str]:
    """
    í’ˆëª©ëª…(=ì œí’ˆì½”ë“œ) -> ìƒ‰ìƒêµ° ë§¤í•‘ ìƒì„±
    ìš°ì„ ìˆœìœ„: Spec_Single_H&S > ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ ê¸°ë¡(ë¹ˆì¹¸ ë³´ì •)
    â€» ì œí’ˆì½”ë“œ í‘œê¸°ê°€ ì¡°ê¸ˆ ë‹¬ë¼ë„ ë§¤ì¹­ë˜ë„ë¡ normalize_product_code ì ìš©
    """
    mapping: dict[str, str] = {}

    sp_pc = find_col(spec_single, "ì œí’ˆì½”ë“œ")
    sp_cg = find_col(spec_single, "ìƒ‰ìƒêµ°")
    if sp_pc and sp_cg and len(spec_single):
        tmp = spec_single[[sp_pc, sp_cg]].dropna()
        tmp[sp_pc] = tmp[sp_pc].apply(normalize_product_code)
        tmp = tmp[tmp[sp_pc].astype(str).str.len() > 0]
        tmp[sp_cg] = tmp[sp_cg].apply(normalize_color_group)
        # ì œí’ˆì½”ë“œ ì¤‘ë³µì´ë©´ ìµœë¹ˆê°’
        for pc, g in tmp.groupby(sp_pc)[sp_cg]:
            mapping[str(pc)] = g.value_counts().idxmax()

    s_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")
    s_cg = find_col(single_df, "ìƒ‰ìƒêµ°")
    if s_pc and s_cg and len(single_df):
        tmp = single_df[[s_pc, s_cg]].dropna()
        tmp[s_pc] = tmp[s_pc].apply(normalize_product_code)
        tmp = tmp[tmp[s_pc].astype(str).str.len() > 0]
        tmp[s_cg] = tmp[s_cg].apply(normalize_color_group)
        for pc, g in tmp.groupby(s_pc)[s_cg]:
            pc = str(pc)
            if pc not in mapping:
                mapping[pc] = g.value_counts().idxmax()

    return mapping


def _parse_stock_sheet_date(sheet_name: str, today: dt.date) -> dt.date | None:
    s = str(sheet_name).strip()
    m = re.match(r"^(\d{1,2})\.(\d{1,2})$", s)
    if not m:
        return None
    month = int(m.group(1)); day = int(m.group(2))
    year = today.year
    if month > (today.month + 1):
        year -= 1
    try:
        return dt.date(year, month, day)
    except ValueError:
        return None

@st.cache_data(show_spinner=False)
def load_stock_history(stock_xlsx_path: str, product_to_color: dict[str, str]) -> pd.DataFrame:
    """
    ì¬ê³  ì—‘ì…€(ì¼ìë³„ ì‹œíŠ¸) -> long-form
    expected cols: êµ¬ë¶„, í’ˆëª©ëª…, ì „ì¼ ì¬ê³ (kg), ê¸ˆì¼ ì¬ê³ (kg), í•˜ë£¨ ì‚¬ìš©ëŸ‰(kg)
    """
    if not stock_xlsx_path or not Path(stock_xlsx_path).exists():
        return pd.DataFrame()

    today = dt.date.today()
    xls = pd.ExcelFile(stock_xlsx_path, engine="openpyxl")

    frames = []
    for sh in xls.sheet_names:
        d = _parse_stock_sheet_date(sh, today)
        if d is None:
            continue

        df = pd.read_excel(xls, sheet_name=sh)
        df = df.rename(columns=lambda x: str(x).strip())

        c_div = find_col(df, "êµ¬ë¶„")
        c_item = find_col(df, "í’ˆëª©ëª…")
        c_curr = find_col(df, "ê¸ˆì¼ ì¬ê³ (kg)") or find_col(df, "ê¸ˆì¼ì¬ê³ (kg)") or find_col(df, "ì¬ê³ (kg)")
        c_used = find_col(df, "í•˜ë£¨ ì‚¬ìš©ëŸ‰(kg)") or find_col(df, "ì‚¬ìš©ëŸ‰(kg)") or find_col(df, "ì‚¬ìš©ëŸ‰")

        if not (c_item and c_curr and c_used):
            continue

        df["_division"] = df[c_div].astype(str).str.strip() if c_div else ""
        df["_product"] = df[c_item].apply(normalize_product_code)

        df["_curr"] = pd.to_numeric(df[c_curr].astype(str).str.replace(",", "", regex=False), errors="coerce")
        df["_used_raw"] = pd.to_numeric(df[c_used].astype(str).str.replace(",", "", regex=False), errors="coerce")
        df = df.dropna(subset=["_product", "_curr"])

        df["used_kg"] = df["_used_raw"].clip(lower=0).fillna(0)
        df["inbound_kg"] = (-df["_used_raw"]).clip(lower=0).fillna(0)
        df["inbound_event"] = (df["inbound_kg"] > 0).astype(int)
        df["curr_stock_kg"] = df["_curr"].fillna(0)

        df["color_group"] = df["_product"].map(product_to_color).fillna("Other").apply(normalize_color_group)

        df["date"] = pd.to_datetime(d)
        frames.append(df[["date","_division","_product","color_group","curr_stock_kg","used_kg","inbound_kg","inbound_event"]])

    if not frames:
        return pd.DataFrame()

    hist = pd.concat(frames, ignore_index=True)
    hist = hist.rename(columns={"_division":"division", "_product":"product_code"})
    hist = hist.sort_values(["date","division","product_code"]).reset_index(drop=True)
    return hist

def _color_scale_color_group():
    domain = ["Black","Blue","Green","Yellow","Red","Pink","White","Other"]
    rng = ["#111111","#1f77b4","#2ca02c","#f1c40f","#d62728","#e377c2","#dddddd","#7f7f7f"]
    return alt.Scale(domain=domain, range=rng)

def _donut_chart(df: pd.DataFrame, cat_col: str, val_col: str, title: str):
    base = alt.Chart(df).mark_arc(innerRadius=70).encode(
        theta=alt.Theta(f"{val_col}:Q", title=None),
        color=alt.Color(f"{cat_col}:N", scale=_color_scale_color_group(), legend=alt.Legend(title="ìƒ‰ìƒê³„ì—´")),
        tooltip=[alt.Tooltip(f"{cat_col}:N", title="ìƒ‰ìƒê³„ì—´"),
                 alt.Tooltip(f"{val_col}:Q", title="kg", format=",.1f")]
    ).properties(title=title)
    return base


def render_stock_tab(stock_xlsx_path: str, spec_single: pd.DataFrame, single_df: pd.DataFrame):
    st.markdown('<div class="section-title">ğŸ“¦ ì•¡ìƒì‰í¬ ì¬ê³ ê´€ë¦¬</div>', unsafe_allow_html=True)
    st.markdown('<div class="section-sub">ì¬ê³ (í˜„ì¬) Â· ë°œì£¼/ì…ê³ (ê¸°ê°„) Â· ì‚¬ìš©ëŸ‰(ì¼ë³„)ì„ <b>ìƒ‰ìƒê³„ì—´</b> ê¸°ì¤€ìœ¼ë¡œ ìš”ì•½í•´ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤. '
                'ìƒì„¸ í’ˆëª©(ì œí’ˆì½”ë“œ) ìˆ˜ì¤€ì€ ì•„ë˜ Expanderì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

    product_to_color = build_product_to_color_map(spec_single, single_df)
    hist = load_stock_history(stock_xlsx_path, product_to_color)

    if hist.empty:
        st.error("ì¬ê³  ì—‘ì…€ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ ê²½ë¡œ/ì‹œíŠ¸ëª…(ì˜ˆ: 1.15)/ì»¬ëŸ¼ëª…(í’ˆëª©ëª…, ê¸ˆì¼ ì¬ê³ (kg), í•˜ë£¨ ì‚¬ìš©ëŸ‰(kg)) í™•ì¸ í•„ìš”)")
        st.stop()

    # --------------------------
    # í•„í„°(ìƒë‹¨)
    # --------------------------
    min_d = hist["date"].min().date()
    max_d = hist["date"].max().date()

    left, mid, right = st.columns([2.2, 2.8, 5.0])
    with left:
        quick = st.selectbox("ê¸°ê°„(ë¹ ë¥¸ ì„ íƒ)", ["ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ìµœê·¼ 90ì¼", "ì „ì²´", "ì§ì ‘ ì„ íƒ"], index=1, key="stock_quick")
    with mid:
        if quick == "ì§ì ‘ ì„ íƒ":
            start = st.date_input("ì‹œì‘ì¼", value=max(min_d, max_d - dt.timedelta(days=30)), min_value=min_d, max_value=max_d, key="stock_start")
            end = st.date_input("ì¢…ë£Œì¼", value=max_d, min_value=min_d, max_value=max_d, key="stock_end")
        else:
            if quick == "ìµœê·¼ 7ì¼":
                start = max(min_d, max_d - dt.timedelta(days=6))
            elif quick == "ìµœê·¼ 30ì¼":
                start = max(min_d, max_d - dt.timedelta(days=29))
            elif quick == "ìµœê·¼ 90ì¼":
                start = max(min_d, max_d - dt.timedelta(days=89))
            else:
                start = min_d
            end = max_d
            st.write(f"**{start} ~ {end}**")
    with right:
        divisions = sorted([x for x in hist["division"].dropna().unique().tolist()
                            if str(x).strip() and str(x).lower() not in ("nan", "none")])
        sel_div = st.multiselect("êµ¬ë¶„(PL/NPL/NSL ë“±)", divisions, default=divisions, key="stock_div")

    if start > end:
        start, end = end, start

    filt = (hist["date"].dt.date >= start) & (hist["date"].dt.date <= end)
    if sel_div:
        filt = filt & (hist["division"].isin(sel_div))
    hist_f = hist[filt].copy()

    latest_date = hist["date"].max()
    latest_df = hist[hist["date"] == latest_date].copy()
    if sel_div:
        latest_df = latest_df[latest_df["division"].isin(sel_div)].copy()

    # --------------------------
    # KPI
    # --------------------------
    total_stock = float(latest_df["curr_stock_kg"].sum())
    total_used = float(hist_f["used_kg"].sum())
    total_inbound = float(hist_f["inbound_kg"].sum())
    inbound_events = int(hist_f["inbound_event"].sum())
    day_span = max(1, (end - start).days + 1)
    avg_daily_use = total_used / day_span if day_span else 0.0

    k1, k2, k3, k4, k5 = st.columns([1.4, 1.6, 1.6, 1.6, 1.8])
    k1.metric("ì¬ê³  ìµœì‹ ì¼", latest_date.date().isoformat())
    k2.metric("í˜„ì¬ ì´ ì¬ê³ (kg)", f"{total_stock:,.1f}")
    k3.metric("ê¸°ê°„ ì´ ì‚¬ìš©ëŸ‰(kg)", f"{total_used:,.1f}")
    k4.metric("ê¸°ê°„ ë°œì£¼/ì…ê³ (ê±´)", f"{inbound_events:,}")
    k5.metric("í‰ê·  ì¼ ì‚¬ìš©ëŸ‰(kg/ì¼)", f"{avg_daily_use:,.1f}")

    st.markdown('<div class="kpi-note">â€» ë°œì£¼/ì…ê³ (kg/ê±´)ëŠ” "í•˜ë£¨ ì‚¬ìš©ëŸ‰"ì´ ìŒìˆ˜ë¡œ ê¸°ì…ëœ ê²½ìš°(ì¬ê³  ì¦ê°€)ë¥¼ ì…ê³ ë¡œ ì¶”ì •í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.</div>',
                unsafe_allow_html=True)

    st.divider()

    # --------------------------
    # ìƒ‰ìƒê³„ì—´ ë‹¨ìˆœí™”/ë§¤í•‘ ìƒíƒœ ì²´í¬
    # --------------------------
    share_other = (latest_df["color_group"] == "Other").mean() if len(latest_df) else 1.0
    if share_other > 0.6:
        st.warning(
            "âš ï¸ ì œí’ˆì½”ë“œ â†’ ìƒ‰ìƒêµ° ë§¤í•‘ì´ ì¶©ë¶„íˆ ì¡íˆì§€ ì•Šì•„ 'Other' ë¹„ì¤‘ì´ í½ë‹ˆë‹¤. "
            "ê·¸ë˜ë„ ì•„ë˜ì— **í’ˆëª©(ì œí’ˆì½”ë“œ) Top ë¦¬ìŠ¤íŠ¸**ì™€ **ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼ìˆ˜)**ë¥¼ í•¨ê»˜ ë³´ì—¬ë“œë¦¬ë‹ˆ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )

    # --------------------------
    # ìš”ì•½ ì°¨íŠ¸ (Bar ì¤‘ì‹¬: í•œëˆˆì—)
    # --------------------------
    inv = latest_df.groupby("color_group", as_index=False)["curr_stock_kg"].sum().rename(columns={"curr_stock_kg":"kg"})
    inv = inv.sort_values("kg", ascending=False)

    use = hist_f.groupby("color_group", as_index=False)["used_kg"].sum().rename(columns={"used_kg":"kg"})
    use = use.sort_values("kg", ascending=False)

    inbound = hist_f.groupby("color_group", as_index=False)["inbound_kg"].sum().rename(columns={"inbound_kg":"kg"})
    inbound = inbound[inbound["kg"] > 0].sort_values("kg", ascending=False)

    def bar_chart(df: pd.DataFrame, title: str, value_title: str):
        if df.empty:
            return None
        return (
            alt.Chart(df)
            .mark_bar()
            .encode(
                y=alt.Y("color_group:N", sort="-x", title="ìƒ‰ìƒê³„ì—´"),
                x=alt.X("kg:Q", title=value_title),
                color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
                tooltip=[
                    alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"),
                    alt.Tooltip("kg:Q", title=value_title, format=",.1f"),
                ],
            )
            .properties(title=title, height=240)
        )

    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<div class="section-title">1) í˜„ì¬ ì¬ê³ (ìµœì‹ ì¼) â€” ìƒ‰ìƒê³„ì—´</div>', unsafe_allow_html=True)
        ch = bar_chart(inv, "", "ì¬ê³ (kg)")
        if ch is None:
            st.info("í‘œì‹œí•  ì¬ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.altair_chart(ch, use_container_width=True)
            with st.expander("í‘œ(ì¬ê³  kg) ë³´ê¸°"):
                t = inv.copy()
                t["ë¹„ì¤‘(%)"] = (t["kg"] / max(1e-9, t["kg"].sum()) * 100).round(1)
                st.dataframe(t.rename(columns={"color_group":"ìƒ‰ìƒê³„ì—´", "kg":"ì¬ê³ (kg)"}), use_container_width=True, height=220)

    with c2:
        st.markdown('<div class="section-title">2) ê¸°ê°„ ì‚¬ìš©ëŸ‰ â€” ìƒ‰ìƒê³„ì—´</div>', unsafe_allow_html=True)
        ch = bar_chart(use, "", "ì‚¬ìš©ëŸ‰(kg)")
        if ch is None:
            st.info("í‘œì‹œí•  ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.altair_chart(ch, use_container_width=True)
            with st.expander("í‘œ(ì‚¬ìš©ëŸ‰ kg) ë³´ê¸°"):
                t = use.copy()
                t["ë¹„ì¤‘(%)"] = (t["kg"] / max(1e-9, t["kg"].sum()) * 100).round(1)
                st.dataframe(t.rename(columns={"color_group":"ìƒ‰ìƒê³„ì—´", "kg":"ì‚¬ìš©ëŸ‰(kg)"}), use_container_width=True, height=220)

    st.divider()

    # --------------------------
    # ì¼ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì´(ì „ì²´ + ìƒ‰ìƒê³„ì—´ ì„ íƒ)
    # --------------------------
    st.markdown('<div class="section-title">3) ì¼ë³„ ì‚¬ìš©ëŸ‰ ì¶”ì´(kg)</div>', unsafe_allow_html=True)
    keys = ["Black","Blue","Green","Yellow","Red","Pink","White","Other"]
    present = [k for k in keys if k in hist_f["color_group"].unique().tolist()]
    default_keys = [k for k in present if k != "Other"][:5] or present  # ë„ˆë¬´ ë§ìœ¼ë©´ 5ê°œë§Œ
    sel_keys = st.multiselect("í‘œì‹œí•  ìƒ‰ìƒê³„ì—´", keys, default=default_keys, key="stock_color_sel")

    daily = hist_f[hist_f["color_group"].isin(sel_keys)].groupby(["date","color_group"], as_index=False)["used_kg"].sum()
    total = hist_f.groupby("date", as_index=False)["used_kg"].sum().rename(columns={"used_kg":"TOTAL"})

    line = alt.Chart(daily).mark_line(point=True).encode(
        x=alt.X("date:T", title="ë‚ ì§œ"),
        y=alt.Y("used_kg:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
        color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=alt.Legend(title="ìƒ‰ìƒê³„ì—´")),
        tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"),
                 alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"),
                 alt.Tooltip("used_kg:Q", title="ì‚¬ìš©ëŸ‰(kg)", format=",.1f")]
    )

    total_line = alt.Chart(total).mark_line(point=True, strokeDash=[6,3]).encode(
        x="date:T",
        y=alt.Y("TOTAL:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
        tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"),
                 alt.Tooltip("TOTAL:Q", title="TOTAL(kg)", format=",.1f")]
    )

    st.altair_chart((line + total_line).interactive(), use_container_width=True)

    st.divider()

    # --------------------------
    # ë°œì£¼/ì…ê³  ì¶”ì´(ê¸°ê°„)
    # --------------------------
    st.markdown('<div class="section-title">4) ë°œì£¼/ì…ê³  ì¶”ì´(ê¸°ê°„)</div>', unsafe_allow_html=True)
    if inbound.empty:
        st.info("ì„ íƒ ê¸°ê°„ì— ë°œì£¼/ì…ê³ (ì¬ê³  ì¦ê°€)ë¡œ ì¶”ì •ë˜ëŠ” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        in_daily = hist_f.groupby("date", as_index=False).agg(inbound_kg=("inbound_kg","sum"), inbound_event=("inbound_event","sum"))
        cA, cB = st.columns(2)
        with cA:
            st.markdown("**ì…ê³ ëŸ‰(kg) ì¼ë³„**")
            ch = alt.Chart(in_daily).mark_bar().encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("inbound_kg:Q", title="ì…ê³ ëŸ‰(kg)"),
                tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"),
                         alt.Tooltip("inbound_kg:Q", title="ì…ê³ ëŸ‰(kg)", format=",.1f")]
            ).properties(height=220)
            st.altair_chart(ch, use_container_width=True)
        with cB:
            st.markdown("**ì…ê³  ì´ë²¤íŠ¸(ê±´) ì¼ë³„**")
            ch2 = alt.Chart(in_daily).mark_bar().encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("inbound_event:Q", title="ì…ê³ (ê±´)"),
                tooltip=[alt.Tooltip("date:T", title="ë‚ ì§œ"),
                         alt.Tooltip("inbound_event:Q", title="ì…ê³ (ê±´)", format=",.0f")]
            ).properties(height=220)
            st.altair_chart(ch2, use_container_width=True)

    st.divider()

    # --------------------------
    # ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼ìˆ˜) / ë°œì£¼ ì œì•ˆ(í’ˆëª© ë‹¨ìœ„)
    # --------------------------
    st.markdown('<div class="section-title">5) ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼ìˆ˜) & ë°œì£¼ ì œì•ˆ(í’ˆëª©)</div>', unsafe_allow_html=True)
    st.markdown('<div class="section-sub">í˜„ì¬ ì¬ê³  Ã· ìµœê·¼ í‰ê·  ì‚¬ìš©ëŸ‰(kg/ì¼) = ì»¤ë²„ë¦¬ì§€(ì¼ìˆ˜)ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

    target_days = st.slider("ëª©í‘œ ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼)", min_value=3, max_value=30, value=14, step=1, key="stock_target_days")
    alert_days = st.slider("ê²½ë³´ ê¸°ì¤€(ì¼)", min_value=1, max_value=21, value=7, step=1, key="stock_alert_days")

    # í‰ê·  ì‚¬ìš©ëŸ‰(kg/ì¼) ê³„ì‚°: ì„ íƒ ê¸°ê°„ ê¸°ë°˜
    use_by_product = hist_f.groupby("product_code", as_index=False).agg(
        used_total=("used_kg","sum")
    )
    use_by_product["avg_daily_use"] = use_by_product["used_total"] / day_span

    stock_by_product = latest_df.groupby("product_code", as_index=False).agg(
        stock_kg=("curr_stock_kg","sum"),
        color_group=("color_group", lambda x: x.value_counts().idxmax() if len(x) else "Other"),
        division=("division", lambda x: x.value_counts().idxmax() if len(x) else ""),
    )

    cov = stock_by_product.merge(use_by_product[["product_code","avg_daily_use"]], on="product_code", how="left")
    cov["avg_daily_use"] = cov["avg_daily_use"].fillna(0.0)
    cov["cover_days"] = cov.apply(lambda r: (r["stock_kg"] / r["avg_daily_use"]) if r["avg_daily_use"] > 0 else None, axis=1)
    cov["need_order_kg"] = cov.apply(
        lambda r: max(0.0, target_days * r["avg_daily_use"] - r["stock_kg"]) if r["avg_daily_use"] > 0 else None,
        axis=1
    )

    # ìš°ì„ ìˆœìœ„: cover_daysê°€ ë‚®ì€ ìˆœ + ì‚¬ìš©ëŸ‰ í° ìˆœ
    cov2 = cov.copy()
    cov2["_cover_sort"] = cov2["cover_days"].fillna(10**9)
    cov2 = cov2.sort_values(["_cover_sort","avg_daily_use"], ascending=[True, False]).drop(columns=["_cover_sort"])

    # ê²½ë³´ ë¦¬ìŠ¤íŠ¸
    alert_df = cov2[(cov2["cover_days"].notna()) & (cov2["cover_days"] <= float(alert_days))].copy()
    if alert_df.empty:
        st.success("âœ… ê²½ë³´ ê¸°ì¤€ ì´í•˜(ì»¤ë²„ë¦¬ì§€ ë¶€ì¡±) í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        show_cols = ["division","product_code","color_group","stock_kg","avg_daily_use","cover_days","need_order_kg"]
        tmp = alert_df[show_cols].copy()
        tmp["stock_kg"] = tmp["stock_kg"].round(1)
        tmp["avg_daily_use"] = tmp["avg_daily_use"].round(2)
        tmp["cover_days"] = tmp["cover_days"].round(1)
        tmp["need_order_kg"] = tmp["need_order_kg"].round(1)
        st.warning(f"âš ï¸ ì»¤ë²„ë¦¬ì§€ {alert_days}ì¼ ì´í•˜ í’ˆëª©: {len(tmp):,}ê°œ (ìƒìœ„ 20ê°œ í‘œì‹œ)")
        st.dataframe(tmp.head(20), use_container_width=True, height=360)

    with st.expander("ğŸ“Œ (ìƒì„¸) í’ˆëª© Top 10 / ì›í˜•(ë„ë„›) ì°¨íŠ¸ ë³´ê¸°"):
        a, b, c = st.columns(3)
        with a:
            st.markdown("**í˜„ì¬ ì¬ê³  Top10(í’ˆëª©)**")
            top_stock = stock_by_product.sort_values("stock_kg", ascending=False).head(10)
            st.dataframe(top_stock, use_container_width=True, height=260)
        with b:
            st.markdown("**ë°œì£¼/ì…ê³ ëŸ‰ Top10(í’ˆëª©, ê¸°ê°„í•©)**")
            top_in = hist_f.groupby("product_code", as_index=False)["inbound_kg"].sum().sort_values("inbound_kg", ascending=False).head(10)
            st.dataframe(top_in, use_container_width=True, height=260)
        with c:
            st.markdown("**ì‚¬ìš©ëŸ‰ Top10(í’ˆëª©, ê¸°ê°„í•©)**")
            top_use = hist_f.groupby("product_code", as_index=False)["used_kg"].sum().sort_values("used_kg", ascending=False).head(10)
            st.dataframe(top_use, use_container_width=True, height=260)

        st.markdown("**ì›í˜•(ë„ë„›) ì°¨íŠ¸(ì„ íƒ)**")
        c1, c2 = st.columns(2)
        with c1:
            if len(inv) and inv["kg"].sum() > 0:
                st.altair_chart(_donut_chart(inv.rename(columns={"kg":"kg"}), "color_group", "kg", "í˜„ì¬ ì¬ê³ (ìµœì‹ ì¼)"), use_container_width=True)
        with c2:
            if len(inbound) and inbound["kg"].sum() > 0:
                st.altair_chart(_donut_chart(inbound.rename(columns={"kg":"kg"}), "color_group", "kg", "ë°œì£¼/ì…ê³ (ê¸°ê°„í•©)"), use_container_width=True)



def render_exec_summary_tab(
    stock_xlsx_path: str | None,
    spec_single: pd.DataFrame,
    single_df: pd.DataFrame,
):
    """ì„ì›/ë³´ê³ ìš© 1í˜ì´ì§€ ìš”ì•½"""
    st.markdown('<div class="section-title">ğŸ“‘ ì„ì› ìš”ì•½ (ì¬ê³  Â· ì ë„)</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="section-sub">ìƒì‚¬/íƒ€ë¶€ì„œê°€ ë´ë„ â€œì¬ê³ ëŠ” ì´ë ‡ê²Œ ê´€ë¦¬í•˜ê³ , ì ë„ëŠ” ì´ë ‡ê²Œ ì¶”ì´ ê´€ë¦¬í•œë‹¤â€ê°€ í•œëˆˆì— ë³´ì´ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.</div>',
        unsafe_allow_html=True
    )

    # ==========================================================
    # A) ì¬ê³  ìš”ì•½
    # ==========================================================
    st.markdown('<div class="section-title">A) ì¬ê³ /ë°œì£¼/ì‚¬ìš©ëŸ‰ ìš”ì•½</div>', unsafe_allow_html=True)

    if stock_xlsx_path and Path(stock_xlsx_path).exists():
        product_to_color = build_product_to_color_map(spec_single, single_df)
        hist = load_stock_history(stock_xlsx_path, product_to_color)

        if hist.empty:
            st.info("ì¬ê³  íŒŒì¼ì„ ì½ì—ˆì§€ë§Œ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            max_d = hist["date"].max().date()
            start = max(hist["date"].min().date(), max_d - dt.timedelta(days=29))
            end = max_d
            day_span = max(1, (end - start).days + 1)

            hist_f = hist[(hist["date"].dt.date >= start) & (hist["date"].dt.date <= end)].copy()
            latest_df = hist[hist["date"].dt.date == end].copy()

            total_stock = float(latest_df["curr_stock_kg"].sum())
            total_used = float(hist_f["used_kg"].sum())
            inbound_events = int(hist_f["inbound_event"].sum())
            avg_daily_use = total_used / day_span if day_span else 0.0

            k1, k2, k3, k4, k5 = st.columns([1.2, 1.5, 1.6, 1.4, 1.8])
            k1.metric("ì¬ê³  ìµœì‹ ì¼", end.isoformat())
            k2.metric("í˜„ì¬ ì´ ì¬ê³ (kg)", f"{total_stock:,.1f}")
            k3.metric("ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰(kg)", f"{total_used:,.1f}")
            k4.metric("ìµœê·¼ 30ì¼ ì…ê³ (ê±´)", f"{inbound_events:,}")
            k5.metric("í‰ê·  ì‚¬ìš©ëŸ‰(kg/ì¼)", f"{avg_daily_use:,.1f}")

            inv = (
                latest_df.groupby("color_group", as_index=False)["curr_stock_kg"]
                .sum()
                .rename(columns={"curr_stock_kg": "kg"})
                .sort_values("kg", ascending=False)
            )
            use = (
                hist_f.groupby("color_group", as_index=False)["used_kg"]
                .sum()
                .rename(columns={"used_kg": "kg"})
                .sort_values("kg", ascending=False)
            )

            c1, c2 = st.columns(2)
            with c1:
                st.markdown("**í˜„ì¬ ì¬ê³ (ìƒ‰ìƒê³„ì—´)**")
                ch = alt.Chart(inv).mark_bar().encode(
                    y=alt.Y("color_group:N", sort="-x", title=""),
                    x=alt.X("kg:Q", title="ì¬ê³ (kg)"),
                    color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
                    tooltip=[
                        alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"),
                        alt.Tooltip("kg:Q", title="ì¬ê³ (kg)", format=",.1f"),
                    ],
                ).properties(height=220)
                st.altair_chart(ch, use_container_width=True)

            with c2:
                st.markdown("**ìµœê·¼ 30ì¼ ì‚¬ìš©ëŸ‰(ìƒ‰ìƒê³„ì—´)**")
                ch2 = alt.Chart(use).mark_bar().encode(
                    y=alt.Y("color_group:N", sort="-x", title=""),
                    x=alt.X("kg:Q", title="ì‚¬ìš©ëŸ‰(kg)"),
                    color=alt.Color("color_group:N", scale=_color_scale_color_group(), legend=None),
                    tooltip=[
                        alt.Tooltip("color_group:N", title="ìƒ‰ìƒê³„ì—´"),
                        alt.Tooltip("kg:Q", title="ì‚¬ìš©ëŸ‰(kg)", format=",.1f"),
                    ],
                ).properties(height=220)
                st.altair_chart(ch2, use_container_width=True)

            # ì»¤ë²„ë¦¬ì§€ ê²½ë³´ Top8
            use_by_product = hist_f.groupby("product_code", as_index=False)["used_kg"].sum()
            use_by_product["avg_daily_use"] = use_by_product["used_kg"] / day_span

            stock_by_product = (
                latest_df.groupby("product_code", as_index=False)["curr_stock_kg"]
                .sum()
                .rename(columns={"curr_stock_kg": "stock_kg"})
            )

            cov = stock_by_product.merge(use_by_product[["product_code", "avg_daily_use"]], on="product_code", how="left")
            cov["cover_days"] = cov.apply(
                lambda r: (r["stock_kg"] / r["avg_daily_use"]) if (r["avg_daily_use"] and r["avg_daily_use"] > 0) else None,
                axis=1,
            )
            cov2 = cov[cov["cover_days"].notna()].sort_values("cover_days").head(8)
            if len(cov2):
                st.markdown("**ì¬ê³  ì»¤ë²„ë¦¬ì§€(ì¼ìˆ˜) ê²½ë³´ Top8 (ë‚®ì€ ìˆœ)**")
                show = cov2.copy()
                show["stock_kg"] = show["stock_kg"].round(1)
                show["avg_daily_use"] = show["avg_daily_use"].round(2)
                show["cover_days"] = show["cover_days"].round(1)
                st.dataframe(
                    show.rename(
                        columns={
                            "product_code": "ì œí’ˆì½”ë“œ",
                            "stock_kg": "ì¬ê³ (kg)",
                            "avg_daily_use": "ì¼í‰ê· ì‚¬ìš©(kg)",
                            "cover_days": "ì»¤ë²„ë¦¬ì§€(ì¼)",
                        }
                    ),
                    use_container_width=True,
                    height=260,
                )
            else:
                st.info("ì»¤ë²„ë¦¬ì§€ ê³„ì‚°ì— í•„ìš”í•œ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    else:
        st.info("ì¬ê³  íŒŒì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ê³  ì—‘ì…€ ê²½ë¡œ/ì—…ë¡œë“œë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.)")

    st.divider()

    # ==========================================================
    # B) ì ë„ ìš”ì•½
    # ==========================================================
    st.markdown('<div class="section-title">B) ì ë„ ê´€ë¦¬ ìš”ì•½</div>', unsafe_allow_html=True)

    c_s_date = find_col(single_df, "ì…ê³ ì¼")
    c_s_visc = find_col(single_df, "ì ë„ì¸¡ì •ê°’(cP)")
    c_s_judge = find_col(single_df, "ì ë„íŒì •")
    c_s_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")

    if not all([c_s_date, c_s_visc, c_s_pc]):
        st.info("ì ë„ ìš”ì•½ì„ ìœ„í•´ ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ ì‹œíŠ¸ì— ì…ê³ ì¼/ì ë„ì¸¡ì •ê°’/ì œí’ˆì½”ë“œ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    df = single_df.copy()
    df[c_s_date] = pd.to_datetime(df[c_s_date], errors="coerce")
    df["_ì ë„"] = pd.to_numeric(df[c_s_visc].astype(str).str.replace(",", "", regex=False), errors="coerce")
    df = df.dropna(subset=[c_s_date, "_ì ë„", c_s_pc])

    if len(df) == 0:
        st.info("í‘œì‹œí•  ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    max_d = df[c_s_date].max().date()
    start = max(df[c_s_date].min().date(), max_d - dt.timedelta(days=29))
    df30 = df[(df[c_s_date].dt.date >= start) & (df[c_s_date].dt.date <= max_d)].copy()

    total = len(df30)
    ng = int((df30[c_s_judge] == "ë¶€ì í•©").sum()) if c_s_judge and c_s_judge in df30.columns else 0
    ng_rate = (ng / total * 100) if total else 0.0

    # ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼ í‰ê·  ë³€í™”(ì¶”ì„¸)
    last7_start = max_d - dt.timedelta(days=6)
    prev7_start = max_d - dt.timedelta(days=13)
    prev7_end = max_d - dt.timedelta(days=7)

    last7 = df[(df[c_s_date].dt.date >= last7_start) & (df[c_s_date].dt.date <= max_d)]["_ì ë„"]
    prev7 = df[(df[c_s_date].dt.date >= prev7_start) & (df[c_s_date].dt.date <= prev7_end)]["_ì ë„"]
    last7_mean = float(last7.mean()) if len(last7) else None
    prev7_mean = float(prev7.mean()) if len(prev7) else None
    delta = (last7_mean - prev7_mean) if (last7_mean is not None and prev7_mean is not None) else None

    k1, k2, k3, k4 = st.columns([1.5, 1.2, 1.3, 2.0])
    k1.metric("ìµœê·¼ 30ì¼ ì ë„ ì¸¡ì •(ê±´)", f"{total:,}")
    k2.metric("ë¶€ì í•©(ê±´)", f"{ng:,}")
    k3.metric("ë¶€ì í•©ë¥ (%)", f"{ng_rate:.1f}")
    if delta is None:
        k4.metric("ìµœê·¼ 7ì¼ í‰ê· ì ë„", f"{last7_mean:,.0f} cP" if last7_mean is not None else "-")
    else:
        k4.metric("ìµœê·¼ 7ì¼ í‰ê· ì ë„ ë³€í™”", f"{last7_mean:,.0f} cP", delta=f"{delta:,.0f} cP")

    # ì¼ë³„ í‰ê· ì ë„ + ë¶€ì í•©ê±´ìˆ˜
    daily = (
        df30.groupby(df30[c_s_date].dt.date)
        .agg(mean_visc=("_ì ë„", "mean"), cnt=("_ì ë„", "size"))
        .reset_index()
    )
    daily = daily.rename(columns={daily.columns[0]: "date"})
    daily["date"] = pd.to_datetime(daily["date"])

    if c_s_judge and c_s_judge in df30.columns:
        ng_daily = (
            df30[df30[c_s_judge] == "ë¶€ì í•©"]
            .groupby(df30[c_s_date].dt.date)
            .size()
            .reset_index(name="ng_cnt")
        )
        ng_daily = ng_daily.rename(columns={ng_daily.columns[0]: "date"})
        ng_daily["date"] = pd.to_datetime(ng_daily["date"])
        daily = daily.merge(ng_daily, on="date", how="left")
        daily["ng_cnt"] = daily["ng_cnt"].fillna(0).astype(int)
    else:
        daily["ng_cnt"] = 0

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì¼ë³„ í‰ê·  ì ë„(ìµœê·¼ 30ì¼)**")
        ch = alt.Chart(daily).mark_line(point=True).encode(
            x=alt.X("date:T", title="ë‚ ì§œ"),
            y=alt.Y("mean_visc:Q", title="í‰ê·  ì ë„(cP)"),
            tooltip=[
                alt.Tooltip("date:T", title="ë‚ ì§œ"),
                alt.Tooltip("mean_visc:Q", title="í‰ê· ì ë„", format=",.0f"),
                alt.Tooltip("cnt:Q", title="ì¸¡ì •(ê±´)", format=",.0f"),
            ],
        ).properties(height=220)
        st.altair_chart(ch, use_container_width=True)

    with c2:
        st.markdown("**ë¶€ì í•© ê±´ìˆ˜(ìµœê·¼ 30ì¼)**")
        ch2 = alt.Chart(daily).mark_bar().encode(
            x=alt.X("date:T", title="ë‚ ì§œ"),
            y=alt.Y("ng_cnt:Q", title="ë¶€ì í•©(ê±´)"),
            tooltip=[
                alt.Tooltip("date:T", title="ë‚ ì§œ"),
                alt.Tooltip("ng_cnt:Q", title="ë¶€ì í•©(ê±´)", format=",.0f"),
            ],
        ).properties(height=220)
        st.altair_chart(ch2, use_container_width=True)

    if c_s_judge and c_s_judge in df30.columns:
        top_ng = (
            df30[df30[c_s_judge] == "ë¶€ì í•©"]
            .groupby(c_s_pc)
            .size()
            .reset_index(name="ng_cnt")
            .sort_values("ng_cnt", ascending=False)
            .head(10)
        )
        if len(top_ng):
            st.markdown("**ì œí’ˆì½”ë“œ ë¶€ì í•© Top10(ìµœê·¼ 30ì¼)**")
            st.dataframe(
                top_ng.rename(columns={c_s_pc: "ì œí’ˆì½”ë“œ", "ng_cnt": "ë¶€ì í•©(ê±´)"}),
                use_container_width=True,
                height=280,
            )

    st.info("ë³´ê³  í¬ì¸íŠ¸: â‘  ì¬ê³  ìµœì‹ ì¼/ì´ì¬ê³ /ìµœê·¼30ì¼ ì‚¬ìš©ëŸ‰ â‘¡ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± Top í’ˆëª© â‘¢ ì ë„ ë¶€ì í•©ë¥  ë° ìµœê·¼ ì¶”ì„¸ â‘£ ë¶€ì í•© Top ì œí’ˆì½”ë“œ")


# ==========================================================
# UI Header
# ==========================================================
st.title("ì•¡ìƒ ì‰í¬ Lot ì¶”ì  ê´€ë¦¬ ëŒ€ì‹œë³´ë“œ")
st.caption("âœ… ëŒ€ì‹œë³´ë“œ(ëª©ë¡/í‰ê· /ì¶”ì´)  |  âœ… ì‰í¬ ì…ê³ (ì—‘ì…€ ëˆ„ì )  |  âœ… ë°”ì¸ë” ì…ì¶œê³ (êµ¬ê¸€ì‹œíŠ¸ ìµœì‹ ìˆœ)  |  âœ… ë°˜í’ˆ(kg) ê¸°ë¡  |  âœ… ë¹ ë¥¸ê²€ìƒ‰/ìˆ˜ì •  |  âœ… ì¬ê³ ê´€ë¦¬(ì¬ê³ /ë°œì£¼/ì‚¬ìš©ëŸ‰)")

# ==========================================================
# Data file selection
# ==========================================================
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼")
    xlsx_path = st.text_input("ì—‘ì…€ íŒŒì¼ ê²½ë¡œ", value=DEFAULT_XLSX)
    uploaded = st.file_uploader("ë˜ëŠ” ì—‘ì…€ ì—…ë¡œë“œ(ì—…ë¡œë“œ ëª¨ë“œ: ì„œë²„ ì €ì¥ ë³´ì¥ X)", type=["xlsx"], key="lot_upload")

    st.divider()
    st.header("ì¬ê³  íŒŒì¼")
    stock_xlsx_path = st.text_input("ì¬ê³  ì—‘ì…€ íŒŒì¼ ê²½ë¡œ", value=DEFAULT_STOCK_XLSX, key="stock_path")
    uploaded_stock = st.file_uploader("ë˜ëŠ” ì¬ê³  ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx"], key="stock_upload")

# ì—…ë¡œë“œ íŒŒì¼ì€ "ì²˜ìŒ 1íšŒë§Œ" tmpë¡œ ë³µì‚¬ (ì €ì¥í•œ ë‚´ìš©ì´ rerun ë•Œ ë®ì–´ì¨ì§€ëŠ” ë¬¸ì œ ë°©ì§€)
if uploaded is not None:
    upload_sig = f"{uploaded.name}:{uploaded.size}"
    if st.session_state.get("_uploaded_sig") != upload_sig:
        tmp_path = Path(".streamlit_tmp.xlsx")
        tmp_path.write_bytes(uploaded.getvalue())
        st.session_state["_uploaded_sig"] = upload_sig
        st.session_state["_tmp_xlsx_path"] = str(tmp_path)
    xlsx_path = st.session_state.get("_tmp_xlsx_path", xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼(Lotê´€ë¦¬)ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì„œë²„ ì¬ì‹œì‘ ì‹œ ëˆ„ì ì´ ë³´ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)")

if uploaded_stock is not None:
    upload_sig_stock = f"{uploaded_stock.name}:{uploaded_stock.size}"
    if st.session_state.get("_uploaded_sig_stock") != upload_sig_stock:
        tmp_stock = Path(".streamlit_tmp_stock.xlsx")
        tmp_stock.write_bytes(uploaded_stock.getvalue())
        st.session_state["_uploaded_sig_stock"] = upload_sig_stock
        st.session_state["_tmp_stock_path"] = str(tmp_stock)
    stock_xlsx_path = st.session_state.get("_tmp_stock_path", stock_xlsx_path)
    st.sidebar.info("ì—…ë¡œë“œ íŒŒì¼(ì¬ê³ )ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. (ì„œë²„ ì¬ì‹œì‘ ì‹œ ëˆ„ì ì´ ë³´ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)")

if not Path(xlsx_path).exists():
    st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {xlsx_path}")
    st.stop()

# ë°˜í™˜ ì‹œíŠ¸ ì—†ìœ¼ë©´ ìƒì„±
ensure_sheet_exists(
    xlsx_path,
    SHEET_BINDER_RETURN,
    headers=["ì¼ì", "ë°”ì¸ë”íƒ€ì…", "ë°”ì¸ë”ëª…", "ë°”ì¸ë” Lot", "ë°˜í™˜ëŸ‰(kg)", "ë¹„ê³ "]
)

data = load_dataframes(xlsx_path)
binder_df = data["binder"].copy()
single_df = data["single"].copy()
spec_binder = data["spec_binder"].copy()
spec_single = data["spec_single"].copy()
base_lab = data["base_lab"].copy()
binder_return_df = data["binder_return"].copy()

# ì»¬ëŸ¼ ì°¸ì¡°(ì‹¤ì œ ì´ë¦„)
c_b_date = find_col(binder_df, "ì œì¡°/ì…ê³ ì¼")
c_s_date = find_col(single_df, "ì…ê³ ì¼")

# ë‚ ì§œ ì •ë¦¬
if c_b_date:
    binder_df[c_b_date] = binder_df[c_b_date].apply(normalize_date)
if c_s_date:
    single_df[c_s_date] = single_df[c_s_date].apply(normalize_date)

# ëŒ€ì‹œë³´ë“œ íŒŒìƒ
c_s_visc = find_col(single_df, "ì ë„ì¸¡ì •ê°’(cP)")
c_s_lot = find_col(single_df, "ë‹¨ì¼ìƒ‰ì‰í¬ Lot")
c_s_blot = find_col(single_df, "ì‚¬ìš©ëœ ë°”ì¸ë” Lot")
c_s_cg = find_col(single_df, "ìƒ‰ìƒêµ°")
c_s_pc = find_col(single_df, "ì œí’ˆì½”ë“œ")

# Î”E76
single_df["_Î”E76"] = compute_de76_series(single_df, base_lab)

# tabs (âœ… ì¬ê³  íƒ­ ì¶”ê°€)
tab_exec, tab_dash, tab_stock, tab_ink_in, tab_binder, tab_search = st.tabs(
    ["ğŸ“‘ ì„ì› ìš”ì•½", "ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“¦ ì•¡ìƒì‰í¬ ì¬ê³ ê´€ë¦¬", "âœï¸ ì‰í¬ ì…ê³ ", "ğŸ“¦ ë°”ì¸ë” ì…ì¶œê³ ", "ğŸ” ë¹ ë¥¸ê²€ìƒ‰/ìˆ˜ì •"]
)


# ==========================================================
# Executive Summary (ì„ì› ìš”ì•½)
# ==========================================================
with tab_exec:
    render_exec_summary_tab(stock_xlsx_path, spec_single, single_df)

# ==========================================================
# Dashboard
# ==========================================================
with tab_dash:
    # KPI
    b_total = len(binder_df)
    s_total = len(single_df)
    c_b_judge = find_col(binder_df, "íŒì •")
    c_s_judge = find_col(single_df, "ì ë„íŒì •")
    b_ng = int((binder_df[c_b_judge] == "ë¶€ì í•©").sum()) if c_b_judge else 0
    s_ng = int((single_df[c_s_judge] == "ë¶€ì í•©").sum()) if c_s_judge else 0

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ë°”ì¸ë” ê¸°ë¡", f"{b_total:,}")
    c2.metric("ë°”ì¸ë” ë¶€ì í•©", f"{b_ng:,}")
    c3.metric("ë‹¨ì¼ìƒ‰ ê¸°ë¡", f"{s_total:,}")
    c4.metric("ë‹¨ì¼ìƒ‰(ì ë„) ë¶€ì í•©", f"{s_ng:,}")

    st.divider()

    # 1) ëª©ë¡(ì—‘ì…€í˜•)
    st.subheader("1) ë‹¨ì¼ìƒ‰ ë°ì´í„° ëª©ë¡ (ì—‘ì…€í˜•)")
    need = [c_s_date, c_s_cg, c_s_pc, c_s_blot, c_s_visc]
    if any(c is None for c in need):
        st.warning("ë‹¨ì¼ìƒ‰ ì‹œíŠ¸ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì…ê³ ì¼/ìƒ‰ìƒêµ°/ì œí’ˆì½”ë“œ/ì‚¬ìš©ëœ ë°”ì¸ë” Lot/ì ë„ì¸¡ì •ê°’)")
    else:
        df_list = single_df.copy()
        df_list[c_s_date] = pd.to_datetime(df_list[c_s_date], errors="coerce")
        dmin, dmax = safe_date_bounds(df_list[c_s_date])

        f1, f2, f3, f4 = st.columns([1.2, 1.2, 1.6, 2.0])
        with f1:
            start = st.date_input("ì‹œì‘ì¼(ëª©ë¡)", value=max(dmin, dmax - dt.timedelta(days=90)), key="list_start")
        with f2:
            end = st.date_input("ì¢…ë£Œì¼(ëª©ë¡)", value=dmax, key="list_end")
        with f3:
            cg_opts = sorted([x for x in df_list[c_s_cg].dropna().unique().tolist()]) if c_s_cg else []
            cg = st.multiselect("ìƒ‰ìƒêµ°(ëª©ë¡)", cg_opts, key="list_cg")
        with f4:
            pc_opts = sorted([x for x in df_list[c_s_pc].dropna().unique().tolist()]) if c_s_pc else []
            pc = st.multiselect("ì œí’ˆì½”ë“œ(ëª©ë¡)", pc_opts, key="list_pc")

        if start > end:
            start, end = end, start

        df_list = df_list[(df_list[c_s_date].dt.date >= start) & (df_list[c_s_date].dt.date <= end)]
        if cg and c_s_cg:
            df_list = df_list[df_list[c_s_cg].isin(cg)]
        if pc and c_s_pc:
            df_list = df_list[df_list[c_s_pc].isin(pc)]

        view = pd.DataFrame({
            "ì œì¡°ì¼ì": df_list[c_s_date].dt.date,
            "ìƒ‰ìƒêµ°": df_list[c_s_cg] if c_s_cg else None,
            "ì œí’ˆì½”ë“œ": df_list[c_s_pc] if c_s_pc else None,
            "ì‚¬ìš©ëœë°”ì¸ë”": df_list[c_s_blot] if c_s_blot else None,
            "ì ë„(cP)": pd.to_numeric(df_list[c_s_visc].astype(str).str.replace(",", "", regex=False), errors="coerce") if c_s_visc else None,
            "ìƒ‰ì°¨(Î”E76)": df_list["_Î”E76"],
        }).dropna(subset=["ì œì¡°ì¼ì"]).sort_values(by="ì œì¡°ì¼ì", ascending=False)

        st.dataframe(view, use_container_width=True, height=320)

        st.divider()

        st.subheader("1-1) ìƒ‰ìƒêµ°ë³„ í‰ê·  ì ë„ (ì  + ê°’)")
        mean_df = (
            view.dropna(subset=["ìƒ‰ìƒêµ°", "ì ë„(cP)"])
            .groupby("ìƒ‰ìƒêµ°", as_index=False)["ì ë„(cP)"]
            .mean()
            .rename(columns={"ì ë„(cP)": "í‰ê· ì ë„(cP)"})
        )
        if len(mean_df) == 0:
            st.info("í‘œì‹œí•  í‰ê·  ì ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            mean_df["í‘œì‹œ"] = mean_df["í‰ê· ì ë„(cP)"].round(0).astype("Int64").astype(str)
            base = alt.Chart(mean_df).encode(
                x=alt.X("ìƒ‰ìƒêµ°:N", sort=sorted(mean_df["ìƒ‰ìƒêµ°"].unique().tolist()), title="ìƒ‰ìƒêµ°"),
                y=alt.Y("í‰ê· ì ë„(cP):Q", title="í‰ê·  ì ë„(cP)"),
                tooltip=["ìƒ‰ìƒêµ°:N", "í‰ê· ì ë„(cP):Q"],
            )
            pts = base.mark_circle(size=240)
            lbl = base.mark_text(dx=10, dy=-10).encode(text="í‘œì‹œ:N")
            st.altair_chart((pts + lbl).interactive(), use_container_width=True)

    st.divider()

    # 3) ì œí’ˆ(ë‹¨ì¼ìƒ‰)ë³„ íŠ¸ë Œë“œ + ìŠ¤í™ì„  + ìŠ¤í™ ìˆ˜ì •
    st.subheader("3) ì œí’ˆë³„ ì ë„ íŠ¸ëœë“œ")
    st.caption("ì œí’ˆì½”ë“œ ê¸°ì¤€ ì ë„ ì¶”ì´ + ìŠ¤í™ ìƒ/í•˜í•œ(ë¹¨ê°„ì„ ) í‘œì‹œ, ê·¸ë¦¬ê³  ìŠ¤í™ ê°’ì€ ëŒ€ì‹œë³´ë“œì—ì„œ ë°”ë¡œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    if not all([c_s_date, c_s_visc, c_s_pc]):
        st.info("ì œí’ˆë³„ íŠ¸ë Œë“œë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë‹¨ì¼ìƒ‰ ì‹œíŠ¸ì— ì…ê³ ì¼/ì ë„ì¸¡ì •ê°’/ì œí’ˆì½”ë“œ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        dfp = single_df.copy()
        dfp[c_s_date] = pd.to_datetime(dfp[c_s_date], errors="coerce")
        dfp["_ì ë„"] = pd.to_numeric(dfp[c_s_visc].astype(str).str.replace(",", "", regex=False), errors="coerce")
        dfp = dfp.dropna(subset=[c_s_date, "_ì ë„", c_s_pc])

        prod_opts = sorted(dfp[c_s_pc].astype(str).dropna().unique().tolist())
        if len(prod_opts) == 0:
            st.info("ì œí’ˆì½”ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            cA, cB, cC = st.columns([1.4, 1.2, 1.4])
            with cA:
                prod = st.selectbox("ì œí’ˆì½”ë“œ ì„ íƒ", prod_opts, key="prod_trend_pc")
            with cB:
                cg_val = None
                if c_s_cg:
                    cg_opts = sorted(dfp[dfp[c_s_pc].astype(str) == str(prod)][c_s_cg].dropna().unique().tolist())
                    cg_val = st.selectbox("ìƒ‰ìƒêµ°(ì„ íƒ)", ["(ì „ì²´)"] + cg_opts, key="prod_trend_cg")
            with cC:
                btypes = []
                if c_s_blot:
                    for x in dfp[dfp[c_s_pc].astype(str) == str(prod)][c_s_blot].dropna().astype(str).tolist():
                        bt = infer_binder_name_from_lot(spec_binder, x)
                        if bt:
                            btypes.append(bt)
                btypes = sorted(set(btypes))
                bt_val = st.selectbox("BinderType(ìë™/ì„ íƒ)", ["(ìë™/ì „ì²´)"] + btypes, key="prod_trend_bt")

            dfp2 = dfp[dfp[c_s_pc].astype(str) == str(prod)].copy()
            if c_s_cg and cg_val and cg_val != "(ì „ì²´)":
                dfp2 = dfp2[dfp2[c_s_cg] == cg_val]

            # ìŠ¤í™ ì¡°íšŒ
            c_sp_cg = find_col(spec_single, "ìƒ‰ìƒêµ°")
            c_sp_pc = find_col(spec_single, "ì œí’ˆì½”ë“œ")
            c_sp_bt = find_col(spec_single, "BinderType")
            c_sp_lo = find_col(spec_single, "í•˜í•œ")
            c_sp_hi = find_col(spec_single, "ìƒí•œ")

            spec_lo = None
            spec_hi = None
            spec_row_excel = None

            if all([c_sp_pc, c_sp_lo, c_sp_hi]) and len(spec_single):
                hit = spec_single.copy()
                hit[c_sp_pc] = hit[c_sp_pc].astype(str).str.strip()
                hit = hit[hit[c_sp_pc] == str(prod).strip()]

                if c_s_cg and cg_val and cg_val != "(ì „ì²´)" and c_sp_cg:
                    hit = hit[hit[c_sp_cg] == cg_val]

                if bt_val != "(ìë™/ì „ì²´)" and c_sp_bt:
                    hit = hit[hit[c_sp_bt] == bt_val]

                if len(hit) >= 1:
                    spec_lo = safe_to_float(hit.iloc[0][c_sp_lo])
                    spec_hi = safe_to_float(hit.iloc[0][c_sp_hi])
                    spec_row_excel = int(hit.index[0]) + 2

            # ì°¨íŠ¸
            if len(dfp2) == 0:
                st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                dfp2 = dfp2.sort_values(c_s_date)
                dfp2["_í‘œì‹œ"] = dfp2["_ì ë„"].round(0).astype("Int64").astype(str)

                base = alt.Chart(dfp2).encode(
                    x=alt.X(f"{c_s_date}:T", title="ì…ê³ ì¼"),
                    y=alt.Y("_ì ë„:Q", title="ì ë„(cP)"),
                    tooltip=[f"{c_s_date}:T", f"{c_s_pc}:N", "_ì ë„:Q"] + ([f"{c_s_cg}:N"] if c_s_cg else []) + ([f"{c_s_blot}:N"] if c_s_blot else []),
                )
                line = base.mark_line()
                pts = base.mark_point(size=260)
                lbl = base.mark_text(dy=-12).encode(text="_í‘œì‹œ:N")

                layers = [line, pts, lbl]

                # ìŠ¤í™ì„ (ë¹¨ê°„ì„ )
                if spec_lo is not None:
                    lo_df = pd.DataFrame({"y": [spec_lo]})
                    lo_rule = alt.Chart(lo_df).mark_rule(color="red").encode(y="y:Q")
                    layers.append(lo_rule)
                if spec_hi is not None:
                    hi_df = pd.DataFrame({"y": [spec_hi]})
                    hi_rule = alt.Chart(hi_df).mark_rule(color="red").encode(y="y:Q")
                    layers.append(hi_rule)

                st.altair_chart(alt.layer(*layers).interactive(), use_container_width=True)

            # ìŠ¤í™ ìˆ˜ì • UI
            with st.expander("ìŠ¤í™ ìƒ/í•˜í•œ ìˆ˜ì •(Excel: Spec_Single_H&S)"):
                if spec_row_excel is None:
                    st.info("í˜„ì¬ ì„ íƒ ì¡°ê±´ìœ¼ë¡œ Spec_Single_H&Sì—ì„œ ìŠ¤í™ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì œí’ˆì½”ë“œ/ìƒ‰ìƒêµ°/BinderType ë§¤ì¹­ í™•ì¸)")
                else:
                    cX, cY = st.columns(2)
                    with cX:
                        new_lo = st.number_input("ìƒˆ í•˜í•œ", value=float(spec_lo) if spec_lo is not None else 0.0, step=10.0, format="%.1f", key="spec_edit_lo")
                    with cY:
                        new_hi = st.number_input("ìƒˆ ìƒí•œ", value=float(spec_hi) if spec_hi is not None else 0.0, step=10.0, format="%.1f", key="spec_edit_hi")

                    if st.button("ìŠ¤í™ ì €ì¥", type="primary", key="spec_save_btn"):
                        updates = []
                        if c_sp_lo:
                            updates.append((spec_row_excel, c_sp_lo, float(new_lo)))
                        if c_sp_hi:
                            updates.append((spec_row_excel, c_sp_hi, float(new_hi)))
                        try:
                            update_sheet_cells(xlsx_path, SHEET_SPEC_SINGLE, updates)
                            st.success("ìŠ¤í™ ì €ì¥ ì™„ë£Œ! (ë‹¤ì‹œ ê³„ì‚°/í‘œì‹œë©ë‹ˆë‹¤)")
                            st.cache_data.clear()
                            st.rerun()
                        except Exception as e:
                            st.error(f"ìŠ¤í™ ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()

    st.subheader("ìµœê·¼ 20ê±´ (ë‹¨ì¼ìƒ‰)")
    show = single_df.copy()
    if c_s_date:
        show[c_s_date] = pd.to_datetime(show[c_s_date], errors="coerce")
        show = show.sort_values(by=c_s_date, ascending=False)
    st.dataframe(show.head(20), use_container_width=True)

    with st.expander("ìµœê·¼ ë°ì´í„°(ë‹¨ì¼ìƒ‰) ìˆ˜ì •í•˜ê¸° (ìµœëŒ€ 50ê±´)"):
        st.caption("ì‹¤ìˆ˜ë¡œ ì…ë ¥ëœ ê°’ì´ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ ë°”ë¡œ ìˆ˜ì • â†’ 'ë³€ê²½ì‚¬í•­ ì €ì¥'ì„ ëˆ„ë¥´ì‹œë©´ ì—‘ì…€ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        if len(single_df) == 0:
            st.info("ë‹¨ì¼ìƒ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            edit_base = add_excel_row_number(show.head(50)).copy()
            editable_cols = []
            for w in ["ì…ê³ ì¼", "ì‰í¬íƒ€ì…\n(HEMA/Silicone)", "ìƒ‰ìƒêµ°", "ì œí’ˆì½”ë“œ", "ë‹¨ì¼ìƒ‰ì‰í¬ Lot", "ì‚¬ìš©ëœ ë°”ì¸ë” Lot",
                      "ë°”ì¸ë”ì œì¡°ì²˜\n(ë‚´ë¶€/ì™¸ì£¼)", "BinderType(ìë™)", "ì ë„ì¸¡ì •ê°’(cP)", "ì°©ìƒ‰ë ¥_L*", "ì°©ìƒ‰ë ¥_a*", "ì°©ìƒ‰ë ¥_b*", "ë¹„ê³ "]:
                c = find_col(edit_base, w)
                if c:
                    editable_cols.append(c)
            show_cols = ["_excel_row"] + editable_cols
            original = edit_base[show_cols].copy()

            edited = st.data_editor(
                original,
                use_container_width=True,
                num_rows="fixed",
                key="edit_recent_single",
                disabled=["_excel_row"],
            )

            if st.button("ë³€ê²½ì‚¬í•­ ì €ì¥(ìµœê·¼ 50ê±´)", type="primary", key="save_recent_single"):
                updates = []
                for i in range(len(original)):
                    excel_row = int(original.iloc[i]["_excel_row"])
                    for col in editable_cols:
                        before = original.iloc[i][col]
                        after = edited.iloc[i][col]
                        if (pd.isna(before) and pd.isna(after)) or (str(before) == str(after)):
                            continue
                        if "ì¼" in norm_key(col) and after is not None:
                            after = normalize_date(after)
                        updates.append((excel_row, col, after))
                if not updates:
                    st.info("ë³€ê²½ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        update_sheet_cells(xlsx_path, SHEET_SINGLE, updates)
                        st.success("ìˆ˜ì •ì‚¬í•­ ì €ì¥ ì™„ë£Œ!")
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================================
# Stock Tab
# ==========================================================
with tab_stock:
    if stock_xlsx_path and Path(stock_xlsx_path).exists():
        render_stock_tab(stock_xlsx_path, spec_single, single_df)
    else:
        st.error("ì¬ê³  íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì¬ê³  íŒŒì¼ ê²½ë¡œ/ì—…ë¡œë“œ ì„¤ì •)")

# ==========================================================
# ì‰í¬ ì…ê³  (ë‹¨ì¼ìƒ‰ ì…ë ¥)
# ==========================================================
with tab_ink_in:
    st.subheader("ë‹¨ì¼ìƒ‰ ì‰í¬ ì…ë ¥(ì…ê³ )")
    st.info("ì´ íƒ­ì€ **ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬** ì‹œíŠ¸ì— í–‰ì„ ì¶”ê°€(Append)í•˜ì—¬ ëˆ„ì í•©ë‹ˆë‹¤. (ë™ì‹œ ì‚¬ìš© ì‹œ ì¶©ëŒ ê°€ëŠ¥)")

    ink_types = ["HEMA", "Silicone"]
    cg_col = find_col(spec_single, "ìƒ‰ìƒêµ°")
    pc_col = find_col(spec_single, "ì œí’ˆì½”ë“œ")
    bt_col = find_col(spec_single, "BinderType")
    lo_col = find_col(spec_single, "í•˜í•œ")
    hi_col = find_col(spec_single, "ìƒí•œ")

    color_groups = sorted(spec_single[cg_col].dropna().unique().tolist()) if cg_col else []
    product_codes = sorted(spec_single[pc_col].dropna().unique().tolist()) if pc_col else []

    # ë°”ì¸ë” Lot í›„ë³´: ì—‘ì…€(ë°”ì¸ë”_ì œì¡°_ì…ê³ ) + êµ¬ê¸€ì‹œíŠ¸(ë°”ì¸ë” ì…ì¶œê³ ) LOT
    c_blot = find_col(binder_df, "Lot(ìë™)")
    binder_lots_excel = binder_df[c_blot].dropna().astype(str).tolist() if c_blot else []

    binder_lots_gsheet: list[str] = []
    try:
        df_hema_l = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil_l = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
        lot_h = detect_lot_col(df_hema_l)
        lot_s = detect_lot_col(df_sil_l)
        if lot_h:
            binder_lots_gsheet += df_hema_l[lot_h].dropna().astype(str).tolist()
        if lot_s:
            binder_lots_gsheet += df_sil_l[lot_s].dropna().astype(str).tolist()
    except Exception:
        binder_lots_gsheet = []

    _lots_all = []
    for x in (binder_lots_excel + binder_lots_gsheet):
        s = str(x).strip()
        if not s:
            continue
        if s.lower() in ("nan", "none"):
            continue
        _lots_all.append(s)

    binder_lots = sorted(set(_lots_all), reverse=True)

    c_refresh, _sp = st.columns([1.4, 8.6])
    with c_refresh:
        if st.button("ë°”ì¸ë” Lot ìµœì‹ ê°’ìœ¼ë¡œ ê°±ì‹ ", key="btn_refresh_binder_lots"):
            st.cache_data.clear()
            st.rerun()
    with _sp:
        st.caption("â€» 'ì‚¬ìš©ëœ ë°”ì¸ë” Lot' ëª©ë¡ì€ ì—‘ì…€(ë°”ì¸ë”_ì œì¡°_ì…ê³ ) + êµ¬ê¸€ì‹œíŠ¸(ë°”ì¸ë” ì…ì¶œê³ ) LOTë¥¼ í•©ì³ í‘œì‹œí•©ë‹ˆë‹¤. êµ¬ê¸€ì‹œíŠ¸ë¥¼ ìˆ˜ì •í–ˆë‹¤ë©´ ìœ„ ë²„íŠ¼ìœ¼ë¡œ ê°±ì‹ í•˜ì„¸ìš”.")

    with st.form("single_form", clear_on_submit=True):
        col1, col2, col3, col4 = st.columns([1.2, 1.3, 1.5, 2.0])
        with col1:
            in_date = st.date_input("ì…ê³ ì¼", value=dt.date.today(), key="single_in_date")
            ink_type = st.selectbox("ì‰í¬íƒ€ì…", ink_types, key="single_ink_type")
            color_group = st.selectbox("ìƒ‰ìƒêµ°", color_groups, key="single_cg") if color_groups else st.text_input("ìƒ‰ìƒêµ°", key="single_cg_text")
        with col2:
            product_code = st.selectbox("ì œí’ˆì½”ë“œ", product_codes, key="single_pc") if product_codes else st.text_input("ì œí’ˆì½”ë“œ", key="single_pc_text")
            binder_lot = st.selectbox("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", binder_lots, key="single_blot") if binder_lots else st.text_input("ì‚¬ìš©ëœ ë°”ì¸ë” Lot", key="single_blot_text")
        with col3:
            visc_meas = st.number_input("ì ë„ì¸¡ì •ê°’(cP)", min_value=0.0, step=1.0, format="%.1f", key="single_visc")
            supplier = st.selectbox("ë°”ì¸ë”ì œì¡°ì²˜", ["ë‚´ë¶€", "ì™¸ì£¼"], index=0, key="single_supplier")
        with col4:
            st.caption("ì„ íƒ: ì°©ìƒ‰ë ¥(L*a*b*) ì…ë ¥ ì‹œ, ê¸°ì¤€LABì´ ìˆìœ¼ë©´ Î”E(76)ì„ ìë™ ê³„ì‚°í•´ 'ë¹„ê³ 'ì— ê¸°ë¡í•©ë‹ˆë‹¤.")
            L = st.number_input("ì°©ìƒ‰ë ¥_L*", value=0.0, step=0.1, format="%.2f", key="single_L")
            a = st.number_input("ì°©ìƒ‰ë ¥_a*", value=0.0, step=0.1, format="%.2f", key="single_a")
            b = st.number_input("ì°©ìƒ‰ë ¥_b*", value=0.0, step=0.1, format="%.2f", key="single_b")
            lab_enabled = st.checkbox("L*a*b* ì…ë ¥í•¨", value=False, key="single_lab_en")

        note = st.text_input("ë¹„ê³ ", value="", key="single_note")
        submit_s = st.form_submit_button("ì €ì¥(ë‹¨ì¼ìƒ‰)")

    if submit_s:
        binder_type = infer_binder_name_from_lot(spec_binder, binder_lot)

        lo, hi = None, None
        visc_judge = None
        if all([cg_col, pc_col, lo_col, hi_col]) and len(spec_single):
            hit = spec_single[(spec_single[cg_col] == color_group) & (spec_single[pc_col] == product_code)].copy()
            if binder_type and bt_col and bt_col in hit.columns:
                hit = hit[hit[bt_col] == binder_type]
            if len(hit):
                lo = safe_to_float(hit.iloc[0][lo_col])
                hi = safe_to_float(hit.iloc[0][hi_col])
                visc_judge = judge_range(visc_meas, lo, hi)

        new_lot = generate_single_lot(single_df, product_code, color_group, in_date)
        if new_lot is None:
            st.error("ë‹¨ì¼ìƒ‰ Lot ìë™ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ìƒ‰ìƒêµ° ë§¤í•‘ í™•ì¸ í•„ìš”)")
        else:
            note2 = note
            if lab_enabled:
                base_pc = find_col(base_lab, "ì œí’ˆì½”ë“œ")
                base_hit = base_lab[base_lab[base_pc].astype(str).str.strip() == str(product_code).strip()] if base_pc else pd.DataFrame()

                bL = find_col(base_lab, "ê¸°ì¤€_L*")
                ba = find_col(base_lab, "ê¸°ì¤€_a*")
                bb = find_col(base_lab, "ê¸°ì¤€_b*")
                if len(base_hit) == 1 and all([bL, ba, bb]):
                    base_vals = (safe_to_float(base_hit.iloc[0][bL]), safe_to_float(base_hit.iloc[0][ba]), safe_to_float(base_hit.iloc[0][bb]))
                    if None not in base_vals:
                        de = delta_e76((float(L), float(a), float(b)), base_vals)
                        note2 = (note2 + " " if note2 else "") + f"[Î”E76={de:.2f}]"
                    else:
                        note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"
                else:
                    note2 = (note2 + " " if note2 else "") + f"[Lab=({L:.2f},{a:.2f},{b:.2f})]"

            row = {
                norm_key("ì…ê³ ì¼"): in_date,
                norm_key("ì‰í¬íƒ€ì…\n(HEMA/Silicone)"): ink_type,
                norm_key("ìƒ‰ìƒêµ°"): color_group,
                norm_key("ì œí’ˆì½”ë“œ"): product_code,
                norm_key("ë‹¨ì¼ìƒ‰ì‰í¬ Lot"): new_lot,
                norm_key("ì‚¬ìš©ëœ ë°”ì¸ë” Lot"): binder_lot,
                norm_key("ë°”ì¸ë”ì œì¡°ì²˜\n(ë‚´ë¶€/ì™¸ì£¼)"): supplier,
                norm_key("BinderType(ìë™)"): binder_type,
                norm_key("ì ë„ì¸¡ì •ê°’(cP)"): float(visc_meas),
                norm_key("ì ë„í•˜í•œ"): lo,
                norm_key("ì ë„ìƒí•œ"): hi,
                norm_key("ì ë„íŒì •"): visc_judge,
                norm_key("ì°©ìƒ‰ë ¥_L*"): float(L) if lab_enabled else None,
                norm_key("ì°©ìƒ‰ë ¥_a*"): float(a) if lab_enabled else None,
                norm_key("ì°©ìƒ‰ë ¥_b*"): float(b) if lab_enabled else None,
                norm_key("ë¹„ê³ "): note2,
            }

            try:
                append_row_to_sheet(xlsx_path, SHEET_SINGLE, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë‹¨ì¼ìƒ‰ Lot = {new_lot} / ì ë„íŒì • = {visc_judge}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================================
# ë°”ì¸ë” ì…ì¶œê³ 
# ==========================================================
with tab_binder:
    st.subheader("ì—…ì²´ë°˜í™˜(ë°˜í’ˆ) ì…ë ¥ (kg ë‹¨ìœ„)")
    st.caption("â€» 20kg(1í†µ) ê¸°ì¤€ì´ë”ë¼ë„, ì‹¤ì œ ë°˜í™˜ëŸ‰ì€ kg ë‹¨ìœ„ë¡œ ì…ë ¥í•©ë‹ˆë‹¤.")

    bname_col = find_col(spec_binder, "ë°”ì¸ë”ëª…")
    binder_names = sorted(spec_binder[bname_col].dropna().unique().tolist()) if bname_col else []
    blot_col = find_col(binder_df, "Lot(ìë™)")
    binder_lots = binder_df[blot_col].dropna().astype(str).tolist() if blot_col else []
    binder_lots = sorted(set([x.strip() for x in binder_lots if x.strip()]), reverse=True)

    with st.form("binder_return_form", clear_on_submit=True):
        c1, c2, c3 = st.columns([1.2, 1.2, 2.6])
        with c1:
            r_date = st.date_input("ë°˜í™˜ì¼ì", value=dt.date.today(), key="ret_date")
        with c2:
            r_type = st.selectbox("ë°”ì¸ë”íƒ€ì…", ["HEMA", "Silicone"], key="ret_type")
        with c3:
            r_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="ret_name") if binder_names else st.text_input("ë°”ì¸ë”ëª…", key="ret_name_text")

        c4, c5, c6 = st.columns([2.0, 1.2, 2.8])
        with c4:
            r_lot = st.selectbox("ë°”ì¸ë” Lot(ì„ íƒ)", ["(ì§ì ‘ì…ë ¥)"] + binder_lots, key="ret_lot_sel")
            r_lot_text = st.text_input("ë°”ì¸ë” Lot ì§ì ‘ì…ë ¥", value="", key="ret_lot_text") if r_lot == "(ì§ì ‘ì…ë ¥)" else ""
            final_lot = r_lot_text.strip() if r_lot == "(ì§ì ‘ì…ë ¥)" else r_lot
        with c5:
            r_kg = st.number_input("ë°˜í™˜ëŸ‰(kg)", min_value=0.0, step=0.5, format="%.1f", key="ret_kg")
        with c6:
            r_note = st.text_input("ë¹„ê³ ", value="", key="ret_note")

        submit_ret = st.form_submit_button("ë°˜í’ˆ ì €ì¥")

    if submit_ret:
        if r_kg <= 0:
            st.error("ë°˜í™˜ëŸ‰(kg)ì€ 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤.")
        else:
            row = {
                "ì¼ì": r_date,
                "ë°”ì¸ë”íƒ€ì…": r_type,
                "ë°”ì¸ë”ëª…": r_name,
                "ë°”ì¸ë” Lot": final_lot,
                "ë°˜í™˜ëŸ‰(kg)": float(r_kg),
                "ë¹„ê³ ": r_note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER_RETURN, row)
                st.success("ë°˜í’ˆ ì €ì¥ ì™„ë£Œ!")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ë°˜í’ˆ ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()
    st.subheader("ë°”ì¸ë” ì…ë ¥ (ì œì¡°/ì…ê³ ) â€” ì—¬ëŸ¬ ë‚ ì§œ/ìˆ˜ëŸ‰ ë¬¶ìŒ ì…ë ¥ ì§€ì›")

    input_mode = st.radio("ì…ë ¥ ë°©ì‹", ["ê°œë³„ ì…ë ¥", "ë¬¶ìŒ ì…ë ¥(ì—¬ëŸ¬ ë‚ ì§œ/ìˆ˜ëŸ‰)"], horizontal=True, key="binder_input_mode")

    if input_mode == "ê°œë³„ ì…ë ¥":
        with st.form("binder_form_single", clear_on_submit=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                mfg_date = st.date_input("ì œì¡°/ì…ê³ ì¼", value=dt.date.today(), key="b_single_date")
                b_name = st.selectbox("ë°”ì¸ë”ëª…", binder_names, key="b_single_name") if binder_names else st.text_input("ë°”ì¸ë”ëª…", key="b_single_name_text")
            with col2:
                visc = st.number_input("ì ë„(cP)", min_value=0.0, step=1.0, format="%.1f", key="b_single_visc")
                uv = st.number_input("UVí¡ê´‘ë„(ì„ íƒ)", min_value=0.0, step=0.01, format="%.3f", key="b_single_uv")
                uv_enabled = st.checkbox("UV ê°’ ì…ë ¥í•¨", value=False, key="b_single_uv_en")
            with col3:
                note = st.text_input("ë¹„ê³ ", value="", key="b_single_note")
                submit_b = st.form_submit_button("ì €ì¥(ë°”ì¸ë”)")

        if submit_b:
            visc_lo, visc_hi, uv_hi, _ = get_binder_limits(spec_binder, b_name)
            lot = generate_binder_lot(spec_binder, b_name, mfg_date, binder_df.get(blot_col, pd.Series(dtype=str)) if blot_col else pd.Series(dtype=str))

            judge_v = judge_range(visc, visc_lo, visc_hi)
            judge_u = judge_range(uv if uv_enabled else None, None, uv_hi)
            judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

            row = {
                "ì œì¡°/ì…ê³ ì¼": mfg_date,
                "ë°”ì¸ë”ëª…": b_name,
                "Lot(ìë™)": lot,
                "ì ë„(cP)": float(visc),
                "UVí¡ê´‘ë„(ì„ íƒ)": float(uv) if uv_enabled else None,
                "íŒì •": judge,
                "ë¹„ê³ ": note,
            }
            try:
                append_row_to_sheet(xlsx_path, SHEET_BINDER, row)
                st.success(f"ì €ì¥ ì™„ë£Œ! ë°”ì¸ë” Lot = {lot}")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        st.caption("í‘œì— ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰(í†µ)/ì ë„/UV/ë¹„ê³ ë¥¼ ì…ë ¥í•˜ê³ , í•œ ë²ˆì— ì €ì¥í•©ë‹ˆë‹¤.")
        base_rows = st.session_state.get("binder_batch_rows")
        if base_rows is None:
            d0 = dt.date.today()
            first_name = binder_names[0] if binder_names else ""
            base_rows = [
                {"ì œì¡°/ì…ê³ ì¼": d0, "ë°”ì¸ë”ëª…": first_name, "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
                {"ì œì¡°/ì…ê³ ì¼": d0 - dt.timedelta(days=1), "ë°”ì¸ë”ëª…": first_name, "ìˆ˜ëŸ‰(í†µ)": 8, "ì ë„(cP)": 0.0, "UVì…ë ¥": False, "UVí¡ê´‘ë„(ì„ íƒ)": None, "ë¹„ê³ ": ""},
            ]
        edit_df = st.data_editor(pd.DataFrame(base_rows), use_container_width=True, num_rows="dynamic", key="binder_batch_editor")
        submit_batch = st.button("ë¬¶ìŒ ì €ì¥(ë°”ì¸ë”)", type="primary", key="binder_batch_submit")

        if submit_batch:
            tmp = edit_df.copy()
            tmp["ì œì¡°/ì…ê³ ì¼"] = tmp["ì œì¡°/ì…ê³ ì¼"].apply(normalize_date)
            tmp["ìˆ˜ëŸ‰(í†µ)"] = pd.to_numeric(tmp["ìˆ˜ëŸ‰(í†µ)"], errors="coerce").fillna(0).astype(int)
            tmp["ì ë„(cP)"] = pd.to_numeric(tmp["ì ë„(cP)"].astype(str).str.replace(",", "", regex=False), errors="coerce")
            tmp = tmp.dropna(subset=["ì œì¡°/ì…ê³ ì¼", "ë°”ì¸ë”ëª…", "ì ë„(cP)"])
            tmp = tmp[tmp["ìˆ˜ëŸ‰(í†µ)"] > 0]
            if len(tmp) == 0:
                st.error("ì €ì¥í•  í–‰ì´ ì—†ìŠµë‹ˆë‹¤. (ë‚ ì§œ/ë°”ì¸ë”ëª…/ìˆ˜ëŸ‰/ì ë„ ì…ë ¥ í™•ì¸)")
                st.stop()

            existing = binder_df.get(blot_col, pd.Series(dtype=str)) if blot_col else pd.Series(dtype=str)
            existing_list = existing.dropna().astype(str).tolist()
            seq_counters = {}
            rows_out = []

            tmp = tmp.sort_values(by="ì œì¡°/ì…ê³ ì¼")
            for _, r in tmp.iterrows():
                mfg_date = r["ì œì¡°/ì…ê³ ì¼"]
                b_name = str(r["ë°”ì¸ë”ëª…"]).strip()
                qty = int(r["ìˆ˜ëŸ‰(í†µ)"])
                visc = safe_to_float(r["ì ë„(cP)"])
                uv_enabled = bool(r.get("UVì…ë ¥", False))
                uv_val = safe_to_float(r.get("UVí¡ê´‘ë„(ì„ íƒ)", None)) if uv_enabled else None
                note = str(r.get("ë¹„ê³ ", "")).strip()

                visc_lo, visc_hi, uv_hi, rule = get_binder_limits(spec_binder, b_name)
                m = re.match(r"^([A-Za-z0-9]+)\+YYYYMMDD(-##)?$", str(rule).strip()) if rule else None
                if not m:
                    st.error(f"[{b_name}] Lotë¶€ì—¬ê·œì¹™ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Spec_Binder í™•ì¸ í•„ìš”)")
                    st.stop()

                prefix = m.group(1)
                has_seq = bool(m.group(2))
                date_str = mfg_date.strftime("%Y%m%d")

                if (not has_seq) and qty > 1:
                    st.error(f"[{b_name}] Lotë¶€ì—¬ê·œì¹™ì— ìˆœë²ˆ(-##)ì´ ì—†ì–´ ì—¬ëŸ¬ í†µ(ìˆ˜ëŸ‰={qty})ì„ ìë™ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                key = (prefix, date_str)
                if key not in seq_counters:
                    seq_counters[key] = next_seq_for_pattern(pd.Series(existing_list), prefix, date_str, sep="-")

                for _i in range(qty):
                    if has_seq:
                        seq = seq_counters[key]
                        seq_counters[key] += 1
                        lot = f"{prefix}{date_str}-{seq:02d}"
                    else:
                        lot = f"{prefix}{date_str}"

                    judge_v = judge_range(visc, visc_lo, visc_hi)
                    judge_u = judge_range(uv_val, None, uv_hi) if uv_enabled else None
                    judge = "ë¶€ì í•©" if (judge_v == "ë¶€ì í•©" or judge_u == "ë¶€ì í•©") else "ì í•©"

                    rows_out.append({
                        "ì œì¡°/ì…ê³ ì¼": mfg_date,
                        "ë°”ì¸ë”ëª…": b_name,
                        "Lot(ìë™)": lot,
                        "ì ë„(cP)": float(visc) if visc is not None else None,
                        "UVí¡ê´‘ë„(ì„ íƒ)": float(uv_val) if uv_enabled and uv_val is not None else None,
                        "íŒì •": judge,
                        "ë¹„ê³ ": note,
                    })
                    existing_list.append(lot)

            st.write("ì €ì¥ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 50ê±´)")
            st.dataframe(pd.DataFrame(rows_out).tail(50), use_container_width=True)

            try:
                append_rows_to_sheet(xlsx_path, SHEET_BINDER, rows_out)
                st.success(f"ë¬¶ìŒ ì €ì¥ ì™„ë£Œ! ì´ {len(rows_out)}ê±´ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.")
                st.cache_data.clear()
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    st.divider()
    st.subheader("ë°”ì¸ë” ì…ì¶œê³  (Google Sheets ìë™ ë°˜ì˜, ìµœì‹ ìˆœ)")
    st.caption("êµ¬ê¸€ ì‹œíŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ì´ í™”ë©´ì€ ìƒˆë¡œê³ ì¹¨ ì‹œ ìë™ ë°˜ì˜ë©ë‹ˆë‹¤. (ìºì‹œ 60ì´ˆ)")

    try:
        df_hema = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_HEMA)
        df_sil = read_gsheet_csv(BINDER_SHEET_ID, BINDER_SHEET_SIL)
    except Exception as e:
        st.error("êµ¬ê¸€ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ëª» ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ì‹œíŠ¸ ê³µìœ /ì›¹ê²Œì‹œ/ì‹œíŠ¸ëª…/ID í™•ì¸)")
        st.exception(e)
        st.stop()

    for _df in [df_hema, df_sil]:
        dc = detect_date_col(_df)
        if dc:
            _df["_sort_date"] = pd.to_datetime(_df[dc], errors="coerce")
            _df.sort_values(by="_sort_date", ascending=False, inplace=True)
            _df.drop(columns=["_sort_date"], inplace=True)

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("### HEMA (ìµœì‹ ìˆœ)")
        st.dataframe(df_hema, use_container_width=True, height=420)
    with c2:
        st.markdown("### Silicone (ìµœì‹ ìˆœ)")
        st.dataframe(df_sil, use_container_width=True, height=420)

    if st.button("ì§€ê¸ˆ ìµœì‹ ê°’ìœ¼ë¡œ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°", key="binder_refresh"):
        st.cache_data.clear()
        st.rerun()

# ==========================================================
# ë¹ ë¥¸ê²€ìƒ‰ / ìˆ˜ì •
# ==========================================================
with tab_search:
    st.subheader("ë¹ ë¥¸ê²€ìƒ‰")
    st.caption("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”ë¡œ 'ìˆ˜ì • ëª¨ë“œ'ë¡œ ì—´ì–´ì„œ ì˜ëª» ì…ë ¥ëœ ë°ì´í„°ë¥¼ ê³ ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì—‘ì…€ì— ì§ì ‘ ë°˜ì˜)")

    edit_mode = st.checkbox("ğŸ”§ ìˆ˜ì • ëª¨ë“œ ì¼œê¸°(ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¸ì§‘ ê°€ëŠ¥í•˜ê²Œ)", value=False, key="qs_edit_mode")

    c1, c2, c3 = st.columns([2, 2, 3])
    with c1:
        mode = st.selectbox("ê²€ìƒ‰ ì¢…ë¥˜", ["ë°”ì¸ë” Lot", "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot", "ì œí’ˆì½”ë“œ", "ìƒ‰ìƒêµ°", "ê¸°ê°„(ì…ê³ ì¼)"])
    with c2:
        q = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: PCB20250112-01 / PLB25041501 / PL-835-1 ...")
    with c3:
        st.write("")
        st.caption("ğŸ’¡ ë°”ì¸ë” Lot ê²€ìƒ‰: ë°”ì¸ë” ì •ë³´ + í•´ë‹¹ Lotë¥¼ ì‚¬ìš©í•œ ë‹¨ì¼ìƒ‰ ì‰í¬ ëª©ë¡")

    # ë‹¨ì¼ìƒ‰ ê²€ìƒ‰ìš© df
    s_df = single_df.copy()
    if c_s_date:
        s_df[c_s_date] = pd.to_datetime(s_df[c_s_date], errors="coerce")

    # ë°”ì¸ë” ê²€ìƒ‰ìš© df
    b_df = binder_df.copy()
    if c_b_date:
        b_df[c_b_date] = pd.to_datetime(b_df[c_b_date], errors="coerce")

    def text_filter(df: pd.DataFrame, cols: list[str], text: str) -> pd.DataFrame:
        if not text:
            return df.iloc[0:0]
        t = str(text).strip()
        if not t:
            return df.iloc[0:0]
        mask = False
        for c in cols:
            if c and c in df.columns:
                mask = mask | df[c].astype(str).str.contains(t, case=False, na=False)
        return df[mask]

    if mode == "ê¸°ê°„(ì…ê³ ì¼)":
        dmin, dmax = safe_date_bounds(s_df[c_s_date]) if c_s_date else (dt.date.today(), dt.date.today())
        d1, d2 = st.columns(2)
        with d1:
            start = st.date_input("ì‹œì‘ì¼", value=max(dmin, dmax - dt.timedelta(days=30)), key="qs_start")
        with d2:
            end = st.date_input("ì¢…ë£Œì¼", value=dmax, key="qs_end")
        if start > end:
            start, end = end, start
        df_hit = s_df.copy()
        if c_s_date:
            df_hit = df_hit[(df_hit[c_s_date].dt.date >= start) & (df_hit[c_s_date].dt.date <= end)]
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        df_hit_show = add_excel_row_number(df_hit.sort_values(by=c_s_date, ascending=False) if c_s_date else df_hit)
        st.dataframe(df_hit_show, use_container_width=True)

        if edit_mode and len(df_hit_show) > 0:
            st.markdown("#### ğŸ”§ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì •")
            edited = st.data_editor(
                df_hit_show,
                use_container_width=True,
                num_rows="fixed",
                disabled=["_excel_row"],
                key="qs_edit_period",
            )
            if st.button("ë³€ê²½ì‚¬í•­ ì €ì¥(ê¸°ê°„ê²€ìƒ‰)", type="primary", key="qs_save_period"):
                updates = []
                for i in range(len(df_hit_show)):
                    excel_row = int(df_hit_show.iloc[i]["_excel_row"])
                    for col in df_hit_show.columns:
                        if col == "_excel_row":
                            continue
                        before = df_hit_show.iloc[i][col]
                        after = edited.iloc[i][col]
                        if (pd.isna(before) and pd.isna(after)) or (str(before) == str(after)):
                            continue
                        if "ì¼" in norm_key(col):
                            after = normalize_date(after)
                        updates.append((excel_row, col, after))
                if not updates:
                    st.info("ë³€ê²½ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        update_sheet_cells(xlsx_path, SHEET_SINGLE, updates)
                        st.success("ì €ì¥ ì™„ë£Œ!")
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    elif mode == "ë°”ì¸ë” Lot":
        c_bl = find_col(b_df, "Lot(ìë™)")
        c_bn = find_col(b_df, "ë°”ì¸ë”ëª…")
        c_bnote = find_col(b_df, "ë¹„ê³ ")
        hit_b = text_filter(b_df, [c_bl, c_bn, c_bnote], q)
        st.subheader("ë°”ì¸ë”_ì œì¡°_ì…ê³ ")
        hit_b_show = add_excel_row_number(hit_b.sort_values(by=c_b_date, ascending=False) if c_b_date else hit_b)
        st.dataframe(hit_b_show, use_container_width=True)

        hit_s_show = None
        if q and c_s_blot:
            hit_s = s_df[s_df[c_s_blot].astype(str).str.contains(str(q).strip(), case=False, na=False)]
            st.subheader("ì—°ê²°ëœ ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬ (ì‚¬ìš©ëœ ë°”ì¸ë” Lot)")
            hit_s_show = add_excel_row_number(hit_s.sort_values(by=c_s_date, ascending=False) if c_s_date else hit_s)
            st.dataframe(hit_s_show, use_container_width=True)

        if edit_mode:
            if len(hit_b_show) > 0:
                st.markdown("#### ğŸ”§ ë°”ì¸ë” ê²°ê³¼ ìˆ˜ì •")
                edited_b = st.data_editor(hit_b_show, use_container_width=True, num_rows="fixed", disabled=["_excel_row"], key="qs_edit_binder")
                if st.button("ë³€ê²½ì‚¬í•­ ì €ì¥(ë°”ì¸ë”)", type="primary", key="qs_save_binder"):
                    updates = []
                    for i in range(len(hit_b_show)):
                        excel_row = int(hit_b_show.iloc[i]["_excel_row"])
                        for col in hit_b_show.columns:
                            if col == "_excel_row":
                                continue
                            before = hit_b_show.iloc[i][col]
                            after = edited_b.iloc[i][col]
                            if (pd.isna(before) and pd.isna(after)) or (str(before) == str(after)):
                                continue
                            if "ì¼" in norm_key(col):
                                after = normalize_date(after)
                            updates.append((excel_row, col, after))
                    if not updates:
                        st.info("ë³€ê²½ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        try:
                            update_sheet_cells(xlsx_path, SHEET_BINDER, updates)
                            st.success("ì €ì¥ ì™„ë£Œ!")
                            st.cache_data.clear()
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

            if q and c_s_blot and hit_s_show is not None and len(hit_s_show) > 0:
                st.markdown("#### ğŸ”§ ì—°ê²°ëœ ë‹¨ì¼ìƒ‰ ê²°ê³¼ ìˆ˜ì •")
                edited_s = st.data_editor(hit_s_show, use_container_width=True, num_rows="fixed", disabled=["_excel_row"], key="qs_edit_single_by_binder")
                if st.button("ë³€ê²½ì‚¬í•­ ì €ì¥(ì—°ê²° ë‹¨ì¼ìƒ‰)", type="primary", key="qs_save_single_by_binder"):
                    updates = []
                    for i in range(len(hit_s_show)):
                        excel_row = int(hit_s_show.iloc[i]["_excel_row"])
                        for col in hit_s_show.columns:
                            if col == "_excel_row":
                                continue
                            before = hit_s_show.iloc[i][col]
                            after = edited_s.iloc[i][col]
                            if (pd.isna(before) and pd.isna(after)) or (str(before) == str(after)):
                                continue
                            if "ì¼" in norm_key(col):
                                after = normalize_date(after)
                            updates.append((excel_row, col, after))
                    if not updates:
                        st.info("ë³€ê²½ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        try:
                            update_sheet_cells(xlsx_path, SHEET_SINGLE, updates)
                            st.success("ì €ì¥ ì™„ë£Œ!")
                            st.cache_data.clear()
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    elif mode == "ë‹¨ì¼ìƒ‰ ì‰í¬ Lot":
        hit = text_filter(s_df, [c_s_lot, c_s_pc, c_s_blot, c_s_cg, find_col(s_df, "ë¹„ê³ ")], q)
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        hit_show = add_excel_row_number(hit.sort_values(by=c_s_date, ascending=False) if c_s_date else hit)
        st.dataframe(hit_show, use_container_width=True)

        if edit_mode and len(hit_show) > 0:
            st.markdown("#### ğŸ”§ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì •")
            edited = st.data_editor(hit_show, use_container_width=True, num_rows="fixed", disabled=["_excel_row"], key="qs_edit_single_lot")
            if st.button("ë³€ê²½ì‚¬í•­ ì €ì¥(ë‹¨ì¼ìƒ‰ Lot ê²€ìƒ‰)", type="primary", key="qs_save_single_lot"):
                updates = []
                for i in range(len(hit_show)):
                    excel_row = int(hit_show.iloc[i]["_excel_row"])
                    for col in hit_show.columns:
                        if col == "_excel_row":
                            continue
                        before = hit_show.iloc[i][col]
                        after = edited.iloc[i][col]
                        if (pd.isna(before) and pd.isna(after)) or (str(before) == str(after)):
                            continue
                        if "ì¼" in norm_key(col):
                            after = normalize_date(after)
                        updates.append((excel_row, col, after))
                if not updates:
                    st.info("ë³€ê²½ëœ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    try:
                        update_sheet_cells(xlsx_path, SHEET_SINGLE, updates)
                        st.success("ì €ì¥ ì™„ë£Œ!")
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

    elif mode == "ì œí’ˆì½”ë“œ":
        hit = text_filter(s_df, [c_s_pc], q)
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        hit_show = add_excel_row_number(hit.sort_values(by=c_s_date, ascending=False) if c_s_date else hit)
        st.dataframe(hit_show, use_container_width=True)

    elif mode == "ìƒ‰ìƒêµ°":
        hit = text_filter(s_df, [c_s_cg], q)
        st.subheader("ë‹¨ì¼ìƒ‰_ìˆ˜ì…ê²€ì‚¬")
        hit_show = add_excel_row_number(hit.sort_values(by=c_s_date, ascending=False) if c_s_date else hit)
        st.dataframe(hit_show, use_container_width=True)
